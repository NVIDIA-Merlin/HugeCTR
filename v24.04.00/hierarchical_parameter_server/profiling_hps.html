<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Profiling HPS &mdash; Merlin HugeCTR  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />

  
    <link rel="canonical" href="https://nvidia-merlin.github.io/HugeCTR/main/hierarchical_parameter_server/profiling_hps.html" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Sparse Operation Kit" href="../sparse_operation_kit.html" />
    <link rel="prev" title="Benchmark the DLRM Model with HPS" href="hps_dlrm_benchmark.html" /> 
</head>

<body class="wy-body-for-nav">
  <div class="banner">
    <p class="banner">
      Since the HugeCTR <code>v23.09</code>, the offline inference has been deprecated.
      Since the HugeCTR <code>v24.06</code>, the HPS has been deprecated.
  </div>

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Merlin HugeCTR
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">HUGECTR</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../hugectr_user_guide.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hugectr_core_features.html">Core Features</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Hierarchical Parameter Server</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="hps_database_backend.html">HPS Database Backend</a></li>
<li class="toctree-l2"><a class="reference internal" href="hps_tf_user_guide.html">HPS Plugin for TensorFlow</a></li>
<li class="toctree-l2"><a class="reference internal" href="hps_trt_user_guide.html">HPS Plugin for TensorRT</a></li>
<li class="toctree-l2"><a class="reference internal" href="hps_torch_user_guide.html">HPS Plugin for Torch</a></li>
<li class="toctree-l2"><a class="reference internal" href="hps_dlrm_benchmark.html">Benchmark HPS-integrated DLRM</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Profiling HPS</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../sparse_operation_kit.html">Sparse Operation Kit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance.html">Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/index.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/multi-modal-data/index.html">Multi-modal Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../additional_resources.html">Additional Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hugectr_contributor_guide.html">Contributing to HugeCTR</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Merlin HugeCTR</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">Hierarchical Parameter Server</a></li>
      <li class="breadcrumb-item active">Profiling HPS</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <!--
# Copyright (c) 2023, NVIDIA CORPORATION.
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
-->
<section class="tex2jax_ignore mathjax_ignore" id="profiling-hps">
<h1>Profiling HPS<a class="headerlink" href="#profiling-hps" title="Permalink to this heading"></a></h1>
<p>A critical part of optimizing the inference performance of HPS
is being able to measure changes in performance as you experiment with
different optimization strategies and data distribution. There are two ways to profile HPS:</p>
<ol class="arabic simple">
<li><p>The HPS profiler.
The hps_profiler application performs benchmark tasks for the Hierarchical Parameter Server. The hps_profiler will be compiled and installed from the following instructions in <a class="reference internal" href="#section-1"><span class="xref myst">Build and install the HPS Profiler</span></a>.</p></li>
<li><p>The Triton Perf Analyzer. For detailed documentation of Triton Perf Analyzer, please refer to <a class="reference external" href="https://github.com/triton-inference-server/client/blob/main/src/c++/perf_analyzer/README.md">here</a>. For how to use Trion Perf Analyzer to profile HPS, take a look at the <a class="reference internal" href="#profile-hps-with-triton-perf-analyzer">procedure</a>.</p></li>
</ol>
<section id="hps-profiler">
<h2>HPS profiler<a class="headerlink" href="#hps-profiler" title="Permalink to this heading"></a></h2>
<p>The hps_profiler application generates inference requests to HPS and measures the throughput and latency of different components, such as embedding cache, Database Backend and Lookup session. To
get representative results, hps_profiler measures the throughput and
latency over the configurable iteration, and then repeats the measurements until it reaches a specified number of iterations.
For example, if <code class="docutils literal notranslate"><span class="pre">--embedding_cache</span></code> is used the results will be show below:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ hps_profiler --iterations 1000 --num_key 2000 --powerlaw --alpha 1.2 --config /hugectr/model/ps.json --table_size 630000 --warmup_iterations 100   --embedding_cache

...
*** Measurement Results ***
  The Benchmark of: Apply for workspace from the memory pool for Embedding Cache Lookup
Latencies [900 iterations] min = 0.000285ms, mean = 0.000384853ms, median = 0.000365ms, 95% = 0.000428ms, 99% = 0.000465ms, max = 0.009736ms, throughput = 2.73973e+06/s
The Benchmark of: Copy the input to workspace of Embedding Cache
Latencies [900 iterations] min = 0.010842ms, mean = 0.0117076ms, median = 0.011596ms, 95% = 0.012219ms, 99% = 0.016642ms, max = 0.027379ms, throughput = 86236.6/s
The Benchmark of: Deduplicate the input embedding key for Embedding Cache
Latencies [900 iterations] min = 0.019159ms, mean = 0.0272492ms, median = 0.027262ms, 95% = 0.028104ms, 99% = 0.029548ms, max = 0.052309ms, throughput = 36681.1/s
The Benchmark of: Lookup the embedding keys from Embedding Cache
Latencies [900 iterations] min = 0.178875ms, mean = 0.231377ms, median = 0.227815ms, 95% = 0.267493ms, 99% = 0.284738ms, max = 0.47672ms, throughput = 4389.53/s
The Benchmark of: Merge output from Embedding Cache
Latencies [900 iterations] min = 0.007656ms, mean = 0.00850756ms, median = 0.008434ms, 95% = 0.009117ms, 99% = 0.011863ms, max = 0.018697ms, throughput = 118568/s
The Benchmark of: Missing key synchronization insert into Embedding Cache
Latencies [900 iterations] min = 0.105163ms, mean = 0.15741ms, median = 0.153763ms, 95% = 0.192302ms, 99% = 0.208846ms, max = 0.402043ms, throughput = 6503.52/s
The Benchmark of: Native Embedding Cache Query API
Latencies [900 iterations] min = 0.021729ms, mean = 0.0227739ms, median = 0.02253ms, 95% = 0.023695ms, 99% = 0.025035ms, max = 0.043024ms, throughput = 44385.3/s
The Benchmark of: decompress/deunique output from Embedding Cache
Latencies [900 iterations] min = 0.011247ms, mean = 0.0121274ms, median = 0.011953ms, 95% = 0.013055ms, 99% = 0.014706ms, max = 0.022186ms, throughput = 83661/s
The Benchmark of: The hit rate of Embedding Cache
Occupancy [900 iterations] min = 0.719323, mean = 0.843972, median = 0.854749, 95% = 0.894188, 99% = 0.90276, max = 0.918169
</pre></div>
</div>
<p><a id="section-1"></a></p>
</section>
<section id="build-and-install-the-hps-profiler">
<h2>Build and install the HPS Profiler<a class="headerlink" href="#build-and-install-the-hps-profiler" title="Permalink to this heading"></a></h2>
<p>To build HPS profiler from source, do the following:
2. Download the HugeCTR repository and the third-party modules that it relies on by running the following commands:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="w">   </span>$<span class="w"> </span>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/NVIDIA/HugeCTR.git
<span class="w">   </span>$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>HugeCTR
<span class="w">   </span>$<span class="w"> </span>git<span class="w"> </span>submodule<span class="w"> </span>update<span class="w"> </span>--init<span class="w"> </span>--recursive
</pre></div>
</div>
<ol class="arabic simple" start="2">
<li><p>Pull the NGC Docker and run it</p></li>
</ol>
<p>Pull the container using the following command:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>pull<span class="w"> </span>nvcr.io/nvidia/merlin/merlin-hugectr:24.04
</pre></div>
</div>
<p>Launch the container in interactive mode (mount the HugeCTR root directory into the container for your convenience) by running this command:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>docker<span class="w"> </span>run<span class="w"> </span>--gpus<span class="w"> </span>all<span class="w"> </span>--rm<span class="w"> </span>-it<span class="w"> </span>--cap-add<span class="w"> </span>SYS_NICE<span class="w"> </span>--ipc<span class="o">=</span>host<span class="w"> </span>--ulimit<span class="w"> </span><span class="nv">memlock</span><span class="o">=</span>-1<span class="w"> </span>--ulimit<span class="w"> </span><span class="nv">stack</span><span class="o">=</span><span class="m">67108864</span><span class="w"> </span>-u<span class="w"> </span>root<span class="w"> </span>-v<span class="w"> </span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span>:/HugeCTR<span class="w"> </span>-w<span class="w"> </span>/HugeCTR<span class="w"> </span>-p<span class="w"> </span><span class="m">8888</span>:8888<span class="w"> </span>nvcr.io/nvidia/merlin/merlin-hugectr:24.04
</pre></div>
</div>
<ol class="arabic" start="3">
<li><p>Here is an example of how you can build HPS Profiler  using the build options:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>mkdir<span class="w"> </span>-p<span class="w"> </span>build<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>build
$<span class="w"> </span>cmake<span class="w"> </span>-DCMAKE_BUILD_TYPE<span class="o">=</span>Release<span class="w"> </span>-DSM<span class="o">=</span><span class="s2">&quot;70;80&quot;</span><span class="w"> </span>-DENABLE_INFERENCE<span class="o">=</span>ON<span class="w"> </span>-DENABLE_PROFILER<span class="o">=</span>ON<span class="w"> </span>..<span class="w"> </span><span class="c1"># Target is NVIDIA V100 / A100 with Inference mode ON.</span>
$<span class="w"> </span>make<span class="w"> </span>-j<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span>make<span class="w"> </span>install
</pre></div>
</div>
</li>
<li><p>You will get <code class="docutils literal notranslate"><span class="pre">hps_profiler</span></code> under bin folder.</p></li>
</ol>
</section>
<section id="create-a-synthetic-embedding-table">
<h2>Create a synthetic embedding table<a class="headerlink" href="#create-a-synthetic-embedding-table" title="Permalink to this heading"></a></h2>
<p>The embedding generator is used to generate synthetic HugeCTR sparse model files that can be loaded into HugeCTR <a class="reference external" href="https://nvidia-merlin.github.io/HugeCTR/main/hierarchical_parameter_server/index.html">HPS</a> for inference. To generate a HugeCTR embedding file, please refer to the <span class="xref myst">Model generator </span></p>
</section>
<section id="use-the-hps-profiler-to-get-the-measurement-results">
<h2>Use the HPS Profiler to get the measurement results<a class="headerlink" href="#use-the-hps-profiler-to-get-the-measurement-results" title="Permalink to this heading"></a></h2>
<ol class="arabic simple">
<li><p>Generate HPS json configuration file based on synthetic model file.
For configuration information about HPS, you can refer to <a class="reference external" href="https://nvidia-merlin.github.io/HugeCTR/main/hugectr_parameter_server.html#configuration">here</a>. Here is an example:</p></li>
</ol>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">	</span><span class="nt">&quot;supportlonglong&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">true</span><span class="p">,</span>
<span class="w">	</span><span class="nt">&quot;models&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[{</span>
<span class="w">			</span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;model_name&quot;</span><span class="p">,</span>
<span class="w">			</span><span class="nt">&quot;sparse_files&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;The path of synthetic embedding files&quot;</span><span class="p">],</span>
<span class="w">			</span><span class="nt">&quot;dense_file&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&quot;</span><span class="p">,</span>
<span class="w">			</span><span class="nt">&quot;network_file&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&quot;</span><span class="p">,</span>
<span class="w">			</span><span class="nt">&quot;num_of_worker_buffer_in_pool&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span>
<span class="w">			</span><span class="nt">&quot;num_of_refresher_buffer_in_pool&quot;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span>
<span class="w">			</span><span class="nt">&quot;deployed_device_list&quot;</span><span class="p">:[</span><span class="mi">0</span><span class="p">],</span>
<span class="w">			</span><span class="nt">&quot;max_batch_size&quot;</span><span class="p">:</span><span class="mi">1024</span><span class="p">,</span>
<span class="w">			</span><span class="nt">&quot;default_value_for_each_table&quot;</span><span class="p">:[</span><span class="mf">0.0</span><span class="p">],</span>
<span class="w">			</span><span class="nt">&quot;cache_refresh_percentage_per_iteration&quot;</span><span class="p">:</span><span class="mf">0.1</span><span class="p">,</span>
<span class="w">			</span><span class="nt">&quot;hit_rate_threshold&quot;</span><span class="p">:</span><span class="mf">1.0</span><span class="p">,</span>
<span class="w">			</span><span class="nt">&quot;gpucacheper&quot;</span><span class="p">:</span><span class="mf">0.9</span><span class="p">,</span>
<span class="w">			</span><span class="nt">&quot;gpucache&quot;</span><span class="p">:</span><span class="kc">true</span><span class="p">,</span>
<span class="w">			</span><span class="nt">&quot;maxnum_des_feature_per_sample&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">			</span><span class="nt">&quot;maxnum_catfeature_query_per_table_per_sample&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">26</span><span class="p">],</span>
<span class="w">			</span><span class="nt">&quot;embedding_vecsize_per_table&quot;</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">16</span><span class="p">]</span>

<span class="w">		</span><span class="p">}</span>
<span class="w">	</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p><em><code class="docutils literal notranslate"><span class="pre">NOTE</span></code></em>: The product of the <code class="docutils literal notranslate"><span class="pre">max_batch_size</span></code> size and the <code class="docutils literal notranslate"><span class="pre">maxnum_catfeature_query_per_table_per_sample</span></code> needs to be greater than or equal to the <code class="docutils literal notranslate"><span class="pre">--num_key</span></code> option in the hps_profiler.</p>
<ol class="arabic simple" start="2">
<li><p>Add arguments to hps_profiler for benchmark</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$ hps_profiler 
--config: required.
Usage: HPS_Profiler [options] 

Optional arguments:
-h --help                       shows help message and exits [default: false]
-v --version                    prints version information and exits [default: false]
--config                        The path of the HPS json configuration file [required]
--distribution                      The distribution of the generated query key in each iteration. Can be &#39;powerlaw&#39;, &#39;hotkey&#39;, or &#39;histogram&#39; [default: &quot;powerlaw&quot;]
--table_size                    The number of keys in the embedded table [default: 100000]
--alpha                         Alpha of power distribution [default: 1.2]
--hot_key_percentage            Percentage of hot keys in embedding tables [default: 0.2]
--hot_key_coverage              The probability of the hot key in each iteration [default: 0.8]
--num_key                       The number of keys to query for each iteration [default: 1000]
--iterations                    The number of iterations of the test [default: 1000]
--warmup_iterations             Performance results in warmup stage will be discarded [default: 0]
--embedding_cache               Enable embedding cache profiler, including the performance of lookup, insert, etc. [default: false]
--database_backend              Enable database backend profiler, which is to get the lookup performance of VDB/PDB [default: false]
--refresh_embeddingcache        Enable refreshing embedding cache. If the embedding cache tool is also enabled, the refresh will be performed asynchronously [default: false]
--lookup_session                Enable lookup_session profiler, which is E2E profiler, including embedding cache and data backend query delay [default: false]
</pre></div>
</div>
<p>Measurement example of the HPS Lookup Session</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$hps_profiler --iterations 1000 --num_key 2000 --powerlaw --alpha 1.2 --config /hugectr/Model_Samples/wdl/wdl_infer/model/ps.json --table_size 630000 --warmup_iterations 100   --lookup_session
...
*** Measurement Results ***
The Benchmark of: End-to-end lookup embedding keys for Lookup session
Latencies [900 iterations] min = 0.190813ms, mean = 0.243117ms, median = 0.238085ms, 95% = 0.283761ms, 99% = 0.346377ms, max = 0.511712ms, throughput= 4200.18/s
</pre></div>
</div>
<p>Measurement example of the HPS Data Backend</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>$hps_profiler --iterations 1000 --num_key 2000 --powerlaw --alpha 1.2 --config /hugectr/Model_Samples/wdl/wdl_infer/model/ps.json --table_size 630000 --warmup_iterations 100   --database_backend
...
*** Measurement Results ***
The Benchmark of: Lookup the embedding key from default HPS database Backend
Latencies [900 iterations] min = 0.075086ms, mean = 0.127312ms, median = 0.121235ms, 95% = 0.166826ms, 99% = 0.219295ms, max = 0.285409ms, throughput = 8248.44/s
</pre></div>
</div>
<p><em><code class="docutils literal notranslate"><span class="pre">NOTE</span></code></em>:</p>
<ol class="arabic simple">
<li><p>If the user add the <code class="docutils literal notranslate"><span class="pre">--powerlaw</span></code> option, the queried embedding key will be generated with the specified argument <code class="docutils literal notranslate"><span class="pre">--alpha</span> <span class="pre">=</span> <span class="pre">**</span></code>.</p></li>
<li><p>If the user add the <code class="docutils literal notranslate"><span class="pre">--hot_key_percentage=**</span></code> and <code class="docutils literal notranslate"><span class="pre">--hot_key_coverage=xx</span></code> options, the queried embedding key  will generate the number of <code class="docutils literal notranslate"><span class="pre">--table_size</span></code> * <code class="docutils literal notranslate"><span class="pre">--hot_key_percentage</span></code> keys with this probability of <code class="docutils literal notranslate"><span class="pre">--hot_key_percentage=**</span></code>.
For example <code class="docutils literal notranslate"><span class="pre">--hot_key_percentage=0.01</span></code>,  <code class="docutils literal notranslate"><span class="pre">--hot_key_coverage=0.9</span></code> and <code class="docutils literal notranslate"><span class="pre">--table_size=1000</span></code>, then the first 1000*0.01=10 keys will appear in the request with a probability of 90%.</p></li>
<li><p>It is recommended that users make mutually exclusive selections of three components(<code class="docutils literal notranslate"><span class="pre">--embedding_cache</span></code>,<code class="docutils literal notranslate"><span class="pre">--database_backend</span></code> and <code class="docutils literal notranslate"><span class="pre">--lookup_session</span></code>) to ensure the most accurate performance. Because the measurement results of the lookup session will include the performance results of the database backend and embedding cache.</p></li>
<li><p>If enable the <a class="reference external" href="https://github.com/NVIDIA-Merlin/HugeCTR/blob/main/docs/source/hugectr_parameter_server.md#inference-parameters-and-embedding-cache-configuration">static embedding table</a> in HPS json file, the hps_profiler does not support the refresh operation.</p></li>
</ol>
</section>
<section id="profile-hps-with-triton-perf-analyzer">
<h2>Profile HPS with Triton Perf Analyzer:<a class="headerlink" href="#profile-hps-with-triton-perf-analyzer" title="Permalink to this heading"></a></h2>
<p>To profile HPS with Triton Perf Analyzer, make sure you know how to deploy your model using the hugectr backend in Triton. If you don’t, please refer to <a class="reference external" href="https://github.com/triton-inference-server/hugectr_backend/tree/main/samples/hierarchical_deployment">here</a>.</p>
<p>To profile HPS, follow the procedure below:</p>
<ol class="arabic simple">
<li><p>Prepare your embedding table. This can be either a real model trained by HugeCTR or a synthetic model generated using the <a class="reference external" href="https://github.com/NVIDIA-Merlin/HugeCTR/blob/main/tools/inference_test_scripts/README.md">model generator</a>.</p></li>
<li><p>Prepare your HPS configuration file <code class="docutils literal notranslate"><span class="pre">ps.config</span></code>, demo showed above.</p></li>
<li><p>Prepare the Triton required JSON like request. The request can be generated using the <a class="reference external" href="https://github.com/NVIDIA-Merlin/HugeCTR/blob/main/tools/inference_test_scripts/README.md">request generator</a></p></li>
<li><p>After everything is prepared, start Triton. For example:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>tritonserver<span class="w"> </span>--model-repository<span class="o">=</span>/dir/to/model/<span class="w"> </span>--load-model<span class="o">=</span>your_model_name<span class="w"> </span>--model-control-mode<span class="o">=</span>explicit<span class="w"> </span>--backend-directory<span class="o">=</span>/usr/local/hugectr/backends<span class="w"> </span>--backend-config<span class="o">=</span>hugectr,ps<span class="o">=</span>/dir/to/your/ps.json
</pre></div>
</div>
<ol class="arabic simple" start="5">
<li><p>Run the Triton Perf Analyzer. For example:</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>perf_analyzer<span class="w"> </span>-m<span class="w"> </span>your_model_name<span class="w"> </span>--collect-metrics<span class="w"> </span>-f<span class="w"> </span>perf_output.csv<span class="w"> </span>--verbose-csv<span class="w"> </span>--input-data<span class="w"> </span>your_generated_request.json
</pre></div>
</div>
</section>
<section id="hps-profiler-vs-triton-perf-analyzer">
<h2>HPS Profiler vs. Triton Perf Analyzer:<a class="headerlink" href="#hps-profiler-vs-triton-perf-analyzer" title="Permalink to this heading"></a></h2>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Functionalities</p></th>
<th class="head"><p>HPS profiler</p></th>
<th class="head"><p>Triton Perf Analyzer</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Profile client side E2E Pipeline</p></td>
<td><p>NO</p></td>
<td><p>YES</p></td>
</tr>
<tr class="row-odd"><td><p>Profile sever side key lookup session</p></td>
<td><p>YES</p></td>
<td><p>YES</p></td>
</tr>
<tr class="row-even"><td><p>Pofile the embedding cache component</p></td>
<td><p>YES</p></td>
<td><p>NO</p></td>
</tr>
<tr class="row-odd"><td><p>Profile the database backend component</p></td>
<td><p>YES</p></td>
<td><p>NO</p></td>
</tr>
<tr class="row-even"><td><p>Support different key distributions</p></td>
<td><p>YES</p></td>
<td><p>YES</p></td>
</tr>
<tr class="row-odd"><td><p>Concurrency Support</p></td>
<td><p>NO</p></td>
<td><p>YES</p></td>
</tr>
<tr class="row-even"><td><p>GPU/Memory Utilization</p></td>
<td><p>NO</p></td>
<td><p>YES</p></td>
</tr>
</tbody>
</table>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="hps_dlrm_benchmark.html" class="btn btn-neutral float-left" title="Benchmark the DLRM Model with HPS" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../sparse_operation_kit.html" class="btn btn-neutral float-right" title="Sparse Operation Kit" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: v24.04.00
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../../v23.08.00/hierarchical_parameter_server/profiling_hps.html">v23.08.00</a></dd>
      <dd><a href="../../v23.09.00/hierarchical_parameter_server/profiling_hps.html">v23.09.00</a></dd>
      <dd><a href="../../v23.12.00/hierarchical_parameter_server/profiling_hps.html">v23.12.00</a></dd>
      <dd><a href="profiling_hps.html">v24.04.00</a></dd>
      <dd><a href="../../v24.06.00/hierarchical_parameter_server/profiling_hps.html">v24.06.00</a></dd>
      <dd><a href="../../v25.03.00/index.html">v25.03.00</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="../../main/index.html">main</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NVJ1Y1YJHK', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>