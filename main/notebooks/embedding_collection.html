<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>HugeCTR Embedding Collection &mdash; Merlin HugeCTR  documentation</title><link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/mystnb.css" type="text/css" />
      <link rel="stylesheet" href="../_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    <link rel="canonical" href="https://nvidia-merlin.github.io/HugeCTR/main/notebooks/embedding_collection.html" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
        <script >let toggleHintShow = 'Click to show';</script>
        <script >let toggleHintHide = 'Click to hide';</script>
        <script >let toggleOpenOnPrint = 'true';</script>
        <script src="../_static/togglebutton.js"></script>
        <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Multi-modal Example Notebooks" href="multi-modal-data/index.html" />
    <link rel="prev" title="Embedding Training Cache Example" href="embedding_training_cache_example.html" /> 
</head>

<body class="wy-body-for-nav">
  <div class="banner">
    <p class="banner">
      Beginning in January 2023, versions for all NVIDIA Merlin projects
      will change from semantic versioning like <code>4.0</code>
      to calendar versioning like <code>23.01</code>.</p>
  </div>

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html" class="icon icon-home"> Merlin HugeCTR
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption"><span class="caption-text">HUGECTR</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../hugectr_user_guide.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hugectr_core_features.html">Core Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hugectr_embedding_training_cache.html">Embedding Training Cache</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hierarchical_parameter_server/index.html">Hierarchical Parameter Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sparse_operation_kit.html">Sparse Operation Kit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance.html">Performance</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Example Notebooks</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="ecommerce-example.html">Merlin ETL, training, and inference with e-Commerce behavior data</a></li>
<li class="toctree-l2"><a class="reference internal" href="movie-lens-example.html">HugeCTR demo on Movie lens data</a></li>
<li class="toctree-l2"><a class="reference internal" href="hugectr_criteo.html">Introduction to the HugeCTR Python Interface</a></li>
<li class="toctree-l2"><a class="reference internal" href="hugectr2onnx_demo.html">HugeCTR to ONNX Converter</a></li>
<li class="toctree-l2"><a class="reference internal" href="continuous_training.html">HugeCTR Continuous Training</a></li>
<li class="toctree-l2"><a class="reference internal" href="hugectr_wdl_prediction.html">HugeCTR Wide and Deep Model with Criteo</a></li>
<li class="toctree-l2"><a class="reference internal" href="news-example.html">NVIDIA Merlin on Microsoft’s News Dataset (MIND)</a></li>
<li class="toctree-l2"><a class="reference internal" href="multi_gpu_offline_inference.html">Multi-GPU Offline Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="hps_demo.html">Hierarchical Parameter Server Demo</a></li>
<li class="toctree-l2"><a class="reference internal" href="embedding_training_cache_example.html">Embedding Training Cache Example</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">HugeCTR Embedding Collection</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="multi-modal-data/index.html">Multi-modal Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../additional_resources.html">Additional Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hugectr_contributor_guide.html">Contributing to HugeCTR</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Merlin HugeCTR</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">HugeCTR Example Notebooks</a></li>
      <li class="breadcrumb-item active">HugeCTR Embedding Collection</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <img alt="http://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_hugectr_embedding-collection/nvidia_logo.png" src="http://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_hugectr_embedding-collection/nvidia_logo.png" />
<div class="tex2jax_ignore mathjax_ignore section" id="hugectr-embedding-collection">
<h1>HugeCTR Embedding Collection<a class="headerlink" href="#hugectr-embedding-collection" title="Permalink to this headline"></a></h1>
<div class="section" id="about-this-notebook">
<h2>About this Notebook<a class="headerlink" href="#about-this-notebook" title="Permalink to this headline"></a></h2>
<p>This notebook demonstrates the following:</p>
<ul class="simple">
<li><p>Introduces the API of the embedding collection.</p></li>
<li><p>Introduces the embedding table placement strategy (ETPS) and how to configure ETPS in embedding collection.</p></li>
<li><p>Shows how to use an embedding collection in a DLRM model with the Criteo dataset for training and evaluation.
The notebook shows two different ETPS as reference.</p></li>
</ul>
</div>
<div class="section" id="concepts-and-api-reference">
<h2>Concepts and API Reference<a class="headerlink" href="#concepts-and-api-reference" title="Permalink to this headline"></a></h2>
<p>The following key classes and configuration file are used in this notebook:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">hugectr.EmbeddingTableConfig</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">hugectr.EmbeddingPlanner</span></code></p></li>
<li><p>JSON plan file for the ETPS</p></li>
</ul>
<p>For the concepts and API reference information about the classes and file, see the <a class="reference external" href="https://nvidia-merlin.github.io/HugeCTR/master/api/hugectr_layer_book.html#overview-of-using-the-hugectr-embedding-collection">Overview of Using the HugeCTR Embedding Collection</a> in the HugeCTR Layer Classes and Methods information.</p>
</div>
<div class="section" id="setup">
<h2>Setup<a class="headerlink" href="#setup" title="Permalink to this headline"></a></h2>
<p>To setup the environment, refer to <span class="xref myst">README</span> and follow the instructions there before running the following.</p>
</div>
<div class="section" id="use-an-embedding-collection-with-a-dlrm-model">
<h2>Use an Embedding Collection with a DLRM Model<a class="headerlink" href="#use-an-embedding-collection-with-a-dlrm-model" title="Permalink to this headline"></a></h2>
<div class="section" id="data-preparation">
<h3>Data Preparation<a class="headerlink" href="#data-preparation" title="Permalink to this headline"></a></h3>
<p>To download and prepare the dataset we will be doing the following steps. At the end of this cell, we provide the shell commands you can run on the terminal to get the data ready for this notebook.</p>
<p><strong>Note</strong>: If you already have the data downloaded, then skip to the preprocessing step (2). If preprocessing is also done, skip to creating the softlink between the processed data to the <code class="docutils literal notranslate"><span class="pre">notebooks/</span></code> directory (3).</p>
<ol class="arabic simple">
<li><p>Download the Criteo dataset</p></li>
</ol>
<p>To preprocess the downloaded Kaggle Criteo dataset, we’ll make the following operations:</p>
<ul class="simple">
<li><p>Reduce the amounts of data to speed up the preprocessing</p></li>
<li><p>Fill missing values</p></li>
<li><p>Remove the feature values whose occurrences are very rare, etc.</p></li>
</ul>
<ol class="arabic" start="2">
<li><p>Preprocessing by Pandas:</p>
<p>Meanings of the command line arguments:</p>
<ul class="simple">
<li><p>The 1st argument represents the dataset postfix. It is <code class="docutils literal notranslate"><span class="pre">1</span></code> here since <code class="docutils literal notranslate"><span class="pre">day_1</span></code> is used.</p></li>
<li><p>The 2nd argument <code class="docutils literal notranslate"><span class="pre">wdl_data</span></code> is where the preprocessed data is stored.</p></li>
<li><p>The 3rd argument <code class="docutils literal notranslate"><span class="pre">pandas</span></code> is the processing script going to use, here we choose <code class="docutils literal notranslate"><span class="pre">pandas</span></code>.</p></li>
<li><p>The 4th argument <code class="docutils literal notranslate"><span class="pre">1</span></code> embodies that the normalization is applied to dense features.</p></li>
<li><p>The 5th argument <code class="docutils literal notranslate"><span class="pre">1</span></code> means that the feature crossing is applied.</p></li>
<li><p>The 6th argument <code class="docutils literal notranslate"><span class="pre">100</span></code> means the number of data files in each file list.</p></li>
</ul>
<p>For more details about the data preprocessing, please refer to the “Preprocess the Criteo Dataset” section of the README in the <a class="reference external" href="https://github.com/NVIDIA-Merlin/HugeCTR/tree/master/samples/criteo">samples/criteo</a> directory of the repository on GitHub.</p>
</li>
<li><p>Create a soft link of the dataset folder to the path of this notebook</p></li>
</ol>
<div class="section" id="run-the-following-commands-on-the-terminal-to-prepare-the-data-for-this-notebook">
<h4>Run the following commands on the terminal to prepare the data for this notebook<a class="headerlink" href="#run-the-following-commands-on-the-terminal-to-prepare-the-data-for-this-notebook" title="Permalink to this headline"></a></h4>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">export</span> <span class="nv">project_root</span><span class="o">=</span>/home/hugectr <span class="c1"># set this to the directory where hugectr is downloaded</span>
<span class="nb">cd</span> <span class="si">${</span><span class="nv">project_root</span><span class="si">}</span>/tools
<span class="c1"># Step 1</span>
wget https://storage.googleapis.com/criteo-cail-datasets/day_0.gz
<span class="c1">#Step 2</span>
bash preprocess.sh <span class="m">0</span> deepfm_data_nvt nvt <span class="m">1</span> <span class="m">0</span> <span class="m">0</span>
<span class="c1">#Step 3</span>
ln -s <span class="si">${</span><span class="nv">project_root</span><span class="si">}</span>/tools/deepfm_data_nvt <span class="si">${</span><span class="nv">project_root</span><span class="si">}</span>/notebooks/deepfm_data_nvt
</pre></div>
</div>
</div>
</div>
<div class="section" id="prepare-the-training-script">
<h3>Prepare the Training Script<a class="headerlink" href="#prepare-the-training-script" title="Permalink to this headline"></a></h3>
<p>This notebook was developed with on single DGX-1 to run the DLRM model in this notebook. The GPU info in DGX-1 is as follows. It consists of 8 V100-SXM2 GPUs.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span> nvidia-smi
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Thu Jun 23 00:14:56 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.6     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |
| N/A   33C    P0    42W / 300W |      0MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |
| N/A   35C    P0    45W / 300W |      0MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |
| N/A   36C    P0    44W / 300W |      0MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |
| N/A   33C    P0    42W / 300W |      0MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |
| N/A   36C    P0    44W / 300W |      0MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |
| N/A   35C    P0    42W / 300W |      0MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |
| N/A   36C    P0    44W / 300W |      0MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |
| N/A   34C    P0    41W / 300W |      0MiB / 16160MiB |      0%      Default |
|                               |                      |                  N/A |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|  No running processes found                                                 |
+-----------------------------------------------------------------------------+
</pre></div>
</div>
</div>
</div>
<p>The training script, <code class="docutils literal notranslate"><span class="pre">dlrm_train.py</span></code>, uses the the embedding collection API.
The script accepts one command-line argument that specifies the plan file so we can run the script several times and evaluate different ETPS:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%%writefile</span> dlrm_train.py
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">hugectr</span>

<span class="n">plan_file</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
<span class="n">slot_size_array</span> <span class="o">=</span> <span class="p">[</span><span class="mi">203931</span><span class="p">,</span> <span class="mi">18598</span><span class="p">,</span> <span class="mi">14092</span><span class="p">,</span> <span class="mi">7012</span><span class="p">,</span> <span class="mi">18977</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6385</span><span class="p">,</span> <span class="mi">1245</span><span class="p">,</span> <span class="mi">49</span><span class="p">,</span>
                   <span class="mi">186213</span><span class="p">,</span> <span class="mi">71328</span><span class="p">,</span> <span class="mi">67288</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">2168</span><span class="p">,</span> <span class="mi">7338</span><span class="p">,</span> <span class="mi">61</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">932</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span>
                   <span class="mi">204515</span><span class="p">,</span> <span class="mi">141526</span><span class="p">,</span> <span class="mi">199433</span><span class="p">,</span> <span class="mi">60919</span><span class="p">,</span> <span class="mi">9137</span><span class="p">,</span> <span class="mi">71</span><span class="p">,</span> <span class="mi">34</span><span class="p">]</span>

<span class="n">solver</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">CreateSolver</span><span class="p">(</span>
    <span class="n">max_eval_batches</span><span class="o">=</span><span class="mi">70</span><span class="p">,</span>
    <span class="n">batchsize_eval</span><span class="o">=</span><span class="mi">65536</span><span class="p">,</span>
    <span class="n">batchsize</span><span class="o">=</span><span class="mi">65536</span><span class="p">,</span>
    <span class="n">lr</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span>
    <span class="n">warmup_steps</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span>
    <span class="n">vvgpu</span><span class="o">=</span><span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">7</span><span class="p">]],</span>
    <span class="n">repeat_dataset</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">i64_input_key</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">metrics_spec</span><span class="o">=</span><span class="p">{</span><span class="n">hugectr</span><span class="o">.</span><span class="n">MetricsType</span><span class="o">.</span><span class="n">AverageLoss</span><span class="p">:</span> <span class="mf">0.0</span><span class="p">},</span>
    <span class="n">use_embedding_collection</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">reader</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">DataReaderParams</span><span class="p">(</span>
    <span class="n">data_reader_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DataReaderType_t</span><span class="o">.</span><span class="n">Parquet</span><span class="p">,</span>
    <span class="n">source</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;./deepfm_data_nvt/train/_file_list.txt&quot;</span><span class="p">],</span>
    <span class="n">eval_source</span><span class="o">=</span><span class="s2">&quot;./deepfm_data_nvt/val/_file_list.txt&quot;</span><span class="p">,</span>
    <span class="n">check_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Check_t</span><span class="o">.</span><span class="n">Non</span><span class="p">,</span>
    <span class="n">slot_size_array</span><span class="o">=</span><span class="n">slot_size_array</span>
<span class="p">)</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">CreateOptimizer</span><span class="p">(</span>
    <span class="n">optimizer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Optimizer_t</span><span class="o">.</span><span class="n">SGD</span><span class="p">,</span>
    <span class="n">update_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Update_t</span><span class="o">.</span><span class="n">Local</span><span class="p">,</span>
    <span class="n">atomic_update</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Model</span><span class="p">(</span><span class="n">solver</span><span class="p">,</span> <span class="n">reader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span>
        <span class="n">label_dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">label_name</span><span class="o">=</span><span class="s2">&quot;label&quot;</span><span class="p">,</span>
        <span class="n">dense_dim</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span>
        <span class="n">dense_name</span><span class="o">=</span><span class="s2">&quot;dense&quot;</span><span class="p">,</span>
        <span class="n">data_reader_sparse_param_array</span><span class="o">=</span><span class="p">[</span>
            <span class="n">hugectr</span><span class="o">.</span><span class="n">DataReaderSparseParam</span><span class="p">(</span><span class="s2">&quot;data</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">slot_size_array</span><span class="p">))</span>
        <span class="p">],</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># Create the embedding table.</span>
<span class="n">embedding_table_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">slot_size_array</span><span class="p">)):</span>
    <span class="n">embedding_table_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">hugectr</span><span class="o">.</span><span class="n">EmbeddingTableConfig</span><span class="p">(</span>
            <span class="n">table_id</span><span class="o">=</span><span class="n">i</span><span class="p">,</span>
            <span class="n">max_vocabulary_size</span><span class="o">=</span><span class="n">slot_size_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">ev_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
            <span class="n">min_key</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">max_key</span><span class="o">=</span><span class="n">slot_size_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
        <span class="p">)</span>
    <span class="p">)</span>

<span class="c1"># Create the embedding planner and embedding collection.</span>
<span class="n">embedding_planner</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">EmbeddingPlanner</span><span class="p">()</span>
<span class="n">emb_vec_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">slot_size_array</span><span class="p">)):</span>
    <span class="n">embedding_planner</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span>
        <span class="n">table_config</span><span class="o">=</span><span class="n">embedding_table_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
        <span class="n">bottom_name</span><span class="o">=</span><span class="s2">&quot;data</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span>
        <span class="n">top_name</span><span class="o">=</span><span class="s2">&quot;emb_vec</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">),</span>
        <span class="n">combiner</span><span class="o">=</span><span class="s2">&quot;sum&quot;</span>
    <span class="p">)</span>

<span class="n">embedding_collection</span> <span class="o">=</span> <span class="n">embedding_planner</span><span class="o">.</span><span class="n">create_embedding_collection</span><span class="p">(</span><span class="n">plan_file</span><span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">embedding_collection</span><span class="p">)</span>
<span class="c1"># need concat</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">Concat</span><span class="p">,</span>
        <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;emb_vec</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">slot_size_array</span><span class="p">))],</span>
        <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;sparse_embedding1&quot;</span><span class="p">],</span>
        <span class="n">axis</span><span class="o">=</span><span class="mi">1</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">InnerProduct</span><span class="p">,</span>
        <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;dense&quot;</span><span class="p">],</span>
        <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;fc1&quot;</span><span class="p">],</span>
        <span class="n">num_output</span><span class="o">=</span><span class="mi">512</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;fc1&quot;</span><span class="p">],</span> <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;relu1&quot;</span><span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">InnerProduct</span><span class="p">,</span>
        <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;relu1&quot;</span><span class="p">],</span>
        <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;fc2&quot;</span><span class="p">],</span>
        <span class="n">num_output</span><span class="o">=</span><span class="mi">256</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;fc2&quot;</span><span class="p">],</span> <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;relu2&quot;</span><span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">InnerProduct</span><span class="p">,</span>
        <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;relu2&quot;</span><span class="p">],</span>
        <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;fc3&quot;</span><span class="p">],</span>
        <span class="n">num_output</span><span class="o">=</span><span class="mi">128</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;fc3&quot;</span><span class="p">],</span> <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;relu3&quot;</span><span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">Interaction</span><span class="p">,</span>  <span class="c1"># interaction only support 3-D input</span>
        <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;relu3&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse_embedding1&quot;</span><span class="p">],</span>
        <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;interaction1&quot;</span><span class="p">],</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">InnerProduct</span><span class="p">,</span>
        <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;interaction1&quot;</span><span class="p">],</span>
        <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;fc4&quot;</span><span class="p">],</span>
        <span class="n">num_output</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;fc4&quot;</span><span class="p">],</span> <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;relu4&quot;</span><span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">InnerProduct</span><span class="p">,</span>
        <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;relu4&quot;</span><span class="p">],</span>
        <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;fc5&quot;</span><span class="p">],</span>
        <span class="n">num_output</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;fc5&quot;</span><span class="p">],</span> <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;relu5&quot;</span><span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">InnerProduct</span><span class="p">,</span>
        <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;relu5&quot;</span><span class="p">],</span>
        <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;fc6&quot;</span><span class="p">],</span>
        <span class="n">num_output</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;fc6&quot;</span><span class="p">],</span> <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;relu6&quot;</span><span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">InnerProduct</span><span class="p">,</span>
        <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;relu6&quot;</span><span class="p">],</span>
        <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;fc7&quot;</span><span class="p">],</span>
        <span class="n">num_output</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span> <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;fc7&quot;</span><span class="p">],</span> <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;relu7&quot;</span><span class="p">]</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">InnerProduct</span><span class="p">,</span>
        <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;relu7&quot;</span><span class="p">],</span>
        <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;fc8&quot;</span><span class="p">],</span>
        <span class="n">num_output</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">BinaryCrossEntropyLoss</span><span class="p">,</span>
        <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;fc8&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">],</span>
        <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">],</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span>
    <span class="n">display</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">eval_interval</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">snapshot</span><span class="o">=</span><span class="mi">10000000</span><span class="p">,</span>
    <span class="n">snapshot_prefix</span><span class="o">=</span><span class="s2">&quot;dlrm&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Overwriting dlrm_train.py
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="embedding-table-placement-strategy-data-parallel-and-model-parallel">
<h3>Embedding Table Placement Strategy: Data Parallel and Model Parallel<a class="headerlink" href="#embedding-table-placement-strategy-data-parallel-and-model-parallel" title="Permalink to this headline"></a></h3>
<p>The following <code class="docutils literal notranslate"><span class="pre">generate_plan()</span></code> function shows how to configure small tables as data parallel and use model parallel for larger tables.
Each table is on single GPU and different GPU will hold different table—the same way we work with data in <code class="docutils literal notranslate"><span class="pre">hugectr.LocalizedHashEmbedding</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">print_plan</span><span class="p">(</span><span class="n">plan</span><span class="p">):</span>
    <span class="k">for</span> <span class="nb">id</span><span class="p">,</span> <span class="n">single_gpu_plan</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">plan</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;single_gpu_plan index = </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">id</span><span class="p">))</span>
        <span class="k">for</span> <span class="n">plan_attr</span> <span class="ow">in</span> <span class="n">single_gpu_plan</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">plan_attr</span><span class="p">:</span>
                <span class="k">if</span> <span class="n">key</span> <span class="o">!=</span> <span class="s2">&quot;global_embedding_list&quot;</span><span class="p">:</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="si">{}</span><span class="s2">:</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">plan_attr</span><span class="p">[</span><span class="n">key</span><span class="p">]))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">prefix_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">key</span><span class="p">)</span>
                    <span class="n">left_space_fill</span> <span class="o">=</span> <span class="s2">&quot; &quot;</span> <span class="o">*</span> <span class="n">prefix_len</span>
                    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="si">{}</span><span class="s2">:</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">plan_attr</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
                    <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">plan_attr</span><span class="p">[</span><span class="n">key</span><span class="p">])):</span>
                        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\t</span><span class="si">{}</span><span class="s2">:</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">left_space_fill</span><span class="p">,</span> <span class="n">plan_attr</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="n">index</span><span class="p">]))</span>


<span class="k">def</span> <span class="nf">generate_plan</span><span class="p">(</span><span class="n">slot_size_array</span><span class="p">,</span> <span class="n">gpu_count</span><span class="p">,</span> <span class="n">plan_file</span><span class="p">):</span>

    <span class="n">mp_table</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">slot_size_array</span><span class="p">))</span> <span class="k">if</span> <span class="n">slot_size_array</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">6000</span><span class="p">]</span>
    <span class="n">dp_table</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">slot_size_array</span><span class="p">))</span> <span class="k">if</span> <span class="n">slot_size_array</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">6000</span><span class="p">]</span>

    <span class="c1"># Place the table across all GPUs.</span>
    <span class="n">plan</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">gpu_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">gpu_count</span><span class="p">):</span>
        <span class="n">single_gpu_plan</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">mp_plan</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;local_embedding_list&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="n">table_id</span>
                <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">table_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">mp_table</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="n">gpu_count</span> <span class="o">==</span> <span class="n">gpu_id</span>
            <span class="p">],</span>
            <span class="s2">&quot;table_placement_strategy&quot;</span><span class="p">:</span> <span class="s2">&quot;mp&quot;</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">dp_plan</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;local_embedding_list&quot;</span><span class="p">:</span> <span class="n">dp_table</span><span class="p">,</span> <span class="s2">&quot;table_placement_strategy&quot;</span><span class="p">:</span> <span class="s2">&quot;dp&quot;</span><span class="p">}</span>
        <span class="n">single_gpu_plan</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">mp_plan</span><span class="p">)</span>
        <span class="n">single_gpu_plan</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">dp_plan</span><span class="p">)</span>
        <span class="n">plan</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">single_gpu_plan</span><span class="p">)</span>

    <span class="c1"># Generate the global view of table placement.</span>
    <span class="n">mp_global_embedding_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">dp_global_embedding_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">single_gpu_plan</span> <span class="ow">in</span> <span class="n">plan</span><span class="p">:</span>
        <span class="n">mp_global_embedding_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">single_gpu_plan</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;local_embedding_list&quot;</span><span class="p">])</span>
        <span class="n">dp_global_embedding_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">single_gpu_plan</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s2">&quot;local_embedding_list&quot;</span><span class="p">])</span>
    <span class="k">for</span> <span class="n">single_gpu_plan</span> <span class="ow">in</span> <span class="n">plan</span><span class="p">:</span>
        <span class="n">single_gpu_plan</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;global_embedding_list&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">mp_global_embedding_list</span>
        <span class="n">single_gpu_plan</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s2">&quot;global_embedding_list&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">dp_global_embedding_list</span>
    <span class="n">print_plan</span><span class="p">(</span><span class="n">plan</span><span class="p">)</span>

    <span class="c1"># Write the plan file to disk.</span>
    <span class="kn">import</span> <span class="nn">json</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">plan_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">slot_size_array</span> <span class="o">=</span> <span class="p">[</span>
    <span class="mi">203931</span><span class="p">,</span>
    <span class="mi">18598</span><span class="p">,</span>
    <span class="mi">14092</span><span class="p">,</span>
    <span class="mi">7012</span><span class="p">,</span>
    <span class="mi">18977</span><span class="p">,</span>
    <span class="mi">4</span><span class="p">,</span>
    <span class="mi">6385</span><span class="p">,</span>
    <span class="mi">1245</span><span class="p">,</span>
    <span class="mi">49</span><span class="p">,</span>
    <span class="mi">186213</span><span class="p">,</span>
    <span class="mi">71328</span><span class="p">,</span>
    <span class="mi">67288</span><span class="p">,</span>
    <span class="mi">11</span><span class="p">,</span>
    <span class="mi">2168</span><span class="p">,</span>
    <span class="mi">7338</span><span class="p">,</span>
    <span class="mi">61</span><span class="p">,</span>
    <span class="mi">4</span><span class="p">,</span>
    <span class="mi">932</span><span class="p">,</span>
    <span class="mi">15</span><span class="p">,</span>
    <span class="mi">204515</span><span class="p">,</span>
    <span class="mi">141526</span><span class="p">,</span>
    <span class="mi">199433</span><span class="p">,</span>
    <span class="mi">60919</span><span class="p">,</span>
    <span class="mi">9137</span><span class="p">,</span>
    <span class="mi">71</span><span class="p">,</span>
    <span class="mi">34</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">generate_plan</span><span class="p">(</span>
    <span class="n">slot_size_array</span><span class="o">=</span><span class="n">slot_size_array</span><span class="p">,</span>
    <span class="n">gpu_count</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">plan_file</span><span class="o">=</span><span class="s2">&quot;./dp_and_localized_plan.json&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>single_gpu_plan index = 0
	local_embedding_list:[0, 11]
	table_placement_strategy:mp
	global_embedding_list:[0, 11]
	                     :[1, 14]
	                     :[2, 19]
	                     :[3, 20]
	                     :[4, 21]
	                     :[6, 22]
	                     :[9, 23]
	                     :[10]
	local_embedding_list:[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	table_placement_strategy:dp
	global_embedding_list:[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
single_gpu_plan index = 1
	local_embedding_list:[1, 14]
	table_placement_strategy:mp
	global_embedding_list:[0, 11]
	                     :[1, 14]
	                     :[2, 19]
	                     :[3, 20]
	                     :[4, 21]
	                     :[6, 22]
	                     :[9, 23]
	                     :[10]
	local_embedding_list:[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	table_placement_strategy:dp
	global_embedding_list:[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
single_gpu_plan index = 2
	local_embedding_list:[2, 19]
	table_placement_strategy:mp
	global_embedding_list:[0, 11]
	                     :[1, 14]
	                     :[2, 19]
	                     :[3, 20]
	                     :[4, 21]
	                     :[6, 22]
	                     :[9, 23]
	                     :[10]
	local_embedding_list:[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	table_placement_strategy:dp
	global_embedding_list:[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
single_gpu_plan index = 3
	local_embedding_list:[3, 20]
	table_placement_strategy:mp
	global_embedding_list:[0, 11]
	                     :[1, 14]
	                     :[2, 19]
	                     :[3, 20]
	                     :[4, 21]
	                     :[6, 22]
	                     :[9, 23]
	                     :[10]
	local_embedding_list:[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	table_placement_strategy:dp
	global_embedding_list:[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
single_gpu_plan index = 4
	local_embedding_list:[4, 21]
	table_placement_strategy:mp
	global_embedding_list:[0, 11]
	                     :[1, 14]
	                     :[2, 19]
	                     :[3, 20]
	                     :[4, 21]
	                     :[6, 22]
	                     :[9, 23]
	                     :[10]
	local_embedding_list:[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	table_placement_strategy:dp
	global_embedding_list:[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
single_gpu_plan index = 5
	local_embedding_list:[6, 22]
	table_placement_strategy:mp
	global_embedding_list:[0, 11]
	                     :[1, 14]
	                     :[2, 19]
	                     :[3, 20]
	                     :[4, 21]
	                     :[6, 22]
	                     :[9, 23]
	                     :[10]
	local_embedding_list:[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	table_placement_strategy:dp
	global_embedding_list:[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
single_gpu_plan index = 6
	local_embedding_list:[9, 23]
	table_placement_strategy:mp
	global_embedding_list:[0, 11]
	                     :[1, 14]
	                     :[2, 19]
	                     :[3, 20]
	                     :[4, 21]
	                     :[6, 22]
	                     :[9, 23]
	                     :[10]
	local_embedding_list:[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	table_placement_strategy:dp
	global_embedding_list:[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
single_gpu_plan index = 7
	local_embedding_list:[10]
	table_placement_strategy:mp
	global_embedding_list:[0, 11]
	                     :[1, 14]
	                     :[2, 19]
	                     :[3, 20]
	                     :[4, 21]
	                     :[6, 22]
	                     :[9, 23]
	                     :[10]
	local_embedding_list:[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	table_placement_strategy:dp
	global_embedding_list:[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
	                     :[5, 7, 8, 12, 13, 15, 16, 17, 18, 24, 25]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>python3 dlrm_train.py ./dp_and_localized_plan.json
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>HugeCTR Version: 3.7
====================================================Model Init=====================================================
[HCTR][08:41:17.942][WARNING][RK0][main]: The model name is not specified when creating the solver.
[HCTR][08:41:17.942][INFO][RK0][main]: Global seed is 1323844045
[HCTR][08:41:18.400][INFO][RK0][main]: Device to NUMA mapping:
  GPU 0 -&gt;  node 0
  GPU 1 -&gt;  node 0
  GPU 2 -&gt;  node 0
  GPU 3 -&gt;  node 0
  GPU 4 -&gt;  node 1
  GPU 5 -&gt;  node 1
  GPU 6 -&gt;  node 1
  GPU 7 -&gt;  node 1
[HCTR][08:41:29.902][WARNING][RK0][main]: Peer-to-peer access cannot be fully enabled.
[HCTR][08:41:29.903][INFO][RK0][main]: Start all2all warmup
[HCTR][08:41:30.083][INFO][RK0][main]: End all2all warmup
[HCTR][08:41:30.095][INFO][RK0][main]: Using All-reduce algorithm: NCCL
[HCTR][08:41:30.097][INFO][RK0][main]: Device 0: Tesla V100-SXM2-16GB
[HCTR][08:41:30.097][INFO][RK0][main]: Device 1: Tesla V100-SXM2-16GB
[HCTR][08:41:30.098][INFO][RK0][main]: Device 2: Tesla V100-SXM2-16GB
[HCTR][08:41:30.099][INFO][RK0][main]: Device 3: Tesla V100-SXM2-16GB
[HCTR][08:41:30.100][INFO][RK0][main]: Device 4: Tesla V100-SXM2-16GB
[HCTR][08:41:30.100][INFO][RK0][main]: Device 5: Tesla V100-SXM2-16GB
[HCTR][08:41:30.101][INFO][RK0][main]: Device 6: Tesla V100-SXM2-16GB
[HCTR][08:41:30.102][INFO][RK0][main]: Device 7: Tesla V100-SXM2-16GB
[HCTR][08:41:30.103][INFO][RK0][main]: num of DataReader workers: 8
[HCTR][08:41:30.133][DEBUG][RK0][tid #140397011531520]: file_name_ deepfm_data_nvt/train/1.c7b6f2423fec47ff97a09ec95f6346f9.parquet file_total_rows_ 4585117
[HCTR][08:41:30.133][DEBUG][RK0][tid #140397774890752]: file_name_ deepfm_data_nvt/train/5.c5b89db1e82d4842998d560796eab838.parquet file_total_rows_ 4583901
[HCTR][08:41:30.140][DEBUG][RK0][tid #140397783283456]: file_name_ deepfm_data_nvt/train/4.4f7e95ed8f9b4bcc9b63c5f3278e6905.parquet file_total_rows_ 4580476
[HCTR][08:41:30.140][DEBUG][RK0][tid #140394788546304]: file_name_ deepfm_data_nvt/train/6.92133f3ee3664684854969202958122f.parquet file_total_rows_ 4581782
[HCTR][08:41:30.140][DEBUG][RK0][tid #140406197053184]: file_name_ deepfm_data_nvt/train/2.6b134d3f8f0a4f0d9453f1d7c08f74d5.parquet file_total_rows_ 4584304
[HCTR][08:41:30.140][DEBUG][RK0][tid #140397829383936]: file_name_ deepfm_data_nvt/train/3.4b192542e2ad4cc8b745feb142d1878a.parquet file_total_rows_ 4581022
[HCTR][08:41:30.140][DEBUG][RK0][tid #140394780153600]: file_name_ deepfm_data_nvt/train/7.9345ade3421b40a5803f518c48ae436f.parquet file_total_rows_ 4589169
[HCTR][08:41:30.141][DEBUG][RK0][tid #140397003138816]: file_name_ deepfm_data_nvt/train/0.1738817c5c5c47dba75a428d0837cbc3.parquet file_total_rows_ 4586722
[HCTR][08:41:30.155][INFO][RK0][main]: Vocabulary size: 1221286
[HCTR][08:41:30.156][DEBUG][RK0][tid #140394662721280]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:41:30.156][DEBUG][RK0][tid #140394520110848]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:41:30.156][DEBUG][RK0][tid #140394654328576]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:41:30.156][DEBUG][RK0][tid #140394528503552]: [HCTR][08:41:30.156][DEBUG][RK0][tid #140394645935872]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:41:30.156][DEBUG][RK0][tid #140394394285824]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:41:30.174][DEBUG][RK0][tid #140394511718144]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:41:30.179][DEBUG][RK0][tid #140394385893120]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:41:30.767][INFO][RK0][main]: Graph analysis to resolve tensor dependency
===================================================Model Compile===================================================
===================================================Model Summary===================================================
[HCTR][08:42:08.060][INFO][RK0][main]: label                                   Dense                         Sparse                        
label                                   dense                          data0,data1,data2,data3,data4,data5,data6,data7,data8,data9,data10,data11,data12,data13,data14,data15,data16,data17,data18,data19,data20,data21,data22,data23,data24,data25
(None, 1)                               (None, 13)                              
——————————————————————————————————————————————————————————————————————————————————————————————————————————————————
Layer Type                              Input Name                    Output Name                   Output Shape                  
——————————————————————————————————————————————————————————————————————————————————————————————————————————————————
EmbeddingCollection                     data0                         emb_vec0                      (None, 1, 128)                
                                        data1                         emb_vec1                      (None, 1, 128)                
                                        data2                         emb_vec2                      (None, 1, 128)                
                                        data3                         emb_vec3                      (None, 1, 128)                
                                        data4                         emb_vec4                      (None, 1, 128)                
                                        data5                         emb_vec5                      (None, 1, 128)                
                                        data6                         emb_vec6                      (None, 1, 128)                
                                        data7                         emb_vec7                      (None, 1, 128)                
                                        data8                         emb_vec8                      (None, 1, 128)                
                                        data9                         emb_vec9                      (None, 1, 128)                
                                        data10                        emb_vec10                     (None, 1, 128)                
                                        data11                        emb_vec11                     (None, 1, 128)                
                                        data12                        emb_vec12                     (None, 1, 128)                
                                        data13                        emb_vec13                     (None, 1, 128)                
                                        data14                        emb_vec14                     (None, 1, 128)                
                                        data15                        emb_vec15                     (None, 1, 128)                
                                        data16                        emb_vec16                     (None, 1, 128)                
                                        data17                        emb_vec17                     (None, 1, 128)                
                                        data18                        emb_vec18                     (None, 1, 128)                
                                        data19                        emb_vec19                     (None, 1, 128)                
                                        data20                        emb_vec20                     (None, 1, 128)                
                                        data21                        emb_vec21                     (None, 1, 128)                
                                        data22                        emb_vec22                     (None, 1, 128)                
                                        data23                        emb_vec23                     (None, 1, 128)                
                                        data24                        emb_vec24                     (None, 1, 128)                
                                        data25                        emb_vec25                     (None, 1, 128)                
------------------------------------------------------------------------------------------------------------------
Concat                                  emb_vec0                      sparse_embedding1             (None, 26, 128)               
                                        emb_vec1                                                                                  
                                        emb_vec2                                                                                  
                                        emb_vec3                                                                                  
                                        emb_vec4                                                                                  
                                        emb_vec5                                                                                  
                                        emb_vec6                                                                                  
                                        emb_vec7                                                                                  
                                        emb_vec8                                                                                  
                                        emb_vec9                                                                                  
                                        emb_vec10                                                                                 
                                        emb_vec11                                                                                 
                                        emb_vec12                                                                                 
                                        emb_vec13                                                                                 
                                        emb_vec14                                                                                 
                                        emb_vec15                                                                                 
                                        emb_vec16                                                                                 
                                        emb_vec17                                                                                 
                                        emb_vec18                                                                                 
                                        emb_vec19                                                                                 
                                        emb_vec20                                                                                 
                                        emb_vec21                                                                                 
                                        emb_vec22                                                                                 
                                        emb_vec23                                                                                 
                                        emb_vec24                                                                                 
                                        emb_vec25                                                                                 
------------------------------------------------------------------------------------------------------------------
InnerProduct                            dense                         fc1                           (None, 512)                   
------------------------------------------------------------------------------------------------------------------
ReLU                                    fc1                           relu1                         (None, 512)                   
------------------------------------------------------------------------------------------------------------------
InnerProduct                            relu1                         fc2                           (None, 256)                   
------------------------------------------------------------------------------------------------------------------
ReLU                                    fc2                           relu2                         (None, 256)                   
------------------------------------------------------------------------------------------------------------------
InnerProduct                            relu2                         fc3                           (None, 128)                   
------------------------------------------------------------------------------------------------------------------
ReLU                                    fc3                           relu3                         (None, 128)                   
------------------------------------------------------------------------------------------------------------------
Interaction                             relu3                         interaction1                  (None, 480)                   
                                        sparse_embedding1                                                                         
------------------------------------------------------------------------------------------------------------------
InnerProduct                            interaction1                  fc4                           (None, 1024)                  
------------------------------------------------------------------------------------------------------------------
ReLU                                    fc4                           relu4                         (None, 1024)                  
------------------------------------------------------------------------------------------------------------------
InnerProduct                            relu4                         fc5                           (None, 1024)                  
------------------------------------------------------------------------------------------------------------------
ReLU                                    fc5                           relu5                         (None, 1024)                  
------------------------------------------------------------------------------------------------------------------
InnerProduct                            relu5                         fc6                           (None, 512)                   
------------------------------------------------------------------------------------------------------------------
ReLU                                    fc6                           relu6                         (None, 512)                   
------------------------------------------------------------------------------------------------------------------
InnerProduct                            relu6                         fc7                           (None, 256)                   
------------------------------------------------------------------------------------------------------------------
ReLU                                    fc7                           relu7                         (None, 256)                   
------------------------------------------------------------------------------------------------------------------
InnerProduct                            relu7                         fc8                           (None, 1)                     
------------------------------------------------------------------------------------------------------------------
BinaryCrossEntropyLoss                  fc8                           loss                                                        
                                        label                                                                                     
------------------------------------------------------------------------------------------------------------------
=====================================================Model Fit=====================================================
[HCTR][08:42:08.061][INFO][RK0][main]: Use non-epoch mode with number of iterations: 1000
[HCTR][08:42:08.061][INFO][RK0][main]: Training batchsize: 65536, evaluation batchsize: 65536
[HCTR][08:42:08.061][INFO][RK0][main]: Evaluation interval: 100, snapshot interval: 10000000
[HCTR][08:42:08.061][INFO][RK0][main]: Dense network trainable: True
[HCTR][08:42:08.061][INFO][RK0][main]: Use mixed precision: False, scaler: 1.000000, use cuda graph: True
[HCTR][08:42:08.061][INFO][RK0][main]: lr: 0.500000, warmup_steps: 300, end_lr: 0.000000
[HCTR][08:42:08.061][INFO][RK0][main]: decay_start: 0, decay_steps: 1, decay_power: 2.000000
[HCTR][08:42:08.061][INFO][RK0][main]: Training source file: ./deepfm_data_nvt/train/_file_list.txt
[HCTR][08:42:08.061][INFO][RK0][main]: Evaluation source file: ./deepfm_data_nvt/val/_file_list.txt
[HCTR][08:42:16.322][INFO][RK0][main]: Iter: 100 Time(100 iters): 8.19237s Loss: 0.140113 lr:0.168333
[HCTR][08:42:18.453][DEBUG][RK0][tid #140394662721280]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:42:18.491][DEBUG][RK0][tid #140394654328576]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:42:18.534][DEBUG][RK0][tid #140394645935872]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:42:18.572][DEBUG][RK0][tid #140394528503552]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:42:18.610][DEBUG][RK0][tid #140394520110848]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:42:18.651][DEBUG][RK0][tid #140394511718144]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:42:18.684][DEBUG][RK0][tid #140394394285824]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:42:18.720][DEBUG][RK0][tid #140394385893120]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:42:18.957][INFO][RK0][main]: Evaluation, AverageLoss: 0.141261
[HCTR][08:42:18.957][INFO][RK0][main]: Eval Time for 70 iters: 2.63429s
[HCTR][08:42:27.041][INFO][RK0][main]: Iter: 200 Time(100 iters): 10.6496s Loss: 0.142313 lr:0.335
[HCTR][08:42:29.077][DEBUG][RK0][tid #140394662721280]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:42:29.115][DEBUG][RK0][tid #140394654328576]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:42:29.157][DEBUG][RK0][tid #140394645935872]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:42:29.195][DEBUG][RK0][tid #140394528503552]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:42:29.237][DEBUG][RK0][tid #140394520110848]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:42:29.275][DEBUG][RK0][tid #140394511718144]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:42:29.312][DEBUG][RK0][tid #140394394285824]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:42:29.351][DEBUG][RK0][tid #140394385893120]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:42:29.532][INFO][RK0][main]: Evaluation, AverageLoss: 0.141891
[HCTR][08:42:29.532][INFO][RK0][main]: Eval Time for 70 iters: 2.4907s
[HCTR][08:42:37.639][INFO][RK0][main]: Iter: 300 Time(100 iters): 10.5395s Loss: 0.154403 lr:0.5
[HCTR][08:42:39.748][DEBUG][RK0][tid #140394662721280]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:42:39.785][DEBUG][RK0][tid #140394654328576]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:42:39.824][DEBUG][RK0][tid #140394645935872]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:42:39.862][DEBUG][RK0][tid #140394528503552]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:42:39.905][DEBUG][RK0][tid #140394520110848]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:42:39.952][DEBUG][RK0][tid #140394511718144]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:42:39.987][DEBUG][RK0][tid #140394394285824]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:42:40.021][DEBUG][RK0][tid #140394385893120]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:42:40.125][INFO][RK0][main]: Evaluation, AverageLoss: 0.147726
[HCTR][08:42:40.125][INFO][RK0][main]: Eval Time for 70 iters: 2.48534s
[HCTR][08:42:48.262][INFO][RK0][main]: Iter: 400 Time(100 iters): 10.5647s Loss: 0.141461 lr:0.5
[HCTR][08:42:50.199][DEBUG][RK0][tid #140394662721280]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:42:50.274][DEBUG][RK0][tid #140394645935872]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:42:50.311][DEBUG][RK0][tid #140394528503552]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:42:50.462][DEBUG][RK0][tid #140394385893120]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:42:50.533][DEBUG][RK0][tid #140394654328576]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:42:50.638][DEBUG][RK0][tid #140394520110848]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:42:50.675][DEBUG][RK0][tid #140394511718144]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:42:50.714][DEBUG][RK0][tid #140394394285824]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:42:50.788][INFO][RK0][main]: Evaluation, AverageLoss: 0.140187
[HCTR][08:42:50.788][INFO][RK0][main]: Eval Time for 70 iters: 2.52533s
[HCTR][08:42:58.948][INFO][RK0][main]: Iter: 500 Time(100 iters): 10.605s Loss: 0.142035 lr:0.5
[HCTR][08:43:00.914][DEBUG][RK0][tid #140394662721280]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:43:00.951][DEBUG][RK0][tid #140394654328576]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:43:00.990][DEBUG][RK0][tid #140394645935872]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:43:01.023][DEBUG][RK0][tid #140394528503552]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:43:01.057][DEBUG][RK0][tid #140394520110848]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:43:01.094][DEBUG][RK0][tid #140394511718144]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:43:01.127][DEBUG][RK0][tid #140394394285824]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:43:01.163][DEBUG][RK0][tid #140394385893120]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:43:01.403][INFO][RK0][main]: Evaluation, AverageLoss: 0.140354
[HCTR][08:43:01.403][INFO][RK0][main]: Eval Time for 70 iters: 2.45442s
[HCTR][08:43:04.871][DEBUG][RK0][tid #140397003138816]: file_name_ deepfm_data_nvt/train/0.1738817c5c5c47dba75a428d0837cbc3.parquet file_total_rows_ 4586722
[HCTR][08:43:04.951][DEBUG][RK0][tid #140397011531520]: file_name_ deepfm_data_nvt/train/1.c7b6f2423fec47ff97a09ec95f6346f9.parquet file_total_rows_ 4585117
[HCTR][08:43:05.031][DEBUG][RK0][tid #140406197053184]: file_name_ deepfm_data_nvt/train/2.6b134d3f8f0a4f0d9453f1d7c08f74d5.parquet file_total_rows_ 4584304
[HCTR][08:43:05.111][DEBUG][RK0][tid #140397829383936]: file_name_ deepfm_data_nvt/train/3.4b192542e2ad4cc8b745feb142d1878a.parquet file_total_rows_ 4581022
[HCTR][08:43:05.192][DEBUG][RK0][tid #140397783283456]: file_name_ deepfm_data_nvt/train/4.4f7e95ed8f9b4bcc9b63c5f3278e6905.parquet file_total_rows_ 4580476
[HCTR][08:43:05.274][DEBUG][RK0][tid #140397774890752]: file_name_ deepfm_data_nvt/train/5.c5b89db1e82d4842998d560796eab838.parquet file_total_rows_ 4583901
[HCTR][08:43:05.354][DEBUG][RK0][tid #140394788546304]: file_name_ deepfm_data_nvt/train/6.92133f3ee3664684854969202958122f.parquet file_total_rows_ 4581782
[HCTR][08:43:06.072][DEBUG][RK0][tid #140394780153600]: file_name_ deepfm_data_nvt/train/7.9345ade3421b40a5803f518c48ae436f.parquet file_total_rows_ 4589169
[HCTR][08:43:09.539][INFO][RK0][main]: Iter: 600 Time(100 iters): 10.5255s Loss: 0.140006 lr:0.5
[HCTR][08:43:11.577][DEBUG][RK0][tid #140394662721280]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:43:11.615][DEBUG][RK0][tid #140394654328576]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:43:11.653][DEBUG][RK0][tid #140394645935872]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:43:11.690][DEBUG][RK0][tid #140394528503552]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:43:11.734][DEBUG][RK0][tid #140394520110848]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:43:11.780][DEBUG][RK0][tid #140394511718144]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:43:11.813][DEBUG][RK0][tid #140394394285824]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:43:11.851][DEBUG][RK0][tid #140394385893120]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:43:12.020][INFO][RK0][main]: Evaluation, AverageLoss: 0.141187
[HCTR][08:43:12.020][INFO][RK0][main]: Eval Time for 70 iters: 2.4811s
[HCTR][08:43:20.138][INFO][RK0][main]: Iter: 700 Time(100 iters): 10.5241s Loss: 0.143169 lr:0.5
[HCTR][08:43:22.305][DEBUG][RK0][tid #140394662721280]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:43:22.343][DEBUG][RK0][tid #140394654328576]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:43:22.382][DEBUG][RK0][tid #140394645935872]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:43:22.420][DEBUG][RK0][tid #140394528503552]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:43:22.463][DEBUG][RK0][tid #140394520110848]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:43:22.507][DEBUG][RK0][tid #140394511718144]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:43:22.551][DEBUG][RK0][tid #140394394285824]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:43:22.588][DEBUG][RK0][tid #140394385893120]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:43:22.694][INFO][RK0][main]: Evaluation, AverageLoss: 0.140917
[HCTR][08:43:22.694][INFO][RK0][main]: Eval Time for 70 iters: 2.55575s
[HCTR][08:43:30.768][INFO][RK0][main]: Iter: 800 Time(100 iters): 10.5603s Loss: 0.143395 lr:0.5
[HCTR][08:43:32.698][DEBUG][RK0][tid #140394662721280]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:43:32.771][DEBUG][RK0][tid #140394645935872]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:43:32.809][DEBUG][RK0][tid #140394528503552]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:43:32.950][DEBUG][RK0][tid #140394385893120]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:43:33.023][DEBUG][RK0][tid #140394654328576]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:43:33.131][DEBUG][RK0][tid #140394520110848]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:43:33.169][DEBUG][RK0][tid #140394511718144]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:43:33.212][DEBUG][RK0][tid #140394394285824]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:43:33.292][INFO][RK0][main]: Evaluation, AverageLoss: 0.139397
[HCTR][08:43:33.292][INFO][RK0][main]: Eval Time for 70 iters: 2.52409s
[HCTR][08:43:41.361][INFO][RK0][main]: Iter: 900 Time(100 iters): 10.5237s Loss: 0.141716 lr:0.5
[HCTR][08:43:43.361][DEBUG][RK0][tid #140394662721280]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:43:43.399][DEBUG][RK0][tid #140394654328576]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:43:43.436][DEBUG][RK0][tid #140394645935872]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:43:43.474][DEBUG][RK0][tid #140394528503552]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:43:43.518][DEBUG][RK0][tid #140394520110848]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:43:43.555][DEBUG][RK0][tid #140394511718144]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:43:43.589][DEBUG][RK0][tid #140394394285824]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:43:43.626][DEBUG][RK0][tid #140394385893120]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:43:43.867][INFO][RK0][main]: Evaluation, AverageLoss: 0.141604
[HCTR][08:43:43.867][INFO][RK0][main]: Eval Time for 70 iters: 2.50584s
[HCTR][08:43:51.826][INFO][RK0][main]: Finish 1000 iterations with batchsize: 65536 in 103.76s.
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="embedding-table-placement-strategy-distributed">
<h3>Embedding Table Placement Strategy: Distributed<a class="headerlink" href="#embedding-table-placement-strategy-distributed" title="Permalink to this headline"></a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">generate_distributed_plan()</span></code> function shows how to distribute all tables across all GPUs
This strategy is similar to <code class="docutils literal notranslate"><span class="pre">hugectr.DistributedHashEmbedding</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">generate_distributed_plan</span><span class="p">(</span><span class="n">slot_size_array</span><span class="p">,</span> <span class="n">gpu_count</span><span class="p">,</span> <span class="n">plan_file</span><span class="p">):</span>
    <span class="c1"># Place the table across all GPUs.</span>
    <span class="n">plan</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">gpu_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">gpu_count</span><span class="p">):</span>
        <span class="n">distributed_plan</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;local_embedding_list&quot;</span><span class="p">:</span> <span class="p">[</span>
                <span class="n">table_id</span> <span class="k">for</span> <span class="n">table_id</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">slot_size_array</span><span class="p">))</span>
            <span class="p">],</span>
            <span class="s2">&quot;table_placement_strategy&quot;</span><span class="p">:</span> <span class="s2">&quot;mp&quot;</span><span class="p">,</span>
            <span class="s2">&quot;shard_id&quot;</span><span class="p">:</span> <span class="n">gpu_id</span><span class="p">,</span>
            <span class="s2">&quot;shards_count&quot;</span><span class="p">:</span> <span class="n">gpu_count</span><span class="p">,</span>
        <span class="p">}</span>
        <span class="n">plan</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="n">distributed_plan</span><span class="p">])</span>

    <span class="c1"># Generate the global view of table placement.</span>
    <span class="n">distributed_global_embedding_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">single_gpu_plan</span> <span class="ow">in</span> <span class="n">plan</span><span class="p">:</span>
        <span class="n">distributed_global_embedding_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">single_gpu_plan</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;local_embedding_list&quot;</span><span class="p">]</span>
        <span class="p">)</span>
    <span class="k">for</span> <span class="n">single_gpu_plan</span> <span class="ow">in</span> <span class="n">plan</span><span class="p">:</span>
        <span class="n">single_gpu_plan</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s2">&quot;global_embedding_list&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">distributed_global_embedding_list</span>
    <span class="n">print_plan</span><span class="p">(</span><span class="n">plan</span><span class="p">)</span>

    <span class="c1"># Write the plan file to disk.</span>
    <span class="kn">import</span> <span class="nn">json</span>
    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">plan_file</span><span class="p">,</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">plan</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">slot_size_array</span> <span class="o">=</span> <span class="p">[</span>
    <span class="mi">203931</span><span class="p">,</span>
    <span class="mi">18598</span><span class="p">,</span>
    <span class="mi">14092</span><span class="p">,</span>
    <span class="mi">7012</span><span class="p">,</span>
    <span class="mi">18977</span><span class="p">,</span>
    <span class="mi">4</span><span class="p">,</span>
    <span class="mi">6385</span><span class="p">,</span>
    <span class="mi">1245</span><span class="p">,</span>
    <span class="mi">49</span><span class="p">,</span>
    <span class="mi">186213</span><span class="p">,</span>
    <span class="mi">71328</span><span class="p">,</span>
    <span class="mi">67288</span><span class="p">,</span>
    <span class="mi">11</span><span class="p">,</span>
    <span class="mi">2168</span><span class="p">,</span>
    <span class="mi">7338</span><span class="p">,</span>
    <span class="mi">61</span><span class="p">,</span>
    <span class="mi">4</span><span class="p">,</span>
    <span class="mi">932</span><span class="p">,</span>
    <span class="mi">15</span><span class="p">,</span>
    <span class="mi">204515</span><span class="p">,</span>
    <span class="mi">141526</span><span class="p">,</span>
    <span class="mi">199433</span><span class="p">,</span>
    <span class="mi">60919</span><span class="p">,</span>
    <span class="mi">9137</span><span class="p">,</span>
    <span class="mi">71</span><span class="p">,</span>
    <span class="mi">34</span><span class="p">,</span>
<span class="p">]</span>

<span class="n">generate_distributed_plan</span><span class="p">(</span>
    <span class="n">slot_size_array</span><span class="o">=</span><span class="n">slot_size_array</span><span class="p">,</span>
    <span class="n">gpu_count</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span>
    <span class="n">plan_file</span><span class="o">=</span><span class="s2">&quot;./distributed_plan.json&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>single_gpu_plan index = 0
	local_embedding_list:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	table_placement_strategy:mp
	shard_id:0
	shards_count:8
	global_embedding_list:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
single_gpu_plan index = 1
	local_embedding_list:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	table_placement_strategy:mp
	shard_id:1
	shards_count:8
	global_embedding_list:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
single_gpu_plan index = 2
	local_embedding_list:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	table_placement_strategy:mp
	shard_id:2
	shards_count:8
	global_embedding_list:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
single_gpu_plan index = 3
	local_embedding_list:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	table_placement_strategy:mp
	shard_id:3
	shards_count:8
	global_embedding_list:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
single_gpu_plan index = 4
	local_embedding_list:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	table_placement_strategy:mp
	shard_id:4
	shards_count:8
	global_embedding_list:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
single_gpu_plan index = 5
	local_embedding_list:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	table_placement_strategy:mp
	shard_id:5
	shards_count:8
	global_embedding_list:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
single_gpu_plan index = 6
	local_embedding_list:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	table_placement_strategy:mp
	shard_id:6
	shards_count:8
	global_embedding_list:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
single_gpu_plan index = 7
	local_embedding_list:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	table_placement_strategy:mp
	shard_id:7
	shards_count:8
	global_embedding_list:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
	                     :[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>python3 dlrm_train.py ./distributed_plan.json
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>HugeCTR Version: 3.7
====================================================Model Init=====================================================
[HCTR][08:44:05.384][WARNING][RK0][main]: The model name is not specified when creating the solver.
[HCTR][08:44:05.384][INFO][RK0][main]: Global seed is 1510630763
[HCTR][08:44:05.843][INFO][RK0][main]: Device to NUMA mapping:
  GPU 0 -&gt;  node 0
  GPU 1 -&gt;  node 0
  GPU 2 -&gt;  node 0
  GPU 3 -&gt;  node 0
  GPU 4 -&gt;  node 1
  GPU 5 -&gt;  node 1
  GPU 6 -&gt;  node 1
  GPU 7 -&gt;  node 1
[HCTR][08:44:17.340][WARNING][RK0][main]: Peer-to-peer access cannot be fully enabled.
[HCTR][08:44:17.341][INFO][RK0][main]: Start all2all warmup
[HCTR][08:44:17.532][INFO][RK0][main]: End all2all warmup
[HCTR][08:44:17.544][INFO][RK0][main]: Using All-reduce algorithm: NCCL
[HCTR][08:44:17.545][INFO][RK0][main]: Device 0: Tesla V100-SXM2-16GB
[HCTR][08:44:17.546][INFO][RK0][main]: Device 1: Tesla V100-SXM2-16GB
[HCTR][08:44:17.547][INFO][RK0][main]: Device 2: Tesla V100-SXM2-16GB
[HCTR][08:44:17.548][INFO][RK0][main]: Device 3: Tesla V100-SXM2-16GB
[HCTR][08:44:17.548][INFO][RK0][main]: Device 4: Tesla V100-SXM2-16GB
[HCTR][08:44:17.549][INFO][RK0][main]: Device 5: Tesla V100-SXM2-16GB
[HCTR][08:44:17.550][INFO][RK0][main]: Device 6: Tesla V100-SXM2-16GB
[HCTR][08:44:17.551][INFO][RK0][main]: Device 7: Tesla V100-SXM2-16GB
[HCTR][08:44:17.552][INFO][RK0][main]: num of DataReader workers: 8
[HCTR][08:44:17.578][DEBUG][RK0][tid #139614253741824]: file_name_ deepfm_data_nvt/train/0.1738817c5c5c47dba75a428d0837cbc3.parquet file_total_rows_ 4586722
[HCTR][08:44:17.578][DEBUG][RK0][tid #139614119524096]: file_name_ deepfm_data_nvt/train/6.92133f3ee3664684854969202958122f.parquet file_total_rows_ 4581782
[HCTR][08:44:17.579][DEBUG][RK0][tid #139614371174144]: file_name_ deepfm_data_nvt/train/1.c7b6f2423fec47ff97a09ec95f6346f9.parquet file_total_rows_ 4585117
[HCTR][08:44:17.579][DEBUG][RK0][tid #139618506761984]: file_name_ deepfm_data_nvt/train/2.6b134d3f8f0a4f0d9453f1d7c08f74d5.parquet file_total_rows_ 4584304
[HCTR][08:44:17.579][DEBUG][RK0][tid #139614505387776]: file_name_ deepfm_data_nvt/train/3.4b192542e2ad4cc8b745feb142d1878a.parquet file_total_rows_ 4581022
[HCTR][08:44:17.579][DEBUG][RK0][tid #139614387959552]: file_name_ deepfm_data_nvt/train/4.4f7e95ed8f9b4bcc9b63c5f3278e6905.parquet file_total_rows_ 4580476
[HCTR][08:44:17.579][DEBUG][RK0][tid #139614111131392]: file_name_ deepfm_data_nvt/train/7.9345ade3421b40a5803f518c48ae436f.parquet file_total_rows_ 4589169
[HCTR][08:44:17.583][INFO][RK0][main]: Vocabulary size: 1221286
[HCTR][08:44:17.583][DEBUG][RK0][tid #139614379566848]: file_name_ deepfm_data_nvt/train/5.c5b89db1e82d4842998d560796eab838.parquet file_total_rows_ 4583901
[HCTR][08:44:17.583][DEBUG][RK0][tid #139614102738688]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:44:17.583][DEBUG][RK0][tid #139609623230208]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:44:17.583][DEBUG][RK0][tid #139609614837504]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:44:17.583][DEBUG][RK0][tid #139609606444800]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:44:17.583][DEBUG][RK0][tid #139609220577024]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:44:17.583][DEBUG][RK0][tid #139609212184320]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:44:17.584][DEBUG][RK0][tid #139609203791616]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:44:17.584][DEBUG][RK0][tid #139609086359296]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:44:18.246][INFO][RK0][main]: Graph analysis to resolve tensor dependency
===================================================Model Compile===================================================
===================================================Model Summary===================================================
[HCTR][08:44:55.511][INFO][RK0][main]: label                                   Dense                         Sparse                        
label                                   dense                          data0,data1,data2,data3,data4,data5,data6,data7,data8,data9,data10,data11,data12,data13,data14,data15,data16,data17,data18,data19,data20,data21,data22,data23,data24,data25
(None, 1)                               (None, 13)                              
——————————————————————————————————————————————————————————————————————————————————————————————————————————————————
Layer Type                              Input Name                    Output Name                   Output Shape                  
——————————————————————————————————————————————————————————————————————————————————————————————————————————————————
EmbeddingCollection                     data0                         emb_vec0                      (None, 1, 128)                
                                        data1                         emb_vec1                      (None, 1, 128)                
                                        data2                         emb_vec2                      (None, 1, 128)                
                                        data3                         emb_vec3                      (None, 1, 128)                
                                        data4                         emb_vec4                      (None, 1, 128)                
                                        data5                         emb_vec5                      (None, 1, 128)                
                                        data6                         emb_vec6                      (None, 1, 128)                
                                        data7                         emb_vec7                      (None, 1, 128)                
                                        data8                         emb_vec8                      (None, 1, 128)                
                                        data9                         emb_vec9                      (None, 1, 128)                
                                        data10                        emb_vec10                     (None, 1, 128)                
                                        data11                        emb_vec11                     (None, 1, 128)                
                                        data12                        emb_vec12                     (None, 1, 128)                
                                        data13                        emb_vec13                     (None, 1, 128)                
                                        data14                        emb_vec14                     (None, 1, 128)                
                                        data15                        emb_vec15                     (None, 1, 128)                
                                        data16                        emb_vec16                     (None, 1, 128)                
                                        data17                        emb_vec17                     (None, 1, 128)                
                                        data18                        emb_vec18                     (None, 1, 128)                
                                        data19                        emb_vec19                     (None, 1, 128)                
                                        data20                        emb_vec20                     (None, 1, 128)                
                                        data21                        emb_vec21                     (None, 1, 128)                
                                        data22                        emb_vec22                     (None, 1, 128)                
                                        data23                        emb_vec23                     (None, 1, 128)                
                                        data24                        emb_vec24                     (None, 1, 128)                
                                        data25                        emb_vec25                     (None, 1, 128)                
------------------------------------------------------------------------------------------------------------------
Concat                                  emb_vec0                      sparse_embedding1             (None, 26, 128)               
                                        emb_vec1                                                                                  
                                        emb_vec2                                                                                  
                                        emb_vec3                                                                                  
                                        emb_vec4                                                                                  
                                        emb_vec5                                                                                  
                                        emb_vec6                                                                                  
                                        emb_vec7                                                                                  
                                        emb_vec8                                                                                  
                                        emb_vec9                                                                                  
                                        emb_vec10                                                                                 
                                        emb_vec11                                                                                 
                                        emb_vec12                                                                                 
                                        emb_vec13                                                                                 
                                        emb_vec14                                                                                 
                                        emb_vec15                                                                                 
                                        emb_vec16                                                                                 
                                        emb_vec17                                                                                 
                                        emb_vec18                                                                                 
                                        emb_vec19                                                                                 
                                        emb_vec20                                                                                 
                                        emb_vec21                                                                                 
                                        emb_vec22                                                                                 
                                        emb_vec23                                                                                 
                                        emb_vec24                                                                                 
                                        emb_vec25                                                                                 
------------------------------------------------------------------------------------------------------------------
InnerProduct                            dense                         fc1                           (None, 512)                   
------------------------------------------------------------------------------------------------------------------
ReLU                                    fc1                           relu1                         (None, 512)                   
------------------------------------------------------------------------------------------------------------------
InnerProduct                            relu1                         fc2                           (None, 256)                   
------------------------------------------------------------------------------------------------------------------
ReLU                                    fc2                           relu2                         (None, 256)                   
------------------------------------------------------------------------------------------------------------------
InnerProduct                            relu2                         fc3                           (None, 128)                   
------------------------------------------------------------------------------------------------------------------
ReLU                                    fc3                           relu3                         (None, 128)                   
------------------------------------------------------------------------------------------------------------------
Interaction                             relu3                         interaction1                  (None, 480)                   
                                        sparse_embedding1                                                                         
------------------------------------------------------------------------------------------------------------------
InnerProduct                            interaction1                  fc4                           (None, 1024)                  
------------------------------------------------------------------------------------------------------------------
ReLU                                    fc4                           relu4                         (None, 1024)                  
------------------------------------------------------------------------------------------------------------------
InnerProduct                            relu4                         fc5                           (None, 1024)                  
------------------------------------------------------------------------------------------------------------------
ReLU                                    fc5                           relu5                         (None, 1024)                  
------------------------------------------------------------------------------------------------------------------
InnerProduct                            relu5                         fc6                           (None, 512)                   
------------------------------------------------------------------------------------------------------------------
ReLU                                    fc6                           relu6                         (None, 512)                   
------------------------------------------------------------------------------------------------------------------
InnerProduct                            relu6                         fc7                           (None, 256)                   
------------------------------------------------------------------------------------------------------------------
ReLU                                    fc7                           relu7                         (None, 256)                   
------------------------------------------------------------------------------------------------------------------
InnerProduct                            relu7                         fc8                           (None, 1)                     
------------------------------------------------------------------------------------------------------------------
BinaryCrossEntropyLoss                  fc8                           loss                                                        
                                        label                                                                                     
------------------------------------------------------------------------------------------------------------------
=====================================================Model Fit=====================================================
[HCTR][08:44:55.512][INFO][RK0][main]: Use non-epoch mode with number of iterations: 1000
[HCTR][08:44:55.512][INFO][RK0][main]: Training batchsize: 65536, evaluation batchsize: 65536
[HCTR][08:44:55.512][INFO][RK0][main]: Evaluation interval: 100, snapshot interval: 10000000
[HCTR][08:44:55.512][INFO][RK0][main]: Dense network trainable: True
[HCTR][08:44:55.512][INFO][RK0][main]: Use mixed precision: False, scaler: 1.000000, use cuda graph: True
[HCTR][08:44:55.512][INFO][RK0][main]: lr: 0.500000, warmup_steps: 300, end_lr: 0.000000
[HCTR][08:44:55.512][INFO][RK0][main]: decay_start: 0, decay_steps: 1, decay_power: 2.000000
[HCTR][08:44:55.512][INFO][RK0][main]: Training source file: ./deepfm_data_nvt/train/_file_list.txt
[HCTR][08:44:55.512][INFO][RK0][main]: Evaluation source file: ./deepfm_data_nvt/val/_file_list.txt
[HCTR][08:45:11.057][INFO][RK0][main]: Iter: 100 Time(100 iters): 15.3926s Loss: 0.144649 lr:0.168333
[HCTR][08:45:14.328][DEBUG][RK0][tid #139614102738688]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:45:14.386][DEBUG][RK0][tid #139609623230208]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:45:14.444][DEBUG][RK0][tid #139609614837504]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:45:14.503][DEBUG][RK0][tid #139609606444800]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:45:14.562][DEBUG][RK0][tid #139609220577024]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:45:14.620][DEBUG][RK0][tid #139609212184320]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:45:14.677][DEBUG][RK0][tid #139609203791616]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:45:14.736][DEBUG][RK0][tid #139609086359296]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:45:15.139][INFO][RK0][main]: Evaluation, AverageLoss: 0.146034
[HCTR][08:45:15.139][INFO][RK0][main]: Eval Time for 70 iters: 4.08247s
[HCTR][08:45:30.553][INFO][RK0][main]: Iter: 200 Time(100 iters): 19.4961s Loss: 0.149704 lr:0.335
[HCTR][08:45:33.943][DEBUG][RK0][tid #139614102738688]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:45:34.001][DEBUG][RK0][tid #139609623230208]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:45:34.060][DEBUG][RK0][tid #139609614837504]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:45:34.118][DEBUG][RK0][tid #139609606444800]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:45:34.177][DEBUG][RK0][tid #139609220577024]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:45:34.235][DEBUG][RK0][tid #139609212184320]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:45:34.292][DEBUG][RK0][tid #139609203791616]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:45:34.350][DEBUG][RK0][tid #139609086359296]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:45:34.645][INFO][RK0][main]: Evaluation, AverageLoss: 0.146364
[HCTR][08:45:34.645][INFO][RK0][main]: Eval Time for 70 iters: 4.09159s
[HCTR][08:45:50.040][INFO][RK0][main]: Iter: 300 Time(100 iters): 19.3843s Loss: 0.158335 lr:0.5
[HCTR][08:45:53.544][DEBUG][RK0][tid #139614102738688]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:45:53.603][DEBUG][RK0][tid #139609623230208]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:45:53.660][DEBUG][RK0][tid #139609614837504]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:45:53.720][DEBUG][RK0][tid #139609606444800]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:45:53.778][DEBUG][RK0][tid #139609220577024]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:45:53.836][DEBUG][RK0][tid #139609212184320]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:45:53.894][DEBUG][RK0][tid #139609203791616]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:45:53.953][DEBUG][RK0][tid #139609086359296]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:45:54.121][INFO][RK0][main]: Evaluation, AverageLoss: 0.148422
[HCTR][08:45:54.121][INFO][RK0][main]: Eval Time for 70 iters: 4.08104s
[HCTR][08:46:09.558][INFO][RK0][main]: Iter: 400 Time(100 iters): 19.5178s Loss: 0.139716 lr:0.5
[HCTR][08:46:12.751][DEBUG][RK0][tid #139614102738688]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:46:12.868][DEBUG][RK0][tid #139609614837504]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:46:12.926][DEBUG][RK0][tid #139609606444800]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:46:13.164][DEBUG][RK0][tid #139609086359296]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:46:13.280][DEBUG][RK0][tid #139609623230208]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:46:13.457][DEBUG][RK0][tid #139609220577024]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:46:13.514][DEBUG][RK0][tid #139609212184320]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:46:13.574][DEBUG][RK0][tid #139609203791616]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:46:13.683][INFO][RK0][main]: Evaluation, AverageLoss: 0.139018
[HCTR][08:46:13.683][INFO][RK0][main]: Eval Time for 70 iters: 4.12495s
[HCTR][08:46:29.073][INFO][RK0][main]: Iter: 500 Time(100 iters): 19.4974s Loss: 0.139979 lr:0.5
[HCTR][08:46:32.347][DEBUG][RK0][tid #139614102738688]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:46:32.403][DEBUG][RK0][tid #139609623230208]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:46:32.462][DEBUG][RK0][tid #139609614837504]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:46:32.521][DEBUG][RK0][tid #139609606444800]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:46:32.579][DEBUG][RK0][tid #139609220577024]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:46:32.637][DEBUG][RK0][tid #139609212184320]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:46:32.696][DEBUG][RK0][tid #139609203791616]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:46:32.754][DEBUG][RK0][tid #139609086359296]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:46:33.157][INFO][RK0][main]: Evaluation, AverageLoss: 0.138041
[HCTR][08:46:33.157][INFO][RK0][main]: Eval Time for 70 iters: 4.08385s
[HCTR][08:46:39.671][DEBUG][RK0][tid #139614253741824]: file_name_ deepfm_data_nvt/train/0.1738817c5c5c47dba75a428d0837cbc3.parquet file_total_rows_ 4586722
[HCTR][08:46:39.823][DEBUG][RK0][tid #139614371174144]: file_name_ deepfm_data_nvt/train/1.c7b6f2423fec47ff97a09ec95f6346f9.parquet file_total_rows_ 4585117
[HCTR][08:46:39.973][DEBUG][RK0][tid #139618506761984]: file_name_ deepfm_data_nvt/train/2.6b134d3f8f0a4f0d9453f1d7c08f74d5.parquet file_total_rows_ 4584304
[HCTR][08:46:40.125][DEBUG][RK0][tid #139614505387776]: file_name_ deepfm_data_nvt/train/3.4b192542e2ad4cc8b745feb142d1878a.parquet file_total_rows_ 4581022
[HCTR][08:46:40.284][DEBUG][RK0][tid #139614387959552]: file_name_ deepfm_data_nvt/train/4.4f7e95ed8f9b4bcc9b63c5f3278e6905.parquet file_total_rows_ 4580476
[HCTR][08:46:40.431][DEBUG][RK0][tid #139614379566848]: file_name_ deepfm_data_nvt/train/5.c5b89db1e82d4842998d560796eab838.parquet file_total_rows_ 4583901
[HCTR][08:46:40.586][DEBUG][RK0][tid #139614119524096]: file_name_ deepfm_data_nvt/train/6.92133f3ee3664684854969202958122f.parquet file_total_rows_ 4581782
[HCTR][08:46:41.968][DEBUG][RK0][tid #139614111131392]: file_name_ deepfm_data_nvt/train/7.9345ade3421b40a5803f518c48ae436f.parquet file_total_rows_ 4589169
[HCTR][08:46:48.555][INFO][RK0][main]: Iter: 600 Time(100 iters): 19.4819s Loss: 0.134819 lr:0.5
[HCTR][08:46:51.959][DEBUG][RK0][tid #139614102738688]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:46:52.017][DEBUG][RK0][tid #139609623230208]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:46:52.075][DEBUG][RK0][tid #139609614837504]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:46:52.134][DEBUG][RK0][tid #139609606444800]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:46:52.193][DEBUG][RK0][tid #139609220577024]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:46:52.253][DEBUG][RK0][tid #139609212184320]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:46:52.313][DEBUG][RK0][tid #139609203791616]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:46:52.372][DEBUG][RK0][tid #139609086359296]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:46:52.663][INFO][RK0][main]: Evaluation, AverageLoss: 0.137611
[HCTR][08:46:52.663][INFO][RK0][main]: Eval Time for 70 iters: 4.1073s
[HCTR][08:47:08.048][INFO][RK0][main]: Iter: 700 Time(100 iters): 19.4769s Loss: 0.140394 lr:0.5
[HCTR][08:47:11.590][DEBUG][RK0][tid #139614102738688]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:47:11.647][DEBUG][RK0][tid #139609623230208]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:47:11.706][DEBUG][RK0][tid #139609614837504]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:47:11.765][DEBUG][RK0][tid #139609606444800]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:47:11.824][DEBUG][RK0][tid #139609220577024]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:47:11.881][DEBUG][RK0][tid #139609212184320]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:47:11.940][DEBUG][RK0][tid #139609203791616]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:47:11.998][DEBUG][RK0][tid #139609086359296]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:47:12.171][INFO][RK0][main]: Evaluation, AverageLoss: 0.138108
[HCTR][08:47:12.171][INFO][RK0][main]: Eval Time for 70 iters: 4.1189s
[HCTR][08:47:27.578][INFO][RK0][main]: Iter: 800 Time(100 iters): 19.5118s Loss: 0.141259 lr:0.5
[HCTR][08:47:30.764][DEBUG][RK0][tid #139614102738688]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:47:30.880][DEBUG][RK0][tid #139609614837504]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:47:30.938][DEBUG][RK0][tid #139609606444800]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:47:31.175][DEBUG][RK0][tid #139609086359296]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:47:31.292][DEBUG][RK0][tid #139609623230208]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:47:31.467][DEBUG][RK0][tid #139609220577024]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:47:31.525][DEBUG][RK0][tid #139609212184320]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:47:31.584][DEBUG][RK0][tid #139609203791616]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:47:31.692][INFO][RK0][main]: Evaluation, AverageLoss: 0.137271
[HCTR][08:47:31.692][INFO][RK0][main]: Eval Time for 70 iters: 4.11364s
[HCTR][08:47:47.105][INFO][RK0][main]: Iter: 900 Time(100 iters): 19.3756s Loss: 0.13619 lr:0.5
[HCTR][08:47:50.398][DEBUG][RK0][tid #139614102738688]: file_name_ deepfm_data_nvt/val/0.35ab81b16b4a409ba42a1baf89dcba52.parquet file_total_rows_ 571942
[HCTR][08:47:50.455][DEBUG][RK0][tid #139609623230208]: file_name_ deepfm_data_nvt/val/1.01854d707a564342aef3af44b814de1c.parquet file_total_rows_ 573919
[HCTR][08:47:50.513][DEBUG][RK0][tid #139609614837504]: file_name_ deepfm_data_nvt/val/2.7d7593c16af64625973ed246f68af624.parquet file_total_rows_ 572137
[HCTR][08:47:50.573][DEBUG][RK0][tid #139609606444800]: file_name_ deepfm_data_nvt/val/3.eec657484d40418cbf2648541592d09e.parquet file_total_rows_ 572545
[HCTR][08:47:50.631][DEBUG][RK0][tid #139609220577024]: file_name_ deepfm_data_nvt/val/4.e60c2f9421d84490bbc4de5f15ec5a0f.parquet file_total_rows_ 573664
[HCTR][08:47:50.690][DEBUG][RK0][tid #139609212184320]: file_name_ deepfm_data_nvt/val/5.883be83fecd74c1fbac00321911f2787.parquet file_total_rows_ 573448
[HCTR][08:47:50.747][DEBUG][RK0][tid #139609203791616]: file_name_ deepfm_data_nvt/val/6.0f6ed30e74dc49668d1e1011e819e9e3.parquet file_total_rows_ 573727
[HCTR][08:47:50.805][DEBUG][RK0][tid #139609086359296]: file_name_ deepfm_data_nvt/val/7.9e48c14d9bde498a8ef5d840d636d276.parquet file_total_rows_ 572680
[HCTR][08:47:51.207][INFO][RK0][main]: Evaluation, AverageLoss: 0.137273
[HCTR][08:47:51.207][INFO][RK0][main]: Eval Time for 70 iters: 4.1011s
[HCTR][08:48:06.342][INFO][RK0][main]: Finish 1000 iterations with batchsize: 65536 in 190.83s.
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="performance-comparison-for-the-different-etps">
<h3>Performance Comparison for the Different ETPS<a class="headerlink" href="#performance-comparison-for-the-different-etps" title="Permalink to this headline"></a></h3>
<p>The iteration duration for the data parallel and model parallel strategy is <code class="docutils literal notranslate"><span class="pre">103.45s</span></code>.
For the distributed strategy, the duration is <code class="docutils literal notranslate"><span class="pre">190.85s</span></code>.
This comparison shows how different ETPS can greatly affect the performance of embedding.
The results show that performance is better if you configure the embedding table as data parallel or localized when the table can fit on a single GPU.</p>
</div>
</div>
</div>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="embedding_training_cache_example.html" class="btn btn-neutral float-left" title="Embedding Training Cache Example" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="multi-modal-data/index.html" class="btn btn-neutral float-right" title="Multi-modal Example Notebooks" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: main
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../../v3.9.1/index.html">v3.9.1</a></dd>
      <dd><a href="../../v4.0/index.html">v4.0</a></dd>
      <dd><a href="../../v4.1/index.html">v4.1</a></dd>
      <dd><a href="../../v4.1.1/index.html">v4.1.1</a></dd>
      <dd><a href="../../v4.2/index.html">v4.2</a></dd>
      <dd><a href="../../v4.3/index.html">v4.3</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="embedding_collection.html">main</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NVJ1Y1YJHK', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>