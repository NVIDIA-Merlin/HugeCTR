{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03f69db2",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/notebooks/dlsw-notebooks/merlin_hugectr_hps-hps-pretrained-model-training-demo/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# HPS Pretrained Model Training Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa18650",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to use HPS to load pre-trained embedding tables. It is recommended to run [hierarchical_parameter_server_demo.ipynb](hierarchical_parameter_server_demo.ipynb) before diving into this notebook.\n",
    "\n",
    "For more details about HPS APIs, please refer to [HPS APIs](https://nvidia-merlin.github.io/HugeCTR/master/hierarchical_parameter_server/api/index.html). For more details about HPS, please refer to [HugeCTR Hierarchical Parameter Server (HPS)](https://nvidia-merlin.github.io/HugeCTR/master/hierarchical_parameter_server/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b613bc",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "### Get HPS from NGC\n",
    "\n",
    "The HPS Python module is preinstalled in the 22.12 and later [Merlin TensorFlow Container](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-hugectr): `nvcr.io/nvidia/merlin/merlin-tensorflow:22.12`.\n",
    "\n",
    "You can check the existence of the required libraries by running the following Python code after launching this container.\n",
    "\n",
    "```bash\n",
    "$ python3 -c \"import hierarchical_parameter_server as hps\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b620163",
   "metadata": {},
   "source": [
    "## Configurations\n",
    "\n",
    "First of all we specify the required configurations, e.g., the arguments needed for generating the dataset, the model parameters and the paths to save the model. We will use a deep neural network (DNN) model which has one embedding table and several dense layers. Please note that the input to the embedding layer will be a sparse key tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd774e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] hierarchical_parameter_server is imported\n"
     ]
    }
   ],
   "source": [
    "import hierarchical_parameter_server as hps\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import struct\n",
    "\n",
    "args = dict()\n",
    "\n",
    "args[\"gpu_num\"] = 4                               # the number of available GPUs\n",
    "args[\"iter_num\"] = 10                             # the number of training iteration\n",
    "args[\"slot_num\"] = 10                             # the number of feature fields in this embedding layer\n",
    "args[\"embed_vec_size\"] = 16                       # the dimension of embedding vectors\n",
    "args[\"dense_dim\"] = 10                            # the dimension of dense features\n",
    "args[\"global_batch_size\"] = 1024                  # the globally batchsize for all GPUs\n",
    "args[\"max_vocabulary_size\"] = 100000\n",
    "args[\"vocabulary_range_per_slot\"] = [[i*10000, (i+1)*10000] for i in range(10)] \n",
    "args[\"max_nnz\"] = 5                # the max number of non-zeros for all slots\n",
    "args[\"combiner\"] = \"mean\"\n",
    "\n",
    "args[\"ps_config_file\"] = \"dnn.json\"\n",
    "args[\"dense_model_path\"] = \"dnn_dense.model\"\n",
    "args[\"embedding_table_path\"] = \"dnn_sparse.model\"\n",
    "args[\"saved_path\"] = \"dnn_tf_saved_model\"\n",
    "args[\"np_key_type\"] = np.int64\n",
    "args[\"np_vector_type\"] = np.float32\n",
    "args[\"tf_key_type\"] = tf.int64\n",
    "args[\"tf_vector_type\"] = tf.float32\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(map(str, range(args[\"gpu_num\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5634498f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_samples(num_samples, vocabulary_range_per_slot, max_nnz, dense_dim):\n",
    "    def generate_sparse_keys(num_samples, vocabulary_range_per_slot, max_nnz, key_dtype = args[\"np_key_type\"]):\n",
    "        slot_num = len(vocabulary_range_per_slot)\n",
    "        indices = []\n",
    "        values = []\n",
    "        for i in range(num_samples):\n",
    "            for j in range(slot_num):\n",
    "                vocab_range = vocabulary_range_per_slot[j]\n",
    "                nnz = np.random.randint(low=1, high=max_nnz+1)\n",
    "                entries = sorted(np.random.choice(max_nnz, nnz, replace=False))\n",
    "                for entry in entries:\n",
    "                    indices.append([i, j, entry])\n",
    "                values.extend(np.random.randint(low=vocab_range[0], high=vocab_range[1], size=(nnz, )))\n",
    "        values = np.array(values, dtype=key_dtype)\n",
    "        return tf.sparse.SparseTensor(indices = indices,\n",
    "                                    values = values,\n",
    "                                    dense_shape = (num_samples, slot_num, max_nnz))\n",
    "\n",
    "    \n",
    "    sparse_keys = generate_sparse_keys(num_samples, vocabulary_range_per_slot, max_nnz)\n",
    "    dense_features = np.random.random((num_samples, dense_dim)).astype(np.float32)\n",
    "    labels = np.random.randint(low=0, high=2, size=(num_samples, 1))\n",
    "    return sparse_keys, dense_features, labels\n",
    "\n",
    "def tf_dataset(sparse_keys, dense_features, labels, batchsize):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((sparse_keys, dense_features, labels))\n",
    "    dataset = dataset.batch(batchsize, drop_remainder=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16543be1",
   "metadata": {},
   "source": [
    "## Train with native TF layers\n",
    "\n",
    "We define the model graph for training with native TF layers, i.e., `tf.nn.embedding_lookup_sparse` and `tf.keras.layers.Dense`. Besides, the embedding weights are stored in `tf.Variable`. We can then train the model and extract the trained weights of the embedding table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec5caba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(tf.keras.models.Model):\n",
    "    def __init__(self,\n",
    "                 init_tensors,\n",
    "                 combiner,\n",
    "                 embed_vec_size,\n",
    "                 slot_num,\n",
    "                 max_nnz,\n",
    "                 dense_dim,\n",
    "                 **kwargs):\n",
    "        super(DNN, self).__init__(**kwargs)\n",
    "        \n",
    "        self.combiner = combiner\n",
    "        self.embed_vec_size = embed_vec_size\n",
    "        self.slot_num = slot_num\n",
    "        self.max_nnz = max_nnz\n",
    "        self.dense_dim = dense_dim\n",
    "        self.params = tf.Variable(initial_value=tf.concat(init_tensors, axis=0))\n",
    "        self.fc1 = tf.keras.layers.Dense(units=1024, activation=\"relu\", name=\"fc1\")\n",
    "        self.fc2 = tf.keras.layers.Dense(units=256, activation=\"relu\", name=\"fc2\")\n",
    "        self.fc3 = tf.keras.layers.Dense(units=1, activation=\"sigmoid\", name=\"fc3\")\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        input_cat = inputs[0]\n",
    "        input_dense = inputs[1]\n",
    "        \n",
    "        # SparseTensor of keys, shape: (batch_size*slot_num, max_nnz)\n",
    "        embeddings = tf.reshape(tf.nn.embedding_lookup_sparse(params=self.params, sp_ids=input_cat, sp_weights = None, combiner=self.combiner),\n",
    "                                shape=[-1, self.slot_num * self.embed_vec_size])\n",
    "        concat_feas = tf.concat([embeddings, input_dense], axis=1)\n",
    "        logit = self.fc3(self.fc2(self.fc1(concat_feas)))\n",
    "        return logit, embeddings\n",
    "\n",
    "    def summary(self):\n",
    "        inputs = [tf.keras.Input(shape=(self.max_nnz, ), sparse=True, dtype=args[\"tf_key_type\"]), \n",
    "                  tf.keras.Input(shape=(self.dense_dim, ), dtype=tf.float32)]\n",
    "        model = tf.keras.models.Model(inputs=inputs, outputs=self.call(inputs))\n",
    "        return model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0cee05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    init_tensors = np.ones(shape=[args[\"max_vocabulary_size\"], args[\"embed_vec_size\"]], dtype=args[\"np_vector_type\"])\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        model = DNN(init_tensors, args[\"combiner\"], args[\"embed_vec_size\"], args[\"slot_num\"], args[\"max_nnz\"], args[\"dense_dim\"])\n",
    "        model.summary()\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)    \n",
    "\n",
    "    loss_fn = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    def _replica_loss(labels, logits):\n",
    "        loss = loss_fn(labels, logits)\n",
    "        return tf.nn.compute_average_loss(loss, global_batch_size=args[\"global_batch_size\"])\n",
    "    \n",
    "    def _reshape_input(sparse_keys):\n",
    "        sparse_keys = tf.sparse.reshape(sparse_keys, [-1, sparse_keys.shape[-1]])\n",
    "        return sparse_keys\n",
    "    \n",
    "    def _train_step(inputs, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logit, _ = model(inputs)\n",
    "            loss = _replica_loss(labels, logit)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        return logit, loss\n",
    "\n",
    "    def _dataset_fn(input_context):\n",
    "        replica_batch_size = input_context.get_per_replica_batch_size(args[\"global_batch_size\"])\n",
    "        sparse_keys, dense_features, labels = generate_random_samples(args[\"global_batch_size\"]  * args[\"iter_num\"], args[\"vocabulary_range_per_slot\"], args[\"max_nnz\"], args[\"dense_dim\"])\n",
    "        dataset = tf_dataset(sparse_keys, dense_features, labels, replica_batch_size)\n",
    "        dataset = dataset.shard(input_context.num_input_pipelines, input_context.input_pipeline_id)\n",
    "        return dataset\n",
    "\n",
    "    dataset = strategy.distribute_datasets_from_function(_dataset_fn)\n",
    "    for i, (sparse_keys, dense_features, labels) in enumerate(dataset):\n",
    "        sparse_keys = strategy.run(_reshape_input, args=(sparse_keys,))\n",
    "        inputs = [sparse_keys, dense_features]  \n",
    "        _, loss = strategy.run(_train_step, args=(inputs, labels))\n",
    "        print(\"-\"*20, \"Step {}, loss: {}\".format(i, loss),  \"-\"*20)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40d9d2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-29 06:41:55.554588: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-29 06:41:57.606412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30989 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0\n",
      "2022-07-29 06:41:57.608128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30989 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:07:00.0, compute capability: 7.0\n",
      "2022-07-29 06:41:57.609468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 30989 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0a:00.0, compute capability: 7.0\n",
      "2022-07-29 06:41:57.610818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 30989 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:0b:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_sparse), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(100000, 16) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.nn.embedding_look  (None, 16)          0           ['input_1[0][0]']                \n",
      " up_sparse (TFOpLambda)                                                                           \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 160)          0           ['tf.compat.v1.nn.embedding_looku\n",
      "                                                                 p_sparse[0][0]']                 \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)         (None, 170)          0           ['tf.reshape[0][0]',             \n",
      "                                                                  'input_2[0][0]']                \n",
      "                                                                                                  \n",
      " fc1 (Dense)                    (None, 1024)         175104      ['tf.concat[0][0]']              \n",
      "                                                                                                  \n",
      " fc2 (Dense)                    (None, 256)          262400      ['fc1[0][0]']                    \n",
      "                                                                                                  \n",
      " fc3 (Dense)                    (None, 1)            257         ['fc2[0][0]']                    \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 437,761\n",
      "Trainable params: 437,761\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "-------------------- Step 0, loss: PerReplica:{\n",
      "  0: tf.Tensor(0.1950232, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(0.20766959, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(0.2006835, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(0.21188965, shape=(), dtype=float32)\n",
      "} --------------------\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "-------------------- Step 1, loss: PerReplica:{\n",
      "  0: tf.Tensor(681.73474, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(691.33826, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(588.15265, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(622.72485, shape=(), dtype=float32)\n",
      "} --------------------\n",
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1\n",
      "WARNING:tensorflow:Efficient allreduce is not supported for 1 IndexedSlices\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:GPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3').\n",
      "-------------------- Step 2, loss: PerReplica:{\n",
      "  0: tf.Tensor(6.9260483, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(8.509967, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(7.0374002, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(7.1059036, shape=(), dtype=float32)\n",
      "} --------------------\n",
      "INFO:tensorflow:batch_all_reduce: 6 all-reduces with algorithm = nccl, num_packs = 1\n",
      "-------------------- Step 3, loss: PerReplica:{\n",
      "  0: tf.Tensor(3.002458, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(3.7079678, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(3.333396, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(3.6451607, shape=(), dtype=float32)\n",
      "} --------------------\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function _apply_all_reduce.<locals>._all_reduce at 0x7fba4c2dc1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "-------------------- Step 4, loss: PerReplica:{\n",
      "  0: tf.Tensor(0.8326673, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(0.79405844, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(0.85364443, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(0.92679256, shape=(), dtype=float32)\n",
      "} --------------------\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _apply_all_reduce.<locals>._all_reduce at 0x7fba4c2dcdc0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "-------------------- Step 5, loss: PerReplica:{\n",
      "  0: tf.Tensor(0.5796976, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(0.54752666, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(0.57471323, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(0.54845804, shape=(), dtype=float32)\n",
      "} --------------------\n",
      "-------------------- Step 6, loss: PerReplica:{\n",
      "  0: tf.Tensor(0.61678064, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(0.647662, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(0.6421599, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(0.6278339, shape=(), dtype=float32)\n",
      "} --------------------\n",
      "-------------------- Step 7, loss: PerReplica:{\n",
      "  0: tf.Tensor(0.28049487, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(0.2768654, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(0.2943622, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(0.2805586, shape=(), dtype=float32)\n",
      "} --------------------\n",
      "-------------------- Step 8, loss: PerReplica:{\n",
      "  0: tf.Tensor(1.2102679, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(1.368755, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(1.4997649, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(1.5143406, shape=(), dtype=float32)\n",
      "} --------------------\n",
      "-------------------- Step 9, loss: PerReplica:{\n",
      "  0: tf.Tensor(0.413176, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(0.42411563, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(0.38453132, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(0.4314984, shape=(), dtype=float32)\n",
      "} --------------------\n"
     ]
    }
   ],
   "source": [
    "trained_model = train(args)\n",
    "weights_list = trained_model.get_weights()\n",
    "embedding_weights = weights_list[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6075746f",
   "metadata": {},
   "source": [
    "## Load the pre-trained embeddings via HPS\n",
    "In order to use HPS to load the pre-trained embeddings, they should be converted to the formats required by HPS. After that, we can train a new model which leverages the pre-trained embeddings and only updates the weights of dense layers. Please note that  `hps.SparseLookupLayer` and ` hps.LookupLayer` are not trainable.\n",
    "\n",
    "In order to initialize the lookup service provided by HPS, we also need to create a JSON configuration file and specify the details of the embedding tables for the models to be deployed. We deploy a model that has one embedding table here, and it can support multiple models with multiple embedding tables actually. Please note how `maxnum_catfeature_query_per_table_per_sample` is specified for the embedding table: the `max_nnz` is 5 for all the slots and there are 10 slots, so this entry is configured as 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9db421b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_sparse_model(embeddings_weights, embedding_table_path, embedding_vec_size):\n",
    "    os.system(\"mkdir -p {}\".format(embedding_table_path))\n",
    "    with open(\"{}/key\".format(embedding_table_path), 'wb') as key_file, \\\n",
    "        open(\"{}/emb_vector\".format(embedding_table_path), 'wb') as vec_file:\n",
    "      for key in range(embeddings_weights.shape[0]):\n",
    "        vec = embeddings_weights[key]\n",
    "        key_struct = struct.pack('q', key)\n",
    "        vec_struct = struct.pack(str(embedding_vec_size) + \"f\", *vec)\n",
    "        key_file.write(key_struct)\n",
    "        vec_file.write(vec_struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1bfa609",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting dnn.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile dnn.json\n",
    "{\n",
    "    \"supportlonglong\": true,\n",
    "    \"models\": [{\n",
    "        \"model\": \"dnn\",\n",
    "        \"sparse_files\": [\"dnn_sparse.model\"],\n",
    "        \"num_of_worker_buffer_in_pool\": 3,\n",
    "        \"embedding_table_names\":[\"sparse_embedding0\"],\n",
    "        \"embedding_vecsize_per_table\": [16],\n",
    "        \"maxnum_catfeature_query_per_table_per_sample\": [50],\n",
    "        \"default_value_for_each_table\": [1.0],\n",
    "        \"deployed_device_list\": [0,1,2,3],\n",
    "        \"max_batch_size\": 1024,\n",
    "        \"cache_refresh_percentage_per_iteration\": 0.2,\n",
    "        \"hit_rate_threshold\": 1.0,\n",
    "        \"gpucacheper\": 1.0,\n",
    "        \"gpucache\": true\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2341b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreTrainedEmbedding(tf.keras.models.Model):\n",
    "    def __init__(self,\n",
    "                 combiner,\n",
    "                 embed_vec_size,\n",
    "                 slot_num,\n",
    "                 max_nnz,\n",
    "                 dense_dim,\n",
    "                 **kwargs):\n",
    "        super(PreTrainedEmbedding, self).__init__(**kwargs)\n",
    "        \n",
    "        self.combiner = combiner\n",
    "        self.embed_vec_size = embed_vec_size\n",
    "        self.slot_num = slot_num\n",
    "        self.max_nnz = max_nnz\n",
    "        self.dense_dim = dense_dim\n",
    "        \n",
    "        self.sparse_lookup_layer = hps.SparseLookupLayer(model_name = \"dnn\", \n",
    "                                                         table_id = 0,\n",
    "                                                         emb_vec_size = self.embed_vec_size,\n",
    "                                                         emb_vec_dtype = args[\"tf_vector_type\"])\n",
    "        # Only use one FC layer when leveraging pre-trained embeddings\n",
    "        self.new_fc = tf.keras.layers.Dense(units=1, activation=\"sigmoid\", name=\"new_fc\")\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        input_cat = inputs[0]\n",
    "        input_dense = inputs[1]\n",
    "        \n",
    "        # SparseTensor of keys, shape: (batch_size*slot_num, max_nnz)\n",
    "        embeddings = tf.reshape(self.sparse_lookup_layer(sp_ids=input_cat, sp_weights = None, combiner=self.combiner),\n",
    "                                shape=[-1, self.slot_num * self.embed_vec_size])\n",
    "        concat_feas = tf.concat([embeddings, input_dense], axis=1)\n",
    "        logit = self.new_fc(concat_feas)\n",
    "        return logit, embeddings\n",
    "\n",
    "    def summary(self):\n",
    "        inputs = [tf.keras.Input(shape=(self.max_nnz, ), sparse=True, dtype=args[\"tf_key_type\"]), \n",
    "                  tf.keras.Input(shape=(self.dense_dim, ), dtype=tf.float32)]\n",
    "        model = tf.keras.models.Model(inputs=inputs, outputs=self.call(inputs))\n",
    "        return model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a650d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_with_pretrained_embeddings(args):\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        hps.Init(global_batch_size = args[\"global_batch_size\"], ps_config_file = args[\"ps_config_file\"])\n",
    "        model = PreTrainedEmbedding(args[\"combiner\"], args[\"embed_vec_size\"], args[\"slot_num\"], args[\"max_nnz\"], args[\"dense_dim\"])\n",
    "        model.summary()\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "        \n",
    "    loss_fn = tf.keras.losses.BinaryCrossentropy(reduction=tf.keras.losses.Reduction.NONE)\n",
    "    def _replica_loss(labels, logits):\n",
    "        loss = loss_fn(labels, logits)\n",
    "        return tf.nn.compute_average_loss(loss, global_batch_size=args[\"global_batch_size\"])\n",
    "    \n",
    "    def _reshape_input(sparse_keys):\n",
    "        sparse_keys = tf.sparse.reshape(sparse_keys, [-1, sparse_keys.shape[-1]])\n",
    "        return sparse_keys\n",
    "    \n",
    "    def _train_step(inputs, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logit, _ = model(inputs)\n",
    "            loss = _replica_loss(labels, logit)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        return logit, loss\n",
    "    \n",
    "    def _dataset_fn(input_context):\n",
    "        replica_batch_size = input_context.get_per_replica_batch_size(args[\"global_batch_size\"])\n",
    "        sparse_keys, dense_features, labels = generate_random_samples(args[\"global_batch_size\"]  * args[\"iter_num\"], args[\"vocabulary_range_per_slot\"], args[\"max_nnz\"], args[\"dense_dim\"])\n",
    "        dataset = tf_dataset(sparse_keys, dense_features, labels, replica_batch_size)\n",
    "        dataset = dataset.shard(input_context.num_input_pipelines, input_context.input_pipeline_id)\n",
    "        return dataset\n",
    "\n",
    "    dataset = strategy.distribute_datasets_from_function(_dataset_fn)\n",
    "    for i, (sparse_keys, dense_features, labels) in enumerate(dataset):\n",
    "        sparse_keys = strategy.run(_reshape_input, args=(sparse_keys,))\n",
    "        inputs = [sparse_keys, dense_features]\n",
    "        _, loss = strategy.run(_train_step, args=(inputs, labels))\n",
    "        print(\"-\"*20, \"Step {}, loss: {}\".format(i, loss),  \"-\"*20)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9834f942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n",
      "=====================================================HPS Parse====================================================\n",
      "You are using the plugin with MirroredStrategy.\n",
      "[HCTR][06:42:16.707][INFO][RK0][main]: dense_file is not specified using default: \n",
      "[HCTR][06:42:16.707][INFO][RK0][main]: num_of_refresher_buffer_in_pool is not specified using default: 1\n",
      "[HCTR][06:42:16.707][INFO][RK0][main]: maxnum_des_feature_per_sample is not specified using default: 26\n",
      "[HCTR][06:42:16.707][INFO][RK0][main]: refresh_delay is not specified using default: 0\n",
      "[HCTR][06:42:16.707][INFO][RK0][main]: refresh_interval is not specified using default: 0\n",
      "====================================================HPS Create====================================================\n",
      "[HCTR][06:42:16.707][INFO][RK0][main]: Creating HashMap CPU database backend...\n",
      "[HCTR][06:42:16.707][INFO][RK0][main]: Volatile DB: initial cache rate = 1\n",
      "[HCTR][06:42:16.707][INFO][RK0][main]: Volatile DB: cache missed embeddings = 0\n",
      "[HCTR][06:42:17.153][INFO][RK0][main]: Table: hps_et.dnn.sparse_embedding0; cached 100000 / 100000 embeddings in volatile database (PreallocatedHashMapBackend); load: 100000 / 18446744073709551615 (0.00%).\n",
      "[HCTR][06:42:17.153][DEBUG][RK0][main]: Real-time subscribers created!\n",
      "[HCTR][06:42:17.153][INFO][RK0][main]: Creating embedding cache in device 0.\n",
      "[HCTR][06:42:17.160][INFO][RK0][main]: Model name: dnn\n",
      "[HCTR][06:42:17.160][INFO][RK0][main]: Number of embedding tables: 1\n",
      "[HCTR][06:42:17.160][INFO][RK0][main]: Use GPU embedding cache: True, cache size percentage: 1.000000\n",
      "[HCTR][06:42:17.160][INFO][RK0][main]: Use I64 input key: True\n",
      "[HCTR][06:42:17.160][INFO][RK0][main]: Configured cache hit rate threshold: 1.000000\n",
      "[HCTR][06:42:17.160][INFO][RK0][main]: The size of thread pool: 80\n",
      "[HCTR][06:42:17.160][INFO][RK0][main]: The size of worker memory pool: 3\n",
      "[HCTR][06:42:17.160][INFO][RK0][main]: The size of refresh memory pool: 1\n",
      "[HCTR][06:42:17.170][INFO][RK0][main]: Creating embedding cache in device 1.\n",
      "[HCTR][06:42:17.177][INFO][RK0][main]: Model name: dnn\n",
      "[HCTR][06:42:17.177][INFO][RK0][main]: Number of embedding tables: 1\n",
      "[HCTR][06:42:17.177][INFO][RK0][main]: Use GPU embedding cache: True, cache size percentage: 1.000000\n",
      "[HCTR][06:42:17.177][INFO][RK0][main]: Use I64 input key: True\n",
      "[HCTR][06:42:17.177][INFO][RK0][main]: Configured cache hit rate threshold: 1.000000\n",
      "[HCTR][06:42:17.177][INFO][RK0][main]: The size of thread pool: 80\n",
      "[HCTR][06:42:17.177][INFO][RK0][main]: The size of worker memory pool: 3\n",
      "[HCTR][06:42:17.177][INFO][RK0][main]: The size of refresh memory pool: 1\n",
      "[HCTR][06:42:17.180][INFO][RK0][main]: Creating embedding cache in device 2.\n",
      "[HCTR][06:42:17.188][INFO][RK0][main]: Model name: dnn\n",
      "[HCTR][06:42:17.188][INFO][RK0][main]: Number of embedding tables: 1\n",
      "[HCTR][06:42:17.188][INFO][RK0][main]: Use GPU embedding cache: True, cache size percentage: 1.000000\n",
      "[HCTR][06:42:17.188][INFO][RK0][main]: Use I64 input key: True\n",
      "[HCTR][06:42:17.188][INFO][RK0][main]: Configured cache hit rate threshold: 1.000000\n",
      "[HCTR][06:42:17.188][INFO][RK0][main]: The size of thread pool: 80\n",
      "[HCTR][06:42:17.188][INFO][RK0][main]: The size of worker memory pool: 3\n",
      "[HCTR][06:42:17.188][INFO][RK0][main]: The size of refresh memory pool: 1\n",
      "[HCTR][06:42:17.191][INFO][RK0][main]: Creating embedding cache in device 3.\n",
      "[HCTR][06:42:17.197][INFO][RK0][main]: Model name: dnn\n",
      "[HCTR][06:42:17.197][INFO][RK0][main]: Number of embedding tables: 1\n",
      "[HCTR][06:42:17.197][INFO][RK0][main]: Use GPU embedding cache: True, cache size percentage: 1.000000\n",
      "[HCTR][06:42:17.197][INFO][RK0][main]: Use I64 input key: True\n",
      "[HCTR][06:42:17.197][INFO][RK0][main]: Configured cache hit rate threshold: 1.000000\n",
      "[HCTR][06:42:17.197][INFO][RK0][main]: The size of thread pool: 80\n",
      "[HCTR][06:42:17.197][INFO][RK0][main]: The size of worker memory pool: 3\n",
      "[HCTR][06:42:17.197][INFO][RK0][main]: The size of refresh memory pool: 1\n",
      "[HCTR][06:42:17.300][INFO][RK0][main]: Creating lookup session for dnn on device: 0\n",
      "[HCTR][06:42:17.300][INFO][RK0][main]: Creating lookup session for dnn on device: 1\n",
      "[HCTR][06:42:17.300][INFO][RK0][main]: Creating lookup session for dnn on device: 2\n",
      "[HCTR][06:42:17.300][INFO][RK0][main]: Creating lookup session for dnn on device: 3\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 5)]          0           []                               \n",
      "                                                                                                  \n",
      " sparse_lookup_layer (SparseLoo  (None, 16)          0           ['input_3[0][0]']                \n",
      " kupLayer)                                                                                        \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)      (None, 160)          0           ['sparse_lookup_layer[0][0]']    \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)       (None, 170)          0           ['tf.reshape_1[0][0]',           \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " new_fc (Dense)                 (None, 1)            171         ['tf.concat_1[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 171\n",
      "Trainable params: 171\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "-------------------- Step 0, loss: PerReplica:{\n",
      "  0: tf.Tensor(0.17934436, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(0.17969523, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(0.18917403, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(0.18102707, shape=(), dtype=float32)\n",
      "} --------------------\n",
      "-------------------- Step 1, loss: PerReplica:{\n",
      "  0: tf.Tensor(1.7858478, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(1.68311, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(1.66279, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(1.5826445, shape=(), dtype=float32)\n",
      "} --------------------\n",
      "-------------------- Step 2, loss: PerReplica:{\n",
      "  0: tf.Tensor(0.7325904, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(0.7331751, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(0.7210605, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(0.7671325, shape=(), dtype=float32)\n",
      "} --------------------\n",
      "-------------------- Step 3, loss: PerReplica:{\n",
      "  0: tf.Tensor(0.62144834, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(0.5696643, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(0.5946336, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(0.64713424, shape=(), dtype=float32)\n",
      "} --------------------\n",
      "-------------------- Step 4, loss: PerReplica:{\n",
      "  0: tf.Tensor(0.88115656, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(0.9079187, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(0.98161024, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(0.97925556, shape=(), dtype=float32)\n",
      "} --------------------\n",
      "-------------------- Step 5, loss: PerReplica:{\n",
      "  0: tf.Tensor(0.6572284, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(0.6304919, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(0.66552734, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(0.6695935, shape=(), dtype=float32)\n",
      "} --------------------\n",
      "-------------------- Step 6, loss: PerReplica:{\n",
      "  0: tf.Tensor(0.2002374, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(0.19162768, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(0.1874283, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(0.19209734, shape=(), dtype=float32)\n",
      "} --------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Step 7, loss: PerReplica:{\n",
      "  0: tf.Tensor(0.5284709, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(0.6028371, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(0.5635803, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(0.5773235, shape=(), dtype=float32)\n",
      "} --------------------\n",
      "-------------------- Step 8, loss: PerReplica:{\n",
      "  0: tf.Tensor(0.74001855, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(0.71915305, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(0.619328, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(0.7890761, shape=(), dtype=float32)\n",
      "} --------------------\n",
      "-------------------- Step 9, loss: PerReplica:{\n",
      "  0: tf.Tensor(0.55197906, shape=(), dtype=float32),\n",
      "  1: tf.Tensor(0.5565746, shape=(), dtype=float32),\n",
      "  2: tf.Tensor(0.52792, shape=(), dtype=float32),\n",
      "  3: tf.Tensor(0.6230979, shape=(), dtype=float32)\n",
      "} --------------------\n"
     ]
    }
   ],
   "source": [
    "convert_to_sparse_model(embedding_weights, args[\"embedding_table_path\"], args[\"embed_vec_size\"])\n",
    "model = train_with_pretrained_embeddings(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
