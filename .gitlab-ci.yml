include:
#  - remote: 'https://gitlab.com/yesolutions/gitlab-ci-templates/raw/main/templates/pre-commit-autofix.yaml'
  - project: "dl/devops/gitlab-ci-slurm"
    ref: master
    file: "/.gitlab-ci.yml"
  - /ci/common.yml
  - /ci/template.yml
  - /ci/benchmark.yml
  - /ci/rules.gitlab_ci.yml

nightly_build_all:
  extends: .build_nightly
  variables:
    REMOTE_REPO: https://github.com/NVIDIA-Merlin/Merlin.git
    DST_IMAGE: ${IMAGE_ALL}
    DOCKER_FILE: dockerfile.ctr
    BUILD_ARGS: --build-arg HUGECTR_DEV_MODE=true

nightly_build_sok_tf2:
  extends: .build_nightly
  variables:
    REMOTE_REPO: https://github.com/NVIDIA-Merlin/Merlin.git
    DST_IMAGE: ${IMAGE_SOK_TF2}
    DOCKER_FILE: dockerfile.tf
    BUILD_ARGS: --build-arg HUGECTR_DEV_MODE=true

nightly_build_sok_tf1:
  extends: .build_nightly_tf1
  variables:
    DST_IMAGE: ${IMAGE_SOK_TF1}
    DOCKER_FILE: Dockerfile.sok1
    BUILD_ARGS: --build-arg HUGECTR_DEV_MODE=true

nightly_build_unified_container.tf:
  extends: .build_nightly
  variables:
    REMOTE_REPO: https://github.com/NVIDIA-Merlin/Merlin.git
    DST_IMAGE: ${CI_REGISTRY}/dl/hugectr/hugectr:unified.tf.latest
    DOCKER_FILE: dockerfile.tf
    BUILD_ARGS: --build-arg _CI_JOB_TOKEN=${RD_CI_JOB_TOKEN} --build-arg _HUGECTR_REPO=gitlab-master.nvidia.com/dl/hugectr/hugectr.git --build-arg HUGECTR_VER=${CI_COMMIT_BRANCH}

nightly_build_unified_container.ctr:
  extends: .build_nightly
  variables:
    REMOTE_REPO: https://github.com/NVIDIA-Merlin/Merlin.git
    DST_IMAGE: ${CI_REGISTRY}/dl/hugectr/hugectr:unified.ctr.latest
    DOCKER_FILE: dockerfile.ctr
    BUILD_ARGS: --build-arg _CI_JOB_TOKEN=${RD_CI_JOB_TOKEN} --build-arg _HUGECTR_REPO=gitlab-master.nvidia.com/dl/hugectr/hugectr.git --build-arg HUGECTR_VER=${CI_COMMIT_BRANCH} --build-arg _HUGECTR_BACKEND_REPO=gitlab-master.nvidia.com/dl/hugectr/hugectr_inference_backend.git --build-arg HUGECTR_BACKEND_VER=hugectr_performance_test

nightly_build_optimized:
  extends: .build_nightly
  variables:
    REMOTE_REPO: https://${RD_CI_JOB_TOKEN}gitlab-master.nvidia.com/dl/mlperf/optimized.git
    DST_IMAGE: ${IMAGE_OPTIMIZED}
    DOCKER_FILE: Dockerfile
    BUILD_ARGS: --build-arg RELEASE=false
    OPTIMIZED: 1
  rules:
    - if: $NIGHTLY_OPTIMIZED == "1"
      when: always
    - when: never

build_optimized:
  extends: .build_nightly
  variables:
    REMOTE_REPO: https://${RD_CI_JOB_TOKEN}gitlab-master.nvidia.com/dl/mlperf/optimized.git
    DST_IMAGE: ${IMAGE_OPTIMIZED}.${CI_PIPELINE_ID}
    DOCKER_FILE: Dockerfile
    BUILD_ARGS: " --build-arg GITLAB_CLONE_ACCESS_TOKEN=${GITLAB_CLONE_ACCESS_TOKEN}"
    OPTIMIZED: 1
  rules:
    - if: $NIGHTLY_OPTIMIZED == "1"
      when: always
    - when: never

### Stage: build
format_check_python:
  extends: .python_format
  variables:
    EXCLUDE: "third_party|docs|notebooks|tutorial"

format_check_clang:
  extends: .clang_format
  variables:
    EXCLUDE: ./third_party
    STYLE: file
    EXECUTABLE: clang-format14
    EXTENSIONS: "h,hpp,cpp,cu,cuh"

codespell_check:
  extends: .codespell_check
  variables:
    PRE_COM_IMAGE: registry.gitlab.com/yesolutions/docker-pre-commit

build_train_single_node:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $TRAIN_IMAGE_VERSIONED
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DSM=\"60;61;70;75;80;90;100\" -DCLANGFORMAT=OFF"
    BUILD_HUGECTR: 1
    BUILD_HUGECTR2ONNX: 1

build_train_single_node_with_hdfs_full:
  extends: .build_hugectr_daily
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $TRAIN_IMAGE_VERSIONED_WITH_HDFS
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DSM=\"60;61;70;75;80;90;100\" -DCLANGFORMAT=OFF -DENABLE_HDFS=ON"
    BUILD_HDFS: 1
    BUILD_HUGECTR: 1
    BUILD_HUGECTR2ONNX: 1

build_train_single_node_with_s3:
 extends: .build_hugectr
 variables:
   FROM_IMAGE: ${IMAGE_ALL}
   DST_IMAGE: ${TRAIN_IMAGE_VERSIONED_WITH_S3}
   CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DSM=\"60;61;70;75;80;90;100\" -DCLANGFORMAT=OFF -DENABLE_S3=ON"
   BUILD_HUGECTR: 1
   BUILD_HUGECTR2ONNX: 1

build_train_single_node_with_gcs:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: ${TRAIN_IMAGE_VERSIONED_WITH_GCS}
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DSM=\"60;61;70;75;80;90;100\" -DCLANGFORMAT=OFF -DENABLE_GCS=ON"
    BUILD_HUGECTR: 1
    BUILD_HUGECTR2ONNX: 1

build_train_multi_node:
  extends: .build_hugectr
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $TRAIN_IMAGE_MULTINODE_VERSIONED
    CMAKE_OPTION: "-DCMAKE_BUILD_TYPE=Release -DKEY_HIT_RATIO=ON -DENABLE_MULTINODES=ON -DSM=\"60;61;70;75;80;90;100\" -DCLANGFORMAT=OFF"
    BUILD_HUGECTR: 1

build_sok_tf2:
  extends: .build_sok
  variables:
    FROM_IMAGE: ${IMAGE_ALL}
    DST_IMAGE: $SOK_IMAGE_VERSIONED_TF2
    CMAKE_OPTION: "70;75;80;90;100"
    BUILD_SOK: 1

build_sok_tf1:
  extends: .build_sok
  variables:
    FROM_IMAGE: ${IMAGE_SOK_TF1}
    DST_IMAGE: $SOK_IMAGE_VERSIONED_TF1
    CMAKE_OPTION: "70;75;80;90"
    BUILD_SOK: 1

# Check cluster busy or not
check_cluster_status:
  extends: .trigger:rules:selene
  stage: pre_test
  tags:
    - nvidia.com/cuda.driver.major=470
    - $BUILD_TAG
  script:
    - docker login -u ${CI_PRIVATE_USER} -p "${CI_PRIVATE_KEY}" "${CI_REGISTRY}"
    - docker pull ${CONT}
    - RC=0
    - docker run -d --rm --name cluster_idle_${CI_PIPELINE_ID} ${EXTRA_DOCKER_RUN_ARGS} ${CONT} sleep infinity
    - docker exec cluster_idle_${CI_PIPELINE_ID} bash -cx "python get_selene_runner_status.py --quota ${SELENE_QUEUE_QUOTA} --token \"${CLUSTER_TOKEN}\" " || RC=$?
    - echo "$RC"
    - echo "NEW_CI_CONCURRENT_ID=${CI_CONCURRENT_ID}" >> other_param.env
    - if [[ $RC == 0 ]]; then
      echo "Run jobs in draco-oci cluster!";
      cp ./ci/draco-oci/ci.yml ./test-ci.yml;
      echo "NEW_SBATCH_OTHER_PARAMS=" >> other_param.env;
      else
      echo "Run jobs in other cluster!";
      cp ./ci/dracorno/ci.yml ./test-ci.yml;
      echo "NEW_SBATCH_OTHER_PARAMS=--nv-meta ml-model.hugectr --gpus-per-node=8" >> other_param.env;
      fi
    - cat other_param.env
  artifacts:
    paths:
      - ./test-ci.yml
    reports:
      dotenv: other_param.env
  variables:
    CONT: gitlab-master.nvidia.com:5005/dl/hugectr/hugectr/emma:get_selene_status_new
  allow_failure: false
  timeout: 15 minutes

trigger_test_pipeline:
  extends: .trigger:rules:selene
  stage:
    test
  needs:
    - check_cluster_status
  trigger:
    include:
      - artifact: test-ci.yml
        job: check_cluster_status
    strategy: depend
  variables:
    PARENT_SOURCE: ${CI_PIPELINE_SOURCE}
    PARENT_PIPELINE_ID: ${CI_PIPELINE_ID}
    GCS_ACCESS_FILE: ${GCS_ACCESS_FILE}
    PARENT_GCS_ACCESS_FILE: ${GCS_ACCESS_FILE}
    SBATCH_OTHER_PARAMS: ${NEW_SBATCH_OTHER_PARAMS}

criteo_multi_node:
  extends: .cluster_test_job_daily
  needs:
    - build_train_multi_node
  variables:
    CONT: $TRAIN_IMAGE_MULTINODE_VERSIONED
    MOUNTS: ${DRACO_OCI_DATASET}:${DATASET_MOUNT}
    CI_SLURM_TIME: "00:15:00"
    CI_SLURM_NODES: 2
    SLURM_JOB_NUM_NODES: 2
    TEST_CMD: ./ci/integration_test/criteo/criteo_multi_node.sub

dlrm_dcnv2_benchmark_8node:
  extends: .cluster_test_job_daily
  needs:
    - build_train_multi_node
  variables:
    CONT: $TRAIN_IMAGE_MULTINODE_VERSIONED
    MOUNTS: /lustre/fsw/portfolios/coreai/projects/coreai_devtech_all/hugectr/hpc-hugectr/dlrm/datasets/criteo_multihot_raw:/data,/lustre/fsw/portfolios/coreai/projects/coreai_devtech_all/hugectr/hpc-hugectr/dlrm/datasets/criteo_multihot_raw:/data_val
    CI_SLURM_TIME: "02:00:00"
    CI_SLURM_NODES: 8
    SLURM_JOB_NUM_NODES: 8
    TEST_CMD: ./ci/integration_test/dlrm/train_dcnv2_8node.sub

wdl_multi_gpu:
  extends: .cluster_test_job_daily                                                     # test on selene needs to extend .cluster_test_job
  needs:
    - build_train_single_node
  variables:
    CONT: $TRAIN_IMAGE_VERSIONED                                                 # image name
    MOUNTS: ${DRACO_OCI_DATASET_NEW_CRITEO}:${DATASET_MOUNT}                                          # mount
    CI_SLURM_TIME: "00:15:00"                                                         # estimate job time. Less time, higher priority
    TEST_CMD: ./ci/integration_test/wdl/wdl_daily.sub

deepfm_multi_gpu:
  extends: .cluster_test_job_daily
  needs:
    - build_train_single_node
  variables:
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS: ${DRACO_OCI_DATASET}:${DATASET_MOUNT}
    CI_SLURM_TIME: "00:15:00"
    TEST_CMD: ./ci/integration_test/deepfm/deepfm_daily.sub

dcn_multi_node:
  extends: .cluster_test_job_daily
  needs:
    - build_train_multi_node
  variables:
    CONT: $TRAIN_IMAGE_MULTINODE_VERSIONED
    MOUNTS: ${DRACO_OCI_DATASET}:${DATASET_MOUNT}
    CI_SLURM_TIME: "01:00:00"
    CI_SLURM_NODES: 4
    SLURM_JOB_NUM_NODES: 4
    TEST_CMD: ./ci/integration_test/dcn/dcn_multi_node.sub

ebc_single_node:
  extends: .cluster_test_job_daily
  needs:
    - build_train_single_node
  variables:
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS: ${DRACO_OCI_DATASET_NEW_CRITEO}:${DATASET_MOUNT},/raid:/raid
    CI_SLURM_TIME: "02:00:00"
    TEST_CMD: ./ci/integration_test/ebc/ebc.sub

test_sok_pypi:
  extends: .cluster_test_job_daily
  needs:
    - build_sok_tf2
  variables:
    CONT: $SOK_IMAGE_VERSIONED_TF2
    CI_SLURM_TIME: "00:30:00"
    TEST_CMD: ./ci/integration_test/sok/test_sok_pypi.sub

hdfs_backend_test:
  extends: .computelab_test_job_daily
  needs:
    - build_train_single_node_with_hdfs_full
  script:
    - export CONT=${TRAIN_IMAGE_VERSIONED_WITH_HDFS}
    - bash ./ci/integration_test/hdfs/hdfs_backend_test.sh

wdl_check:
  # Push logs to gitlab
  extends: .cluster_post_test_job_daily
  needs:
    - wdl_multi_gpu
  variables:
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS:  ${DRACO_OCI_LOGDIR}/wdl_multi_gpu:/logs
    CI_SLURM_TIME: "00:15:00"
    TEST_CMD: ./ci/post_test/check_wdl.sub

dlrm_dcnv2_8node_check:
  # Push logs to gitlab
  extends: .cluster_post_test_job_daily
  needs:
    - dlrm_dcnv2_benchmark_8node
  variables:
    CONT: $TRAIN_IMAGE_VERSIONED
    MOUNTS: ${DRACO_OCI_LOGDIR}/dlrm_dcnv2_benchmark_8node:/logs
    CI_SLURM_TIME: "00:15:00"
    TEST_CMD: ./ci/post_test/check_dcnv2_dlrm_8node.sub

