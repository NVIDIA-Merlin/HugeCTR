<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Introduction to HugeCTR &mdash; Merlin HugeCTR  documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
      <link rel="stylesheet" type="text/css" href="_static/css/custom.css" />

  
    <link rel="canonical" href="https://nvidia-merlin.github.io/HugeCTR/main/hugectr_user_guide.html" />
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="HugeCTR Core Features" href="hugectr_core_features.html" />
    <link rel="prev" title="Merlin HugeCTR" href="index.html" /> 
</head>

<body class="wy-body-for-nav">
  <div class="banner">
    <p class="banner">
      Since the HugeCTR <code>v23.09</code>, the offline inference has been deprecated.
      Since the HugeCTR <code>v24.06</code>, the HPS has been deprecated.
  </div>

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            Merlin HugeCTR
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">HUGECTR</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="hugectr_core_features.html">Core Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="hugectr_embedding_training_cache.html">Embedding Training Cache</a></li>
<li class="toctree-l1"><a class="reference internal" href="hierarchical_parameter_server/index.html">Hierarchical Parameter Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse_operation_kit.html">Sparse Operation Kit</a></li>
<li class="toctree-l1"><a class="reference internal" href="performance.html">Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/index.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="notebooks/multi-modal-data/index.html">Multi-modal Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="api/index.html">API Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="additional_resources.html">Additional Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="hugectr_contributor_guide.html">Contributing to HugeCTR</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Merlin HugeCTR</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Introduction to HugeCTR</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="introduction-to-hugectr">
<h1>Introduction to HugeCTR<a class="headerlink" href="#introduction-to-hugectr" title="Permalink to this heading"></a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#about-hugectr" id="id1">About HugeCTR</a></p></li>
<li><p><a class="reference internal" href="#installing-and-building-hugectr" id="id2">Installing and Building HugeCTR</a></p>
<ul>
<li><p><a class="reference internal" href="#compute-capability" id="id3">Compute Capability</a></p></li>
<li><p><a class="reference internal" href="#installing-hugectr-using-ngc-containers" id="id4">Installing HugeCTR Using NGC Containers</a></p></li>
<li><p><a class="reference internal" href="#building-hugectr-from-scratch" id="id5">Building HugeCTR from Scratch</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#tools" id="id6">Tools</a></p>
<ul>
<li><p><a class="reference internal" href="#generating-synthetic-data-and-benchmarks" id="id7">Generating Synthetic Data and Benchmarks</a></p></li>
<li><p><a class="reference internal" href="#downloading-and-preprocessing-datasets" id="id8">Downloading and Preprocessing Datasets</a></p></li>
</ul>
</li>
</ul>
</nav>
<section id="about-hugectr">
<h2>About HugeCTR<a class="headerlink" href="#about-hugectr" title="Permalink to this heading"></a></h2>
<p>HugeCTR is a GPU-accelerated framework designed to distribute training across multiple GPUs and nodes and estimate click-through rates (CTRs). HugeCTR supports model-parallel embedding tables and data-parallel neural networks and their variants such as <a class="reference external" href="https://arxiv.org/abs/1606.07792">Wide and Deep Learning (WDL)</a>, <a class="reference external" href="https://arxiv.org/abs/1708.05123">Deep Cross Network (DCN)</a>, <a class="reference external" href="https://arxiv.org/abs/1703.04247">DeepFM</a>, and <a class="reference external" href="https://ai.facebook.com/blog/dlrm-an-advanced-open-source-deep-learning-recommendation-model/">Deep Learning Recommendation Model (DLRM)</a>. HugeCTR is a component of <a class="reference external" href="https://developer.nvidia.com/nvidia-merlin">NVIDIA Merlin</a>. Merlin is used for building large-scale recommender systems, which require massive datasets to train, particularly for deep learning based solutions.</p>
<p><br><img alt="_images/merlin_arch.png" src="_images/merlin_arch.png" /></br></p>
<div align=center>Fig. 1: Merlin Architecture</div>
<p><br></br></p>
<p>To prevent data loading from becoming a major bottleneck during training, HugeCTR contains a dedicated data reader that is inherently asynchronous and multi-threaded. It will read a batched set of data records in which each record consists of high-dimensional, extremely sparse, or categorical features. Each record can also include dense numerical features, which can be fed directly to the fully connected layers. An embedding layer is used to compress the sparse input features to lower-dimensional, dense embedding vectors. There are three GPU-accelerated embedding stages:</p>
<ul class="simple">
<li><p>Table lookup</p></li>
<li><p>Weight reduction within each slot</p></li>
<li><p>Weight concatenation across the slots</p></li>
</ul>
<p>To enable large embedding training, the embedding table in HugeCTR is model parallel and distributed across all GPUs in a homogeneous cluster, which consists of multiple nodes. Each GPU has its own:</p>
<ul class="simple">
<li><p>feed-forward neural network (data parallelism) to estimate CTRs.</p></li>
<li><p>hash table to make the data preprocessing easier and enable dynamic insertion.</p></li>
</ul>
<p>Embedding initialization is not required before training takes place since the input training data are hash values (64-bit signed integer type) instead of original indices. A pair of &lt;key,value&gt; (random small weight) will be inserted during runtime only when a new key appears in the training data and the hash table cannot find it.</p>
<a class="reference internal image-reference" href="_images/fig1_hugectr_arch.png"><img alt="_images/fig1_hugectr_arch.png" class="align-center" src="_images/fig1_hugectr_arch.png" style="width: 781px;" /></a>
<div align=center>Fig. 2: HugeCTR Architecture</div>
<p><br></br></p>
<a class="reference internal image-reference" href="_images/fig2_embedding_mlp.png"><img alt="Embedding architecture" class="align-center" src="_images/fig2_embedding_mlp.png" style="width: 500px;" /></a>
<div align=center>Fig. 3: Embedding Architecture</div>
<p><br></br></p>
<a class="reference internal image-reference" href="_images/fig3_embedding_mech.png"><img alt="_images/fig3_embedding_mech.png" class="align-center" src="_images/fig3_embedding_mech.png" style="width: 640px;" /></a>
<div align=center>Fig. 4: Embedding Mechanism</div>
<p><br></br></p>
</section>
<section id="installing-and-building-hugectr">
<h2>Installing and Building HugeCTR<a class="headerlink" href="#installing-and-building-hugectr" title="Permalink to this heading"></a></h2>
<p>You can either install HugeCTR easily using the Merlin Docker image in NGC, or build HugeCTR from scratch using various build options if you’re an advanced user.</p>
<section id="compute-capability">
<h3>Compute Capability<a class="headerlink" href="#compute-capability" title="Permalink to this heading"></a></h3>
<p>We support the following compute capabilities:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Compute Capability</p></th>
<th class="head"><p>GPU</p></th>
<th class="head"><p><a class="reference internal" href="#building-hugectr-from-scratch">SM</a></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>6.0</p></td>
<td><p>NVIDIA P100 (Pascal)</p></td>
<td><p>60</p></td>
</tr>
<tr class="row-odd"><td><p>7.0</p></td>
<td><p>NVIDIA V100 (Volta)</p></td>
<td><p>70</p></td>
</tr>
<tr class="row-even"><td><p>7.5</p></td>
<td><p>NVIDIA T4 (Turing)</p></td>
<td><p>75</p></td>
</tr>
<tr class="row-odd"><td><p>8.0</p></td>
<td><p>NVIDIA A100 (Ampere)</p></td>
<td><p>80</p></td>
</tr>
<tr class="row-even"><td><p>9.0</p></td>
<td><p>NVIDIA H100 (Hopper)</p></td>
<td><p>90</p></td>
</tr>
</tbody>
</table>
</section>
<section id="installing-hugectr-using-ngc-containers">
<h3>Installing HugeCTR Using NGC Containers<a class="headerlink" href="#installing-hugectr-using-ngc-containers" title="Permalink to this heading"></a></h3>
<p>All NVIDIA Merlin components are available as open source projects. However, a more convenient way to utilize these components is by using our Merlin NGC containers. These containers allow you to package your software application, libraries, dependencies, and runtime compilers in a self-contained environment. When installing HugeCTR using NGC containers, the application environment remains portable, consistent, reproducible, and agnostic to the underlying host system’s software configuration.</p>
<p>HugeCTR is included in the Merlin Docker containers that are available from the <a class="reference external" href="https://catalog.ngc.nvidia.com/containers">NVIDIA container repository</a>.
You can query the collection for containers that <a class="reference external" href="https://catalog.ngc.nvidia.com/containers?filters=&amp;amp;orderBy=scoreDESC&amp;amp;query=label:%22HugeCTR%22">match the HugeCTR label</a>.
The following table also identifies the containers:</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p>Container Name</p></th>
<th class="head"><p>Container Location</p></th>
<th class="head"><p>Functionality</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>merlin-hugectr</p></td>
<td><p><a class="reference external" href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-hugectr">https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-hugectr</a></p></td>
<td><p>NVTabular, HugeCTR, and Triton Inference</p></td>
</tr>
<tr class="row-odd"><td><p>merlin-tensorflow</p></td>
<td><p><a class="reference external" href="https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow">https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow</a></p></td>
<td><p>NVTabular, TensorFlow, and HugeCTR Tensorflow Embedding plugin</p></td>
</tr>
</tbody>
</table>
<p>To use these Docker containers, you’ll first need to install the <a class="reference external" href="https://github.com/NVIDIA/nvidia-docker">NVIDIA Container Toolkit</a> to provide GPU support for Docker. You can use the NGC links referenced in the table above to obtain more information about how to launch and run these containers.</p>
<p>The following sample command pulls and starts the Merlin Training container:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="c1"># Run the container in interactive mode</span>
$<span class="w"> </span>docker<span class="w"> </span>run<span class="w"> </span>--gpus<span class="o">=</span>all<span class="w"> </span>--rm<span class="w"> </span>-it<span class="w"> </span>--cap-add<span class="w"> </span>SYS_NICE<span class="w"> </span>nvcr.io/nvidia/merlin/merlin-hugectr:23.08
</pre></div>
</div>
</section>
<section id="building-hugectr-from-scratch">
<h3>Building HugeCTR from Scratch<a class="headerlink" href="#building-hugectr-from-scratch" title="Permalink to this heading"></a></h3>
<p>To build HugeCTR from scratch, refer to the <a class="reference internal" href="hugectr_contributor_guide.html"><span class="std std-doc">contributor guide</span></a> information.</p>
</section>
</section>
<section id="tools">
<h2>Tools<a class="headerlink" href="#tools" title="Permalink to this heading"></a></h2>
<p>We currently support the following tools:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#generating-synthetic-data-and-benchmarks">Data Generator</a>: A configurable data generator, which is available from the Python interface, can be used to generate a synthetic dataset for benchmarking and research purposes.</p></li>
<li><p><a class="reference internal" href="#downloading-and-preprocessing-datasets">Preprocessing Script</a>: We provide a set of scripts that form a template implementation to demonstrate how complex datasets, such as the original Criteo dataset, can be converted into HugeCTR using supported dataset formats such as Norm and RAW. It’s used in all of our samples to prepare the data and train various recommender models.</p></li>
</ul>
<section id="generating-synthetic-data-and-benchmarks">
<h3>Generating Synthetic Data and Benchmarks<a class="headerlink" href="#generating-synthetic-data-and-benchmarks" title="Permalink to this heading"></a></h3>
<p>The <a class="reference internal" href="api/python_interface.html#norm"><span class="std std-ref">Norm</span></a> (with Header) and <a class="reference internal" href="api/python_interface.html#raw"><span class="std std-ref">Raw</span></a> (without Header) datasets can be generated with <a class="reference internal" href="api/python_interface.html#datagenerator"><span class="std std-ref">hugectr.tools.DataGenerator</span></a>. For categorical features, you can configure the probability distribution to be uniform or power-law within <a class="reference internal" href="api/python_interface.html#datageneratorparams-class"><span class="std std-ref">hugectr.tools.DataGeneratorParam</span></a>. The default distribution is power law with alpha = 1.2.</p>
<ul>
<li><p>Generate the <code class="docutils literal notranslate"><span class="pre">Norm</span></code> dataset for DCN and start training the HugeCTR model: <br></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>../tools/data_generator/dcn_norm_generate_train.py
</pre></div>
</div>
</li>
<li><p>Generate the <code class="docutils literal notranslate"><span class="pre">Norm</span></code> dataset for WDL and start training the HugeCTR model: <br></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>../tools/data_generator/wdl_norm_generate_train.py
</pre></div>
</div>
</li>
<li><p>Generate the <code class="docutils literal notranslate"><span class="pre">Raw</span></code> dataset for DLRM and start training the HugeCTR model: <br></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>../tools/data_generator/dlrm_raw_generate_train.py
</pre></div>
</div>
</li>
<li><p>Generate the <code class="docutils literal notranslate"><span class="pre">Parquet</span></code> dataset for DCN and start training the HugeCTR model: <br></p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>../tools/data_generator/dcn_parquet_generate_train.py
</pre></div>
</div>
</li>
</ul>
</section>
<section id="downloading-and-preprocessing-datasets">
<h3>Downloading and Preprocessing Datasets<a class="headerlink" href="#downloading-and-preprocessing-datasets" title="Permalink to this heading"></a></h3>
<p>Download the Criteo 1TB Click Logs dataset using <code class="docutils literal notranslate"><span class="pre">HugeCTR/tools/preprocess.sh</span></code> and preprocess it to train the DCN. The <code class="docutils literal notranslate"><span class="pre">file_list.txt</span></code>, <code class="docutils literal notranslate"><span class="pre">file_list_test.txt</span></code>, and preprocessed data files are available within the <code class="docutils literal notranslate"><span class="pre">criteo_data</span></code> directory. For more information, refer to the <a class="reference external" href="https://github.com/NVIDIA-Merlin/HugeCTR/tree/master/samples">samples</a> directory on GitHub.</p>
<p>For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span><span class="nb">cd</span><span class="w"> </span>tools<span class="w"> </span><span class="c1"># assume that the downloaded dataset is here</span>
$<span class="w"> </span>bash<span class="w"> </span>preprocess.sh<span class="w"> </span><span class="m">1</span><span class="w"> </span>criteo_data<span class="w"> </span>pandas<span class="w"> </span><span class="m">1</span><span class="w"> </span><span class="m">0</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="index.html" class="btn btn-neutral float-left" title="Merlin HugeCTR" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="hugectr_core_features.html" class="btn btn-neutral float-right" title="HugeCTR Core Features" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: v23.08.00
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="hugectr_user_guide.html">v23.08.00</a></dd>
      <dd><a href="../v23.09.00/hugectr_user_guide.html">v23.09.00</a></dd>
      <dd><a href="../v23.12.00/hugectr_user_guide.html">v23.12.00</a></dd>
      <dd><a href="../v24.04.00/hugectr_user_guide.html">v24.04.00</a></dd>
      <dd><a href="../v24.06.00/hugectr_user_guide.html">v24.06.00</a></dd>
      <dd><a href="../v25.03.00/hugectr_user_guide.html">v25.03.00</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="../main/hugectr_user_guide.html">main</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NVJ1Y1YJHK', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>