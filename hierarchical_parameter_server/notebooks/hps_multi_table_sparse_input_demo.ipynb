{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52b4fa7c",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# HPS for Multiple Tables and Sparse Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d59c36",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to use HPS when there are multiple embedding tables and sparse input. It is recommended to run [hierarchical_parameter_server_demo.ipynb](hierarchical_parameter_server_demo.ipynb) before diving into this notebook.\n",
    "\n",
    "For more details about HPS APIs, please refer to [HPS APIs](https://nvidia-merlin.github.io/HugeCTR/hierarchical_parameter_server/master/api/index.html). For more details about HPS per se, please refer to [HugeCTR Hierarchical Parameter Server (HPS)](https://nvidia-merlin.github.io/HugeCTR/master/hugectr_parameter_server.html#hugectr-hierarchical-parameter-server-database-backend)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db634221",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "### Get HPS from NGC\n",
    "\n",
    "The HPS Python module is preinstalled in the 22.08 and later [Merlin TensorFlow Container](https://catalog.ngc.nvidia.com/orgs/nvidia/teams/merlin/containers/merlin-tensorflow): `nvcr.io/nvidia/merlin/merlin-tensorflow:22.08`.\n",
    "\n",
    "You can check the existence of the required libraries by running the following Python code after launching this container.\n",
    "\n",
    "```bash\n",
    "$ python3 -c \"import hierarchical_parameter_server as hps\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bca8790",
   "metadata": {},
   "source": [
    "## Configurations\n",
    "\n",
    "First of all we specify the required configurations, e.g., the arguments needed for generating the dataset, the paths to save the model and the model parameters. We will use a deep neural network (DNN) model which has two embedding table and several dense layers in this notebook. Please note that there are two inputs here, one is the sparse key tensor (multi-hot) while the other is the dense key tensor (one-hot). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f238154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] hierarchical_parameter_server is imported\n"
     ]
    }
   ],
   "source": [
    "import hierarchical_parameter_server as hps\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import struct\n",
    "\n",
    "args = dict()\n",
    "\n",
    "args[\"gpu_num\"] = 1                                         # the number of available GPUs\n",
    "args[\"iter_num\"] = 10                                       # the number of training iteration\n",
    "args[\"global_batch_size\"] = 1024                            # the globally batchsize for all GPUs\n",
    "\n",
    "args[\"slot_num_per_table\"] = [3, 2]                         # the number of feature fields for two embedding tables\n",
    "args[\"embed_vec_size_per_table\"] = [16, 32]                 # the dimension of embedding vectors for two embedding tables\n",
    "args[\"max_vocabulary_size_per_table\"] = [30000, 2000]       # the vocabulary size for two embedding tables\n",
    "args[\"vocabulary_range_per_slot_per_table\"] = [ [[0,10000],[10000,20000],[20000,30000]], [[0, 1000], [1000, 2000]] ]\n",
    "args[\"max_nnz_per_slot_per_table\"] = [[4, 2, 3], [1, 1]]    # the max number of non-zeros for each slot for two embedding tables\n",
    "\n",
    "args[\"dense_model_path\"] = \"multi_table_sparse_input_dense.model\"\n",
    "args[\"ps_config_file\"] = \"multi_table_sparse_input.json\"\n",
    "args[\"embedding_table_path\"] = [\"multi_table_sparse_input_sparse_0.model\", \"multi_table_sparse_input_sparse_1.model\"]\n",
    "args[\"saved_path\"] = \"multi_table_sparse_input_tf_saved_model\"\n",
    "args[\"np_key_type\"] = np.int64\n",
    "args[\"np_vector_type\"] = np.float32\n",
    "args[\"tf_key_type\"] = tf.int64\n",
    "args[\"tf_vector_type\"] = tf.float32\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \",\".join(map(str, range(args[\"gpu_num\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a8d12df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_samples(num_samples, vocabulary_range_per_slot_per_table, max_nnz_per_slot_per_table):\n",
    "    def generate_sparse_keys(num_samples, vocabulary_range_per_slot, max_nnz_per_slot, key_dtype = args[\"np_key_type\"]):\n",
    "        slot_num = len(max_nnz_per_slot)\n",
    "        max_nnz_of_all_slots = max(max_nnz_per_slot)\n",
    "        indices = []\n",
    "        values = []\n",
    "        for i in range(num_samples):\n",
    "            for j in range(slot_num):\n",
    "                vocab_range = vocabulary_range_per_slot[j]\n",
    "                max_nnz = max_nnz_per_slot[j]\n",
    "                nnz = np.random.randint(low=1, high=max_nnz+1)\n",
    "                entries = sorted(np.random.choice(max_nnz, nnz, replace=False))\n",
    "                for entry in entries:\n",
    "                    indices.append([i, j, entry])\n",
    "                values.extend(np.random.randint(low=vocab_range[0], high=vocab_range[1], size=(nnz, )))\n",
    "        values = np.array(values, dtype=key_dtype)\n",
    "        return tf.sparse.SparseTensor(indices = indices,\n",
    "                                    values = values,\n",
    "                                    dense_shape = (num_samples, slot_num, max_nnz_of_all_slots))\n",
    "\n",
    "    def generate_dense_keys(num_samples, vocabulary_range_per_slot, key_dtype = args[\"np_key_type\"]):\n",
    "        dense_keys = list()\n",
    "        for vocab_range in vocabulary_range_per_slot:\n",
    "            keys_per_slot = np.random.randint(low=vocab_range[0], high=vocab_range[1], size=(num_samples, 1), dtype=key_dtype)\n",
    "            dense_keys.append(keys_per_slot)\n",
    "        dense_keys = np.concatenate(np.array(dense_keys), axis = 1)\n",
    "        return dense_keys\n",
    "    \n",
    "    assert len(vocabulary_range_per_slot_per_table)==2, \"there should be two embedding tables\"\n",
    "    assert max(max_nnz_per_slot_per_table[0])>1, \"the first embedding table has sparse key input (multi-hot)\"\n",
    "    assert min(max_nnz_per_slot_per_table[1])==1, \"the second embedding table has dense key input (one-hot)\"\n",
    "    \n",
    "    sparse_keys = generate_sparse_keys(num_samples, vocabulary_range_per_slot_per_table[0], max_nnz_per_slot_per_table[0])\n",
    "    dense_keys = generate_dense_keys(num_samples, vocabulary_range_per_slot_per_table[1])\n",
    "    labels = np.random.randint(low=0, high=2, size=(num_samples, 1))\n",
    "    return sparse_keys, dense_keys, labels\n",
    "\n",
    "def tf_dataset(sparse_keys, dense_keys, labels, batchsize):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((sparse_keys, dense_keys, labels))\n",
    "    dataset = dataset.batch(batchsize, drop_remainder=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e368d8b",
   "metadata": {},
   "source": [
    "## Train with native TF layers\n",
    "\n",
    "We define the model graph for training with native TF layers, i.e., `tf.nn.embedding_lookup_sparse`, `tf.nn.embedding_lookup` and `tf.keras.layers.Dense`.  We can then train the model and extract the trained weights of the two embedding tables. As for the dense layers, they are saved as a separate model graph, which can be loaded directly during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45c1a628",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel(tf.keras.models.Model):\n",
    "    def __init__(self,\n",
    "                 init_tensors_per_table,\n",
    "                 slot_num_per_table,\n",
    "                 embed_vec_size_per_table,\n",
    "                 max_nnz_per_slot_per_table,\n",
    "                 **kwargs):\n",
    "        super(TrainModel, self).__init__(**kwargs)\n",
    "        \n",
    "        self.slot_num_per_table = slot_num_per_table\n",
    "        self.embed_vec_size_per_table = embed_vec_size_per_table\n",
    "        self.max_nnz_per_slot_per_table = max_nnz_per_slot_per_table\n",
    "        self.max_nnz_of_all_slots_per_table = [max(ele) for ele in self.max_nnz_per_slot_per_table]\n",
    "        \n",
    "        self.init_tensors_per_table = init_tensors_per_table\n",
    "        self.params0 = tf.Variable(initial_value=tf.concat(self.init_tensors_per_table[0], axis=0))\n",
    "        self.params1 = tf.Variable(initial_value=tf.concat(self.init_tensors_per_table[1], axis=0))\n",
    "        \n",
    "        self.reshape = tf.keras.layers.Reshape((self.max_nnz_of_all_slots_per_table[0],),\n",
    "                                                input_shape=(self.slot_num_per_table[0], self.max_nnz_of_all_slots_per_table[0]))\n",
    "        \n",
    "        self.fc_1 = tf.keras.layers.Dense(units=256, activation=None,\n",
    "                                                 kernel_initializer=\"ones\",\n",
    "                                                 bias_initializer=\"zeros\",\n",
    "                                                 name='fc_1')\n",
    "        self.fc_2 = tf.keras.layers.Dense(units=256, activation=None,\n",
    "                                                 kernel_initializer=\"ones\",\n",
    "                                                 bias_initializer=\"zeros\",\n",
    "                                                 name='fc_2')\n",
    "        self.fc_3 = tf.keras.layers.Dense(units=1, activation=None,\n",
    "                                                 kernel_initializer=\"ones\",\n",
    "                                                 bias_initializer=\"zeros\",\n",
    "                                                 name='fc_3')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # SparseTensor of keys, shape: (batch_size*slot_num, max_nnz)\n",
    "        embeddings0 = tf.reshape(tf.nn.embedding_lookup_sparse(params=self.params0, sp_ids=inputs[0], sp_weights = None, combiner=\"mean\"),\n",
    "                                shape=[-1, self.slot_num_per_table[0] * self.embed_vec_size_per_table[0]])\n",
    "        # Tensor of keys, shape: (batch_size, slot_num)\n",
    "        embeddings1 = tf.reshape(tf.nn.embedding_lookup(params=self.params1, ids=inputs[1]), \n",
    "                                 shape=[-1, self.slot_num_per_table[1] * self.embed_vec_size_per_table[1]])\n",
    "        \n",
    "        logit = self.fc_3(tf.math.add(self.fc_1(embeddings0), self.fc_2(embeddings1)))\n",
    "        return logit, embeddings0, embeddings1\n",
    "\n",
    "    def summary(self):\n",
    "        inputs = [tf.keras.Input(shape=(self.max_nnz_of_all_slots_per_table[0], ), sparse=True, dtype=args[\"tf_key_type\"]),\n",
    "                  tf.keras.Input(shape=(self.slot_num_per_table[1], ), dtype=args[\"tf_key_type\"])]\n",
    "        model = tf.keras.models.Model(inputs=inputs, outputs=self.call(inputs))\n",
    "        return model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82fb7ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    def _train_step(inputs, labels):\n",
    "        with tf.GradientTape() as tape:\n",
    "            logit, _, _ = model(inputs)\n",
    "            loss = loss_fn(labels, logit)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        return logit, loss\n",
    "\n",
    "    init_tensors_per_table = [np.ones(shape=[args[\"max_vocabulary_size_per_table\"][0], args[\"embed_vec_size_per_table\"][0]], dtype=args[\"np_vector_type\"]),\n",
    "                              np.ones(shape=[args[\"max_vocabulary_size_per_table\"][1], args[\"embed_vec_size_per_table\"][1]], dtype=args[\"np_vector_type\"])]\n",
    "\n",
    "    model = TrainModel(init_tensors_per_table, args[\"slot_num_per_table\"], args[\"embed_vec_size_per_table\"], args[\"max_nnz_per_slot_per_table\"])\n",
    "    model.summary()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "    sparse_keys, dense_keys, labels = generate_random_samples(args[\"global_batch_size\"]  * args[\"iter_num\"], args[\"vocabulary_range_per_slot_per_table\"], args[\"max_nnz_per_slot_per_table\"])\n",
    "    dataset = tf_dataset(sparse_keys, dense_keys, labels, args[\"global_batch_size\"])\n",
    "    for i, (sparse_keys, dense_keys, labels) in enumerate(dataset):\n",
    "        sparse_keys = tf.sparse.reshape(sparse_keys, [-1, sparse_keys.shape[-1]])\n",
    "        inputs = [sparse_keys, dense_keys]\n",
    "        _, loss = _train_step(inputs, labels)\n",
    "        print(\"-\"*20, \"Step {}, loss: {}\".format(i, loss),  \"-\"*20)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95fd2137",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 07:51:09.676041: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-12 07:51:10.271131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30989 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:06:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup_sparse), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(30000, 16) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "WARNING:tensorflow:The following Variables were used in a Lambda layer's call (tf.compat.v1.nn.embedding_lookup), but are not present in its tracked objects:   <tf.Variable 'Variable:0' shape=(2000, 32) dtype=float32>. This is a strong indication that the Lambda layer should be rewritten as a subclassed Layer.\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " tf.compat.v1.nn.embedding_look  (None, 16)          0           ['input_1[0][0]']                \n",
      " up_sparse (TFOpLambda)                                                                           \n",
      "                                                                                                  \n",
      " tf.compat.v1.nn.embedding_look  (None, 2, 32)       0           ['input_2[0][0]']                \n",
      " up (TFOpLambda)                                                                                  \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)        (None, 48)           0           ['tf.compat.v1.nn.embedding_looku\n",
      "                                                                 p_sparse[0][0]']                 \n",
      "                                                                                                  \n",
      " tf.reshape_1 (TFOpLambda)      (None, 64)           0           ['tf.compat.v1.nn.embedding_looku\n",
      "                                                                 p[0][0]']                        \n",
      "                                                                                                  \n",
      " fc_1 (Dense)                   (None, 256)          12544       ['tf.reshape[0][0]']             \n",
      "                                                                                                  \n",
      " fc_2 (Dense)                   (None, 256)          16640       ['tf.reshape_1[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.add (TFOpLambda)       (None, 256)          0           ['fc_1[0][0]',                   \n",
      "                                                                  'fc_2[0][0]']                   \n",
      "                                                                                                  \n",
      " fc_3 (Dense)                   (None, 1)            257         ['tf.math.add[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29,441\n",
      "Trainable params: 29,441\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "-------------------- Step 0, loss: 14588.0 --------------------\n",
      "-------------------- Step 1, loss: 11693.25 --------------------\n",
      "-------------------- Step 2, loss: 8232.9658203125 --------------------\n",
      "-------------------- Step 3, loss: 6276.9736328125 --------------------\n",
      "-------------------- Step 4, loss: 4676.82861328125 --------------------\n",
      "-------------------- Step 5, loss: 2921.1875 --------------------\n",
      "-------------------- Step 6, loss: 1938.2447509765625 --------------------\n",
      "-------------------- Step 7, loss: 1093.598388671875 --------------------\n",
      "-------------------- Step 8, loss: 616.3092651367188 --------------------\n",
      "-------------------- Step 9, loss: 257.61248779296875 --------------------\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 48)]         0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 64)]         0           []                               \n",
      "                                                                                                  \n",
      " fc_1 (Dense)                   (None, 256)          12544       ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " fc_2 (Dense)                   (None, 256)          16640       ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " tf.math.add (TFOpLambda)       (None, 256)          0           ['fc_1[1][0]',                   \n",
      "                                                                  'fc_2[1][0]']                   \n",
      "                                                                                                  \n",
      " fc_3 (Dense)                   (None, 1)            257         ['tf.math.add[1][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29,441\n",
      "Trainable params: 29,441\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-12 07:51:13.335404: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_1 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: multi_table_sparse_input_dense.model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: multi_table_sparse_input_dense.model/assets\n"
     ]
    }
   ],
   "source": [
    "trained_model = train(args)\n",
    "weights_list = trained_model.get_weights()\n",
    "embedding_weights_per_table = weights_list[-2:]\n",
    "dense_model = tf.keras.Model([trained_model.get_layer(\"fc_1\").input, \n",
    "                              trained_model.get_layer(\"fc_2\").input], \n",
    "                             trained_model.get_layer(\"fc_3\").output)\n",
    "dense_model.summary()\n",
    "dense_model.save(args[\"dense_model_path\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c69ee8e",
   "metadata": {},
   "source": [
    "## Create the inference graph with HPS SparseLookupLayer and LookupLayer\n",
    "In order to use HPS in the inference stage, we need to create a inference model graph which is almost the same as the train graph except that `tf.nn.embedding_lookup_sparse` is replaced by `hps.SparseLookupLayer` and `tf.nn.embedding_lookup` is replaced by `hps.LookupLayer`. The trained dense model graph can be loaded directly, while the weights of two embedding tables should be converted to the formats required by HPS. \n",
    "\n",
    "We can then save the inference model graph, which will be ready to be loaded for inference deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b2c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InferenceModel(tf.keras.models.Model):\n",
    "    def __init__(self,\n",
    "                 slot_num_per_table,\n",
    "                 embed_vec_size_per_table,\n",
    "                 max_nnz_per_slot_per_table,\n",
    "                 dense_model_path,\n",
    "                 **kwargs):\n",
    "        super(InferenceModel, self).__init__(**kwargs)\n",
    "        \n",
    "        self.slot_num_per_table = slot_num_per_table\n",
    "        self.embed_vec_size_per_table = embed_vec_size_per_table\n",
    "        self.max_nnz_per_slot_per_table = max_nnz_per_slot_per_table\n",
    "        self.max_nnz_of_all_slots_per_table = [max(ele) for ele in self.max_nnz_per_slot_per_table]\n",
    "        \n",
    "        self.sparse_lookup_layer = hps.SparseLookupLayer(model_name = \"multi_table_sparse_input\", \n",
    "                                            table_id = 0,\n",
    "                                            emb_vec_size = self.embed_vec_size_per_table[0],\n",
    "                                            emb_vec_dtype = args[\"tf_vector_type\"])\n",
    "        self.lookup_layer = hps.LookupLayer(model_name = \"multi_table_sparse_input\", \n",
    "                                            table_id = 1,\n",
    "                                            emb_vec_size = self.embed_vec_size_per_table[1],\n",
    "                                            emb_vec_dtype = args[\"tf_vector_type\"])\n",
    "        self.dense_model = tf.keras.models.load_model(dense_model_path)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        # SparseTensor of keys, shape: (batch_size*slot_num, max_nnz)\n",
    "        embeddings0 = tf.reshape(self.sparse_lookup_layer(sp_ids=inputs[0], sp_weights = None, combiner=\"mean\"),\n",
    "                                shape=[-1, self.slot_num_per_table[0] * self.embed_vec_size_per_table[0]])\n",
    "        # Tensor of keys, shape: (batch_size, slot_num)\n",
    "        embeddings1 = tf.reshape(self.lookup_layer(inputs[1]), \n",
    "                                 shape=[-1, self.slot_num_per_table[1] * self.embed_vec_size_per_table[1]])\n",
    "        \n",
    "        logit = self.dense_model([embeddings0, embeddings1])\n",
    "        return logit, embeddings0, embeddings1\n",
    "\n",
    "    def summary(self):\n",
    "        inputs = [tf.keras.Input(shape=(self.max_nnz_of_all_slots_per_table[0], ), sparse=True, dtype=args[\"tf_key_type\"]),\n",
    "                  tf.keras.Input(shape=(self.slot_num_per_table[1], ), dtype=args[\"tf_key_type\"])]\n",
    "        model = tf.keras.models.Model(inputs=inputs, outputs=self.call(inputs))\n",
    "        return model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7eea515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_save_inference_graph(args): \n",
    "    model = InferenceModel(args[\"slot_num_per_table\"], args[\"embed_vec_size_per_table\"], args[\"max_nnz_per_slot_per_table\"], args[\"dense_model_path\"])\n",
    "    model.summary()\n",
    "    inputs = [tf.keras.Input(shape=(max(args[\"max_nnz_per_slot_per_table\"][0]), ), sparse=True, dtype=args[\"tf_key_type\"]),\n",
    "             tf.keras.Input(shape=(args[\"slot_num_per_table\"][1], ), dtype=args[\"tf_key_type\"])]\n",
    "    _, _, _= model(inputs)\n",
    "    model.save(args[\"saved_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36b1789c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_sparse_model(embeddings_weights, embedding_table_path, embedding_vec_size):\n",
    "    os.system(\"mkdir -p {}\".format(embedding_table_path))\n",
    "    with open(\"{}/key\".format(embedding_table_path), 'wb') as key_file, \\\n",
    "        open(\"{}/emb_vector\".format(embedding_table_path), 'wb') as vec_file:\n",
    "      for key in range(embeddings_weights.shape[0]):\n",
    "        vec = embeddings_weights[key]\n",
    "        key_struct = struct.pack('q', key)\n",
    "        vec_struct = struct.pack(str(embedding_vec_size) + \"f\", *vec)\n",
    "        key_file.write(key_struct)\n",
    "        vec_file.write(vec_struct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d1edd8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 4)]          0           []                               \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)           [(None, 2)]          0           []                               \n",
      "                                                                                                  \n",
      " sparse_lookup_layer (SparseLoo  (None, 16)          0           ['input_5[0][0]']                \n",
      " kupLayer)                                                                                        \n",
      "                                                                                                  \n",
      " lookup_layer (LookupLayer)     (None, 2, 32)        0           ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " tf.reshape_2 (TFOpLambda)      (None, 48)           0           ['sparse_lookup_layer[0][0]']    \n",
      "                                                                                                  \n",
      " tf.reshape_3 (TFOpLambda)      (None, 64)           0           ['lookup_layer[0][0]']           \n",
      "                                                                                                  \n",
      " model_1 (Functional)           (None, 1)            29441       ['tf.reshape_2[0][0]',           \n",
      "                                                                  'tf.reshape_3[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29,441\n",
      "Trainable params: 29,441\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) args_0 with unsupported characters which will be renamed to args_0_3 in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: multi_table_sparse_input_tf_saved_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: multi_table_sparse_input_tf_saved_model/assets\n"
     ]
    }
   ],
   "source": [
    "convert_to_sparse_model(embedding_weights_per_table[0], args[\"embedding_table_path\"][0], args[\"embed_vec_size_per_table\"][0])\n",
    "convert_to_sparse_model(embedding_weights_per_table[1], args[\"embedding_table_path\"][1], args[\"embed_vec_size_per_table\"][1])\n",
    "create_and_save_inference_graph(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6af08f",
   "metadata": {},
   "source": [
    "## Inference with saved model graph\n",
    "\n",
    "In order to initialize the lookup service provided by HPS, we also need to create a JSON configuration file and specify the details of the embedding tables for the models to be deployed. We deploy a model that has two embedding tables here, and it can support multiple models with multiple embedding tables actually. Please note how `maxnum_catfeature_query_per_table_per_sample` is specified for the two embedding tables: the `max_nnz_per_slot` of the first table is `[4, 2, 3]`, which sums to 9, and for the second table it is `[1, 1]`, which sums to 2.\n",
    "\n",
    "We first call `hps.Init` to do the necessary initialization work, and then load the saved model graph to make inference. We peek at the keys and the embedding vectors for each table for the last inference batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3dacbe5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing multi_table_sparse_input.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile multi_table_sparse_input.json\n",
    "{\n",
    "    \"supportlonglong\": true,\n",
    "    \"models\": [{\n",
    "        \"model\": \"multi_table_sparse_input\",\n",
    "        \"sparse_files\": [\"multi_table_sparse_input_sparse_0.model\", \"multi_table_sparse_input_sparse_1.model\"],\n",
    "        \"num_of_worker_buffer_in_pool\": 3,\n",
    "        \"embedding_table_names\":[\"sparse_embedding0\", \"sparse_embedding1\"],\n",
    "        \"embedding_vecsize_per_table\": [16, 32],\n",
    "        \"maxnum_catfeature_query_per_table_per_sample\": [9, 2],\n",
    "        \"default_value_for_each_table\": [1.0, 1.0],\n",
    "        \"deployed_device_list\": [0],\n",
    "        \"max_batch_size\": 1024,\n",
    "        \"cache_refresh_percentage_per_iteration\": 0.2,\n",
    "        \"hit_rate_threshold\": 1.0,\n",
    "        \"gpucacheper\": 1.0,\n",
    "        \"gpucache\": true\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "783cfb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_with_saved_model(args):\n",
    "    hps.Init(global_batch_size = args[\"global_batch_size\"],\n",
    "             ps_config_file = args[\"ps_config_file\"])\n",
    "    model = tf.keras.models.load_model(args[\"saved_path\"])\n",
    "    model.summary()\n",
    "    def _infer_step(inputs, labels):\n",
    "        logit, embeddings0, embeddings1 = model(inputs)\n",
    "        return logit, embeddings0, embeddings1\n",
    "    embeddings0_peek = list()\n",
    "    embeddings1_peek = list()\n",
    "    inputs_peek = list()\n",
    "    sparse_keys, dense_keys, labels = generate_random_samples(args[\"global_batch_size\"]  * args[\"iter_num\"], args[\"vocabulary_range_per_slot_per_table\"], args[\"max_nnz_per_slot_per_table\"])\n",
    "    dataset = tf_dataset(sparse_keys, dense_keys, labels, args[\"global_batch_size\"])\n",
    "    for i, (sparse_keys, dense_keys, labels) in enumerate(dataset):\n",
    "        sparse_keys = tf.sparse.reshape(sparse_keys, [-1, sparse_keys.shape[-1]])\n",
    "        inputs = [sparse_keys, dense_keys]\n",
    "        logit, embeddings0, embeddings1 = _infer_step(inputs, labels)\n",
    "        embeddings0_peek.append(embeddings0)\n",
    "        embeddings1_peek.append(embeddings1)\n",
    "        inputs_peek.append(inputs)\n",
    "        print(\"-\"*20, \"Step {}\".format(i),  \"-\"*20)\n",
    "    return embeddings0_peek, embeddings1_peek, inputs_peek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab279d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================HPS Parse====================================================\n",
      "[HCTR][07:51:32.495][INFO][RK0][main]: dense_file is not specified using default: \n",
      "[HCTR][07:51:32.495][WARNING][RK0][main]: default_value_for_each_table.size() is not equal to the number of embedding tables\n",
      "[HCTR][07:51:32.495][INFO][RK0][main]: num_of_refresher_buffer_in_pool is not specified using default: 1\n",
      "[HCTR][07:51:32.495][INFO][RK0][main]: maxnum_des_feature_per_sample is not specified using default: 26\n",
      "[HCTR][07:51:32.495][INFO][RK0][main]: refresh_delay is not specified using default: 0\n",
      "[HCTR][07:51:32.495][INFO][RK0][main]: refresh_interval is not specified using default: 0\n",
      "====================================================HPS Create====================================================\n",
      "[HCTR][07:51:32.495][INFO][RK0][main]: Creating HashMap CPU database backend...\n",
      "[HCTR][07:51:32.495][INFO][RK0][main]: Volatile DB: initial cache rate = 1\n",
      "[HCTR][07:51:32.495][INFO][RK0][main]: Volatile DB: cache missed embeddings = 0\n",
      "[HCTR][07:51:32.855][INFO][RK0][main]: Table: hps_et.multi_table_sparse_input.sparse_embedding0; cached 30000 / 30000 embeddings in volatile database (PreallocatedHashMapBackend); load: 30000 / 18446744073709551615 (0.00%).\n",
      "[HCTR][07:51:33.195][INFO][RK0][main]: Table: hps_et.multi_table_sparse_input.sparse_embedding1; cached 2000 / 2000 embeddings in volatile database (PreallocatedHashMapBackend); load: 2000 / 18446744073709551615 (0.00%).\n",
      "[HCTR][07:51:33.195][DEBUG][RK0][main]: Real-time subscribers created!\n",
      "[HCTR][07:51:33.195][INFO][RK0][main]: Creating embedding cache in device 0.\n",
      "[HCTR][07:51:33.201][INFO][RK0][main]: Model name: multi_table_sparse_input\n",
      "[HCTR][07:51:33.201][INFO][RK0][main]: Number of embedding tables: 2\n",
      "[HCTR][07:51:33.201][INFO][RK0][main]: Use GPU embedding cache: True, cache size percentage: 1.000000\n",
      "[HCTR][07:51:33.201][INFO][RK0][main]: Use I64 input key: True\n",
      "[HCTR][07:51:33.201][INFO][RK0][main]: Configured cache hit rate threshold: 1.000000\n",
      "[HCTR][07:51:33.201][INFO][RK0][main]: The size of thread pool: 80\n",
      "[HCTR][07:51:33.201][INFO][RK0][main]: The size of worker memory pool: 3\n",
      "[HCTR][07:51:33.201][INFO][RK0][main]: The size of refresh memory pool: 1\n",
      "[HCTR][07:51:33.212][INFO][RK0][main]: Creating lookup session for multi_table_sparse_input on device: 0\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inference_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sparse_lookup_layer (Sparse  multiple                 0         \n",
      " LookupLayer)                                                    \n",
      "                                                                 \n",
      " lookup_layer (LookupLayer)  multiple                  0         \n",
      "                                                                 \n",
      " model_1 (Functional)        (None, 1)                 29441     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,441\n",
      "Trainable params: 29,441\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "-------------------- Step 0 --------------------\n",
      "-------------------- Step 1 --------------------\n",
      "-------------------- Step 2 --------------------\n",
      "-------------------- Step 3 --------------------\n",
      "-------------------- Step 4 --------------------\n",
      "-------------------- Step 5 --------------------\n",
      "-------------------- Step 6 --------------------\n",
      "-------------------- Step 7 --------------------\n",
      "-------------------- Step 8 --------------------\n",
      "-------------------- Step 9 --------------------\n",
      "tf.Tensor([ 9905  1750  4223 ... 20477 22119 23797], shape=(6111,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[0.9122444  0.9122444  0.9122444  ... 1.         1.         1.        ]\n",
      " [0.76979905 0.76979905 0.76979905 ... 1.         1.         1.        ]\n",
      " [0.7415885  0.7415885  0.7415885  ... 1.         1.         1.        ]\n",
      " ...\n",
      " [0.66938084 0.66938084 0.66938084 ... 1.         1.         1.        ]\n",
      " [0.90488005 0.90488005 0.90488005 ... 1.         1.         1.        ]\n",
      " [0.7773342  0.7773342  0.7773342  ... 0.6368773  0.6368773  0.6368773 ]], shape=(1024, 48), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 276 1610]\n",
      " [ 408 1884]\n",
      " [ 678 1762]\n",
      " ...\n",
      " [ 369 1794]\n",
      " [ 403 1216]\n",
      " [ 909 1427]], shape=(1024, 2), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[0.28882617 0.28882617 0.28882617 ... 0.41947648 0.41947648 0.41947648]\n",
      " [0.597903   0.597903   0.597903   ... 0.37505823 0.37505823 0.37505823]\n",
      " [0.70420146 0.70420146 0.70420146 ... 0.38864705 0.38864705 0.38864705]\n",
      " ...\n",
      " [0.32224336 0.32224336 0.32224336 ... 0.31987724 0.31987724 0.31987724]\n",
      " [0.43596342 0.43596342 0.43596342 ... 0.5383081  0.5383081  0.5383081 ]\n",
      " [0.37384593 0.37384593 0.37384593 ... 0.6026224  0.6026224  0.6026224 ]], shape=(1024, 64), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "embeddings0_peek, embeddings1_peek, inputs_peek = inference_with_saved_model(args)\n",
    "\n",
    "# 1st embedding table, input keys are SparseTensor \n",
    "print(inputs_peek[-1][0].values)\n",
    "print(embeddings0_peek[-1])\n",
    "\n",
    "# 2nd embedding table, input keys are Tensor\n",
    "print(inputs_peek[-1][1])\n",
    "print(embeddings1_peek[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
