{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://developer.download.nvidia.com/compute/machine-learning/frameworks/nvidia_logo.png\" style=\"width: 90px; float: right;\">\n",
    "\n",
    "# Merlin ETL, training and inference demo on the e-Commerce behavior data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this tutorial, we will be using the [eCommerce behavior data from multi category store](https://www.kaggle.com/mkechinov/ecommerce-behavior-data-from-multi-category-store) from [REES46 Marketing Platform](https://rees46.com/) as our dataset. This tutorial is built upon the NVIDIA RecSys 2020 [tutorial](https://recsys.acm.org/recsys20/tutorials/). \n",
    "\n",
    "This jupyter notebook provides the code to preprocess the dataset and generate the train, validation and test sets for the remainder of the tutorial. We define our own goal and filter the dataset accordingly.\n",
    "\n",
    "For our tutorial, we decided that our goal is to predict if a user purchased an item:\n",
    "\n",
    "-  Positive: User purchased an item\n",
    "-  Negative: User added an item to the cart, but did not purchase it (in the same session)    \n",
    "\n",
    "\n",
    "We split the dataset into train, validation and test set by the timestamp:\n",
    "- Training: October 2019 - February 2020\n",
    "- Validation: March 2020\n",
    "-  Test: April 2020\n",
    "\n",
    "We remove AddToCart Events from a session, if in the same session the same item was purchased.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Data](#1)\n",
    "1. [ETL with NVTabular](#2)\n",
    "1. [Training with HugeCTR](#3)\n",
    "1. [HugeCTR inference](#4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Data\n",
    "First, we download and unzip the raw data.\n",
    "\n",
    "Note: the dataset is ~11GB and will take a while to download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting gdown\n",
      "  Downloading gdown-3.13.0.tar.gz (9.3 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.0.12-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from gdown) (4.61.0)\n",
      "Requirement already satisfied: requests[socks]>=2.12.0 in /usr/lib/python3/dist-packages (from gdown) (2.22.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown) (1.14.0)\n",
      "Collecting PySocks!=1.5.7,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (PEP 517): started\n",
      "  Building wheel for gdown (PEP 517): finished with status 'done'\n",
      "  Created wheel for gdown: filename=gdown-3.13.0-py3-none-any.whl size=9034 sha256=a42e1a003f31f07a2dab41ee0adc192159f56e059bcaafe64672c529a4e2ce5b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-vrf8xmza/wheels/04/51/53/ed3e97af28b242e9eb81afb4836273fbe233a14228aa82fea3\n",
      "Successfully built gdown\n",
      "Installing collected packages: PySocks, filelock, gdown\n",
      "Successfully installed PySocks-1.7.1 filelock-3.0.12 gdown-3.13.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script gdown is installed in '/workdir/notebooks/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 21.0.1; however, version 21.1.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python -m pip install --upgrade pip' command.\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-Rov9fFtGJqb7_ePc6qH-Rhzxn0cIcKB\n",
      "To: /workdir/notebooks/2020-Feb.csv.gz\n",
      "2.35GB [01:13, 32.1MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1-Rov9fFtGJqb7_ePc6qH-Rhzxn0cIcKB\n",
      "To: /workdir/notebooks/2020-Feb.csv.gz\n",
      "2.35GB [00:28, 81.6MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1zr_RXpGvOWN2PrWI6itWL8HnRsCpyqz8\n",
      "To: /workdir/notebooks/2020-Mar.csv.gz\n",
      "2.42GB [01:09, 34.9MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1g5WoIgLe05UMdREbxAjh0bEFgVCjA1UL\n",
      "To: /workdir/notebooks/2020-Apr.csv.gz\n",
      "2.93GB [01:41, 28.9MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1qZIwMbMgMmgDC5EoMdJ8aI9lQPsWA3-P\n",
      "To: /workdir/notebooks/2019-Dec.csv.gz\n",
      "2.95GB [01:08, 43.3MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1x5ohrrZNhWQN4Q-zww0RmXOwctKHH9PT\n",
      "To: /workdir/notebooks/2020-Jan.csv.gz\n",
      "2.39GB [00:56, 42.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "export HOME=$PWD\n",
    "pip install gdown --user\n",
    "~/.local/bin/gdown  https://drive.google.com/uc?id=1-Rov9fFtGJqb7_ePc6qH-Rhzxn0cIcKB\n",
    "~/.local/bin/gdown  https://drive.google.com/uc?id=1-Rov9fFtGJqb7_ePc6qH-Rhzxn0cIcKB\n",
    "~/.local/bin/gdown  https://drive.google.com/uc?id=1zr_RXpGvOWN2PrWI6itWL8HnRsCpyqz8\n",
    "~/.local/bin/gdown  https://drive.google.com/uc?id=1g5WoIgLe05UMdREbxAjh0bEFgVCjA1UL\n",
    "~/.local/bin/gdown  https://drive.google.com/uc?id=1qZIwMbMgMmgDC5EoMdJ8aI9lQPsWA3-P\n",
    "~/.local/bin/gdown  https://drive.google.com/uc?id=1x5ohrrZNhWQN4Q-zww0RmXOwctKHH9PT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2020-Mar.csv.gz',\n",
       " '2020-Jan.csv.gz',\n",
       " '2020-Feb.csv.gz',\n",
       " '2020-Apr.csv.gz',\n",
       " '2019-Dec.csv.gz']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob  \n",
    "\n",
    "list_files = glob.glob('*.csv.gz')\n",
    "list_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data extraction and initial preprocessing\n",
    "\n",
    "We extract a few relevant columns from the raw datasets and parse date columns into several atomic columns (day, month...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘./dataset’: File exists\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-Mar.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████████████▌                                                                  | 1/5 [03:26<13:46, 206.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-Jan.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████████▏                                                 | 2/5 [06:47<10:09, 203.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-Feb.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████████████████████████████████▊                                 | 3/5 [10:11<06:47, 203.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-Apr.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████████████▍                | 4/5 [14:10<03:37, 217.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-Dec.csv.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [18:15<00:00, 219.13s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_files(file):\n",
    "    df_tmp = pd.read_csv(file, compression='gzip')\n",
    "    df_tmp['session_purchase'] =  df_tmp['user_session'] + '_' + df_tmp['product_id'].astype(str)\n",
    "    df_purchase = df_tmp[df_tmp['event_type']=='purchase']\n",
    "    df_cart = df_tmp[df_tmp['event_type']=='cart']\n",
    "    df_purchase = df_purchase[df_purchase['session_purchase'].isin(df_cart['session_purchase'])]\n",
    "    df_cart = df_cart[~(df_cart['session_purchase'].isin(df_purchase['session_purchase']))]\n",
    "    df_cart['target'] = 0\n",
    "    df_purchase['target'] = 1\n",
    "    df = pd.concat([df_cart, df_purchase])\n",
    "    df = df.drop('category_id', axis=1)\n",
    "    df = df.drop('session_purchase', axis=1)\n",
    "    df[['cat_0', 'cat_1', 'cat_2', 'cat_3']] = df['category_code'].str.split(\"\\.\", n = 3, expand = True).fillna('NA')\n",
    "    df['brand'] = df['brand'].fillna('NA')\n",
    "    df = df.drop('category_code', axis=1)\n",
    "    df['timestamp'] = pd.to_datetime(df['event_time'].str.replace(' UTC', ''))\n",
    "    df['ts_hour'] = df['timestamp'].dt.hour\n",
    "    df['ts_minute'] = df['timestamp'].dt.minute\n",
    "    df['ts_weekday'] = df['timestamp'].dt.weekday\n",
    "    df['ts_day'] = df['timestamp'].dt.day\n",
    "    df['ts_month'] = df['timestamp'].dt.month\n",
    "    df['ts_year'] = df['timestamp'].dt.year\n",
    "    df.to_csv('./dataset/' + file.replace('.gz', ''), index=False)\n",
    "    \n",
    "!mkdir ./dataset\n",
    "for file in tqdm(list_files):\n",
    "    print(file)\n",
    "    process_files(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare train/validation/test data\n",
    "\n",
    "Next, we split the data into train, validation and test sets. We will be using 3 months for training, 1 month for validation and 1 month for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lp = []\n",
    "list_files = glob.glob('./dataset/*.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root dip 479323170 Jul 12 05:57 ./dataset/2019-Dec.csv\n",
      "-rw-r--r-- 1 root dip 455992639 Jul 12 05:52 ./dataset/2020-Apr.csv\n",
      "-rw-r--r-- 1 root dip 453967664 Jul 12 05:48 ./dataset/2020-Feb.csv\n",
      "-rw-r--r-- 1 root dip 375205173 Jul 12 05:45 ./dataset/2020-Jan.csv\n",
      "-rw-r--r-- 1 root dip 403896607 Jul 12 05:42 ./dataset/2020-Mar.csv\n"
     ]
    }
   ],
   "source": [
    "!ls -l ./dataset/*.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in list_files:\n",
    "    lp.append(pd.read_csv(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13184044, 19)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(lp)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df[df['ts_month']==4]\n",
    "df_valid = df[df['ts_month']==3]\n",
    "df_train = df[(df['ts_month']!=3)&(df['ts_month']!=4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7949839, 19), (2461719, 19), (2772486, 19))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_valid.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p ./data\n",
    "df_train.to_parquet('./data/train.parquet', index=False)\n",
    "df_valid.to_parquet('./data/valid.parquet', index=False)\n",
    "df_test.to_parquet('./data/test.parquet', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "      <th>target</th>\n",
       "      <th>cat_0</th>\n",
       "      <th>cat_1</th>\n",
       "      <th>cat_2</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ts_hour</th>\n",
       "      <th>ts_minute</th>\n",
       "      <th>ts_weekday</th>\n",
       "      <th>ts_day</th>\n",
       "      <th>ts_month</th>\n",
       "      <th>ts_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:00:10 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>1005124</td>\n",
       "      <td>apple</td>\n",
       "      <td>1453.18</td>\n",
       "      <td>532239316</td>\n",
       "      <td>253616df-2b1e-4bdf-8a0a-2d1aeef79734</td>\n",
       "      <td>0</td>\n",
       "      <td>construction</td>\n",
       "      <td>tools</td>\n",
       "      <td>light</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01 00:00:10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 00:00:11 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>1201565</td>\n",
       "      <td>apple</td>\n",
       "      <td>385.34</td>\n",
       "      <td>581430108</td>\n",
       "      <td>7d7687c4-b613-4467-8a81-54c7600e0ca9</td>\n",
       "      <td>0</td>\n",
       "      <td>apparel</td>\n",
       "      <td>shoes</td>\n",
       "      <td>slipons</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01 00:00:11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 00:00:22 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>13101067</td>\n",
       "      <td>skad</td>\n",
       "      <td>266.67</td>\n",
       "      <td>519373619</td>\n",
       "      <td>e97a30d7-2873-4018-9577-8cbf39b1c2c7</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01 00:00:22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 00:00:26 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>4801028</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>14.95</td>\n",
       "      <td>574723072</td>\n",
       "      <td>2f967c6e-b6c4-4971-8599-d34f86570e29</td>\n",
       "      <td>0</td>\n",
       "      <td>sport</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01 00:00:26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 00:00:36 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>1004226</td>\n",
       "      <td>apple</td>\n",
       "      <td>890.11</td>\n",
       "      <td>518285678</td>\n",
       "      <td>7dad15db-dd6d-4e59-a6c7-674612f40837</td>\n",
       "      <td>0</td>\n",
       "      <td>construction</td>\n",
       "      <td>tools</td>\n",
       "      <td>light</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-01-01 00:00:36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                event_time event_type  product_id   brand    price    user_id  \\\n",
       "0  2020-01-01 00:00:10 UTC       cart     1005124   apple  1453.18  532239316   \n",
       "1  2020-01-01 00:00:11 UTC       cart     1201565   apple   385.34  581430108   \n",
       "2  2020-01-01 00:00:22 UTC       cart    13101067    skad   266.67  519373619   \n",
       "3  2020-01-01 00:00:26 UTC       cart     4801028  xiaomi    14.95  574723072   \n",
       "4  2020-01-01 00:00:36 UTC       cart     1004226   apple   890.11  518285678   \n",
       "\n",
       "                           user_session  target         cat_0    cat_1  \\\n",
       "0  253616df-2b1e-4bdf-8a0a-2d1aeef79734       0  construction    tools   \n",
       "1  7d7687c4-b613-4467-8a81-54c7600e0ca9       0       apparel    shoes   \n",
       "2  e97a30d7-2873-4018-9577-8cbf39b1c2c7       0           NaN      NaN   \n",
       "3  2f967c6e-b6c4-4971-8599-d34f86570e29       0         sport  bicycle   \n",
       "4  7dad15db-dd6d-4e59-a6c7-674612f40837       0  construction    tools   \n",
       "\n",
       "     cat_2 cat_3            timestamp  ts_hour  ts_minute  ts_weekday  ts_day  \\\n",
       "0    light   NaN  2020-01-01 00:00:10        0          0           2       1   \n",
       "1  slipons   NaN  2020-01-01 00:00:11        0          0           2       1   \n",
       "2      NaN   NaN  2020-01-01 00:00:22        0          0           2       1   \n",
       "3      NaN   NaN  2020-01-01 00:00:26        0          0           2       1   \n",
       "4    light   NaN  2020-01-01 00:00:36        0          0           2       1   \n",
       "\n",
       "   ts_month  ts_year  \n",
       "0         1     2020  \n",
       "1         1     2020  \n",
       "2         1     2020  \n",
       "3         1     2020  \n",
       "4         1     2020  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. Preprocessing with NVTabular\n",
    "\n",
    "Next, we will use NVTabular for preprocessing and engineering more features. \n",
    "\n",
    "But first, we need to import the necessary libraries and initialize a Dask GPU cluster for computation.\n",
    "\n",
    "### Initialize Dask GPU cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5.3\n"
     ]
    }
   ],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "from time import time\n",
    "import re\n",
    "import shutil\n",
    "import glob\n",
    "import warnings\n",
    "\n",
    "# External Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cupy as cp\n",
    "import cudf\n",
    "import dask_cudf\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "from dask.utils import parse_bytes\n",
    "from dask.delayed import delayed\n",
    "import rmm\n",
    "\n",
    "# NVTabular\n",
    "import nvtabular as nvt\n",
    "import nvtabular.ops as ops\n",
    "from nvtabular.io import Shuffle\n",
    "from nvtabular.utils import _pynvml_mem_size, device_mem_size\n",
    "\n",
    "print(nvt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some information about where to get our data\n",
    "BASE_DIR = \"./nvtabular_temp\"\n",
    "!rm -r $BASE_DIR && mkdir $BASE_DIR\n",
    "input_path = './dataset'\n",
    "dask_workdir = os.path.join(BASE_DIR, \"workdir\")\n",
    "output_path = os.path.join(BASE_DIR, \"output\")\n",
    "stats_path = os.path.join(BASE_DIR, \"stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example was tested on a DGX server with 8 GPUs. If you have less GPUs, modify the `NUM_GPUS` variable accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:37915</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>503.81 GiB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:37915' processes=8 threads=8, memory=503.81 GiB>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_GPUS = [0,1,2,3,4,5,6,7]\n",
    "#NUM_GPUS = [0]\n",
    "\n",
    "# Dask dashboard\n",
    "dashboard_port = \"8787\"\n",
    "\n",
    "# Deploy a Single-Machine Multi-GPU Cluster\n",
    "protocol = \"tcp\"             # \"tcp\" or \"ucx\"\n",
    "visible_devices = \",\".join([str(n) for n in NUM_GPUS])  # Delect devices to place workers\n",
    "device_limit_frac = 0.5      # Spill GPU-Worker memory to host at this limit.\n",
    "device_pool_frac = 0.6\n",
    "part_mem_frac = 0.05\n",
    "\n",
    "# Use total device size to calculate args.device_limit_frac\n",
    "device_size = device_mem_size(kind=\"total\")\n",
    "device_limit = int(device_limit_frac * device_size)\n",
    "device_pool_size = int(device_pool_frac * device_size)\n",
    "part_size = int(part_mem_frac * device_size)\n",
    "\n",
    "# Check if any device memory is already occupied\n",
    "\"\"\"\n",
    "for dev in visible_devices.split(\",\"):\n",
    "    fmem = _pynvml_mem_size(kind=\"free\", index=int(dev))\n",
    "    used = (device_size - fmem) / 1e9\n",
    "    if used > 1.0:\n",
    "        warnings.warn(f\"BEWARE - {used} GB is already occupied on device {int(dev)}!\")\n",
    "\"\"\"\n",
    "\n",
    "cluster = None               # (Optional) Specify existing scheduler port\n",
    "if cluster is None:\n",
    "    cluster = LocalCUDACluster(\n",
    "        protocol = protocol,\n",
    "        n_workers=len(visible_devices.split(\",\")),\n",
    "        CUDA_VISIBLE_DEVICES = visible_devices,\n",
    "        device_memory_limit = device_limit,\n",
    "        local_directory=dask_workdir,\n",
    "        dashboard_address=\":\" + dashboard_port,\n",
    "    )\n",
    "\n",
    "# Create the distributed client\n",
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Jul 12 05:59:31 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 450.51.06    Driver Version: 450.51.06    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:06:00.0 Off |                    0 |\n",
      "| N/A   38C    P0    60W / 300W |    613MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    60W / 300W |    308MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:0A:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    61W / 300W |    308MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:0B:00.0 Off |                    0 |\n",
      "| N/A   42C    P0    64W / 300W |    308MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  On   | 00000000:85:00.0 Off |                    0 |\n",
      "| N/A   44C    P0    61W / 300W |    308MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  On   | 00000000:86:00.0 Off |                    0 |\n",
      "| N/A   46C    P0    63W / 300W |    308MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2...  On   | 00000000:89:00.0 Off |                    0 |\n",
      "| N/A   43C    P0    60W / 300W |    308MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2...  On   | 00000000:8A:00.0 Off |                    0 |\n",
      "| N/A   40C    P0    59W / 300W |    308MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tcp://127.0.0.1:35787': None,\n",
       " 'tcp://127.0.0.1:35845': None,\n",
       " 'tcp://127.0.0.1:38016': None,\n",
       " 'tcp://127.0.0.1:40845': None,\n",
       " 'tcp://127.0.0.1:41769': None,\n",
       " 'tcp://127.0.0.1:42950': None,\n",
       " 'tcp://127.0.0.1:46364': None,\n",
       " 'tcp://127.0.0.1:46545': None}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize RMM pool on ALL workers\n",
    "def _rmm_pool():\n",
    "    rmm.reinitialize(\n",
    "        # RMM may require the pool size to be a multiple of 256.\n",
    "        pool_allocator=True,\n",
    "        initial_pool_size=(device_pool_size // 256) * 256, # Use default size\n",
    "    )\n",
    "    \n",
    "client.run(_rmm_pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define NVTabular dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = glob.glob('./data/train.parquet')\n",
    "valid_paths = glob.glob('./data/valid.parquet')\n",
    "test_paths = glob.glob('./data/test.parquet')\n",
    "\n",
    "train_dataset = nvt.Dataset(train_paths, engine='parquet', part_mem_fraction=0.15)\n",
    "valid_dataset = nvt.Dataset(valid_paths, engine='parquet', part_mem_fraction=0.15)\n",
    "test_dataset = nvt.Dataset(test_paths, engine='parquet', part_mem_fraction=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_time</th>\n",
       "      <th>event_type</th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>price</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_session</th>\n",
       "      <th>target</th>\n",
       "      <th>cat_0</th>\n",
       "      <th>cat_1</th>\n",
       "      <th>cat_2</th>\n",
       "      <th>cat_3</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ts_hour</th>\n",
       "      <th>ts_minute</th>\n",
       "      <th>ts_weekday</th>\n",
       "      <th>ts_day</th>\n",
       "      <th>ts_month</th>\n",
       "      <th>ts_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01 00:00:10 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>1005124</td>\n",
       "      <td>apple</td>\n",
       "      <td>1453.18</td>\n",
       "      <td>532239316</td>\n",
       "      <td>253616df-2b1e-4bdf-8a0a-2d1aeef79734</td>\n",
       "      <td>0</td>\n",
       "      <td>construction</td>\n",
       "      <td>tools</td>\n",
       "      <td>light</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2020-01-01 00:00:10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-01 00:00:11 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>1201565</td>\n",
       "      <td>apple</td>\n",
       "      <td>385.34</td>\n",
       "      <td>581430108</td>\n",
       "      <td>7d7687c4-b613-4467-8a81-54c7600e0ca9</td>\n",
       "      <td>0</td>\n",
       "      <td>apparel</td>\n",
       "      <td>shoes</td>\n",
       "      <td>slipons</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2020-01-01 00:00:11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-01 00:00:22 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>13101067</td>\n",
       "      <td>skad</td>\n",
       "      <td>266.67</td>\n",
       "      <td>519373619</td>\n",
       "      <td>e97a30d7-2873-4018-9577-8cbf39b1c2c7</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2020-01-01 00:00:22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-01 00:00:26 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>4801028</td>\n",
       "      <td>xiaomi</td>\n",
       "      <td>14.95</td>\n",
       "      <td>574723072</td>\n",
       "      <td>2f967c6e-b6c4-4971-8599-d34f86570e29</td>\n",
       "      <td>0</td>\n",
       "      <td>sport</td>\n",
       "      <td>bicycle</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2020-01-01 00:00:26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-01 00:00:36 UTC</td>\n",
       "      <td>cart</td>\n",
       "      <td>1004226</td>\n",
       "      <td>apple</td>\n",
       "      <td>890.11</td>\n",
       "      <td>518285678</td>\n",
       "      <td>7dad15db-dd6d-4e59-a6c7-674612f40837</td>\n",
       "      <td>0</td>\n",
       "      <td>construction</td>\n",
       "      <td>tools</td>\n",
       "      <td>light</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2020-01-01 00:00:36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                event_time event_type  product_id   brand    price    user_id  \\\n",
       "0  2020-01-01 00:00:10 UTC       cart     1005124   apple  1453.18  532239316   \n",
       "1  2020-01-01 00:00:11 UTC       cart     1201565   apple   385.34  581430108   \n",
       "2  2020-01-01 00:00:22 UTC       cart    13101067    skad   266.67  519373619   \n",
       "3  2020-01-01 00:00:26 UTC       cart     4801028  xiaomi    14.95  574723072   \n",
       "4  2020-01-01 00:00:36 UTC       cart     1004226   apple   890.11  518285678   \n",
       "\n",
       "                           user_session  target         cat_0    cat_1  \\\n",
       "0  253616df-2b1e-4bdf-8a0a-2d1aeef79734       0  construction    tools   \n",
       "1  7d7687c4-b613-4467-8a81-54c7600e0ca9       0       apparel    shoes   \n",
       "2  e97a30d7-2873-4018-9577-8cbf39b1c2c7       0          <NA>     <NA>   \n",
       "3  2f967c6e-b6c4-4971-8599-d34f86570e29       0         sport  bicycle   \n",
       "4  7dad15db-dd6d-4e59-a6c7-674612f40837       0  construction    tools   \n",
       "\n",
       "     cat_2 cat_3            timestamp  ts_hour  ts_minute  ts_weekday  ts_day  \\\n",
       "0    light  <NA>  2020-01-01 00:00:10        0          0           2       1   \n",
       "1  slipons  <NA>  2020-01-01 00:00:11        0          0           2       1   \n",
       "2     <NA>  <NA>  2020-01-01 00:00:22        0          0           2       1   \n",
       "3     <NA>  <NA>  2020-01-01 00:00:26        0          0           2       1   \n",
       "4    light  <NA>  2020-01-01 00:00:36        0          0           2       1   \n",
       "\n",
       "   ts_month  ts_year  \n",
       "0         1     2020  \n",
       "1         1     2020  \n",
       "2         1     2020  \n",
       "3         1     2020  \n",
       "4         1     2020  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.to_ddf().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.to_ddf().columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['event_time', 'event_type', 'product_id', 'brand', 'price', 'user_id',\n",
       "       'user_session', 'target', 'cat_0', 'cat_1', 'cat_2', 'cat_3',\n",
       "       'timestamp', 'ts_hour', 'ts_minute', 'ts_weekday', 'ts_day', 'ts_month',\n",
       "       'ts_year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.to_ddf().columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7949839"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset.to_ddf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will explore a few feature engineering technique with NVTabular:\n",
    "\n",
    "- Creating cross features, e.g. `user_id` and `'brand`\n",
    "- Target encoding\n",
    "\n",
    "The engineered features will then be preprocessed into a form suitable for machine learning model:\n",
    "\n",
    "- Fill missing values\n",
    "- Encoding categorical features into integer values\n",
    "- Normalization of numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nvtabular.ops import LambdaOp\n",
    "\n",
    "# cross features\n",
    "def user_id_cross_maker(col, gdf):\n",
    "    return col.astype(str) + '_' + gdf['user_id'].astype(str)\n",
    "\n",
    "user_id_cross_features = (\n",
    "    nvt.ColumnGroup(['product_id', 'brand', 'ts_hour', 'ts_minute']) >>\n",
    "    LambdaOp(user_id_cross_maker, dependency=['user_id']) >> \n",
    "    nvt.ops.Rename(postfix = '_user_id_cross')\n",
    ")\n",
    "\n",
    "\n",
    "def user_id_brand_cross_maker(col, gdf):\n",
    "    return col.astype(str) + '_' + gdf['user_id'].astype(str) + '_' + gdf['brand'].astype(str)\n",
    "\n",
    "user_id_brand_cross_features = (\n",
    "    nvt.ColumnGroup(['ts_hour', 'ts_weekday', 'cat_0', 'cat_1', 'cat_2']) >>\n",
    "    LambdaOp(user_id_brand_cross_maker, dependency=['user_id', 'brand']) >> \n",
    "    nvt.ops.Rename(postfix = '_user_id_brand_cross')\n",
    ")\n",
    "\n",
    "target_encode = (\n",
    "    ['brand', 'user_id', 'product_id', 'cat_2', ['ts_weekday', 'ts_day']] >>\n",
    "    nvt.ops.TargetEncoding(\n",
    "        nvt.ColumnGroup('target'),\n",
    "        kfold=5,\n",
    "        p_smooth=20,\n",
    "        out_dtype=\"float32\",\n",
    "        )\n",
    ")\n",
    "\n",
    "cat_feats = (user_id_brand_cross_features + user_id_cross_features) >> nvt.ops.Categorify()\n",
    "cont_feats =  ['price', 'ts_weekday', 'ts_day', 'ts_month'] >> nvt.ops.FillMissing() >>  nvt.ops.Normalize()\n",
    "cont_feats += target_encode >> nvt.ops.Rename(postfix = '_TE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = cat_feats + cont_feats + 'target'\n",
    "proc = nvt.Workflow(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize workflow as a DAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "graphviz is already the newest version (2.42.2-3build2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"1880pt\" height=\"476pt\"\n",
       " viewBox=\"0.00 0.00 1879.62 476.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 472)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-472 1875.62,-472 1875.62,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1442.98\" cy=\"-378\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1442.98\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>2</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1364.98\" cy=\"-306\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1364.98\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1424.89,-360.76C1414.58,-351.51 1401.5,-339.77 1390.19,-329.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1392.49,-326.98 1382.71,-322.91 1387.81,-332.19 1392.49,-326.98\"/>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>17</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1442.98\" cy=\"-450\" rx=\"201.46\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1442.98\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[product_id, brand, ts_hour...]</text>\n",
       "</g>\n",
       "<!-- 17&#45;&gt;0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>17&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1442.98,-431.7C1442.98,-423.98 1442.98,-414.71 1442.98,-406.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1446.48,-406.1 1442.98,-396.1 1439.48,-406.1 1446.48,-406.1\"/>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>1</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1766.98\" cy=\"-450\" rx=\"104.78\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1766.98\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[user_id]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;0 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1704.51,-435.5C1645.62,-422.78 1558.07,-403.86 1500.76,-391.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1501.29,-388.02 1490.78,-389.33 1499.81,-394.86 1501.29,-388.02\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>10</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1093.98\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1093.98\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;10 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>2&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1326.44,-295.05C1273.54,-281.38 1179.21,-257.02 1128.5,-243.92\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1129.23,-240.49 1118.67,-241.38 1127.48,-247.27 1129.23,-240.49\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>3</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"506.98\" cy=\"-306\" rx=\"99.38\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"506.98\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[target]</text>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>12</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"567.98\" cy=\"-234\" rx=\"84.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"567.98\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">TargetEncoding</text>\n",
       "</g>\n",
       "<!-- 3&#45;&gt;12 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>3&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M521.75,-288.05C529.24,-279.46 538.48,-268.86 546.72,-259.4\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"549.42,-261.63 553.35,-251.79 544.14,-257.03 549.42,-261.63\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>4</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1014.98\" cy=\"-378\" rx=\"61.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1014.98\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">LambdaOp</text>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>9</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1093.98\" cy=\"-306\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1093.98\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 4&#45;&gt;9 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>4&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1033.31,-360.76C1043.75,-351.51 1057,-339.77 1068.45,-329.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1070.87,-332.16 1076.03,-322.91 1066.23,-326.92 1070.87,-332.16\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>5</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"579.98\" cy=\"-450\" rx=\"201.46\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"579.98\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[ts_hour, ts_weekday, cat_0...]</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>5&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M673.03,-434.03C757.42,-420.45 879.47,-400.81 952.64,-389.03\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"953.31,-392.47 962.63,-387.42 952.2,-385.56 953.31,-392.47\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>6</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"903.98\" cy=\"-450\" rx=\"104.78\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"903.98\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[user_id]</text>\n",
       "</g>\n",
       "<!-- 6&#45;&gt;4 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>6&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M930.29,-432.41C945.65,-422.72 965.18,-410.4 981.62,-400.04\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"983.8,-402.81 990.39,-394.51 980.06,-396.88 983.8,-402.81\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>7</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"1124.98\" cy=\"-450\" rx=\"98.28\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"1124.98\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[brand]</text>\n",
       "</g>\n",
       "<!-- 7&#45;&gt;4 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>7&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1099.19,-432.59C1083.98,-422.9 1064.56,-410.55 1048.2,-400.14\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1049.79,-397 1039.48,-394.59 1046.04,-402.91 1049.79,-397\"/>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>8</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"650.98\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"650.98\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">+</text>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>20</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"650.98\" cy=\"-18\" rx=\"505.81\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"650.98\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">output cols=[ts_hour_user_id_brand_cross, ts_weekday_user_id_brand_cross, cat_0_user_id_brand_cross...]</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;20 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>8&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M650.98,-71.7C650.98,-63.98 650.98,-54.71 650.98,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"654.48,-46.1 650.98,-36.1 647.48,-46.1 654.48,-46.1\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>13</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"971.98\" cy=\"-162\" rx=\"59.59\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"971.98\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Categorify</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;8 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>13&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M924.96,-150.75C859.91,-136.56 743.93,-111.27 685.97,-98.63\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"686.7,-95.21 676.18,-96.5 685.21,-102.05 686.7,-95.21\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>16</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"385.98\" cy=\"-162\" rx=\"58.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"385.98\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Normalize</text>\n",
       "</g>\n",
       "<!-- 16&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>16&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M428.85,-149.68C480.99,-135.9 567.97,-112.93 616.16,-100.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"617.34,-103.51 626.12,-97.57 615.55,-96.74 617.34,-103.51\"/>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>18</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"567.98\" cy=\"-162\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"567.98\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">Rename</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;8 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>18&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M586.82,-145.12C598.67,-135.12 614.07,-122.13 626.82,-111.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"629.36,-113.82 634.74,-104.7 624.84,-108.47 629.36,-113.82\"/>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>19</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"733.98\" cy=\"-162\" rx=\"99.38\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"733.98\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[target]</text>\n",
       "</g>\n",
       "<!-- 19&#45;&gt;8 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>19&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M713.89,-144.05C702.08,-134.1 687.09,-121.46 674.71,-111.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"676.91,-108.28 667,-104.51 672.39,-113.63 676.91,-108.28\"/>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1093.98,-287.7C1093.98,-279.98 1093.98,-270.71 1093.98,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1097.48,-262.1 1093.98,-252.1 1090.48,-262.1 1097.48,-262.1\"/>\n",
       "</g>\n",
       "<!-- 10&#45;&gt;13 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>10&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M1074.11,-221.6C1056.15,-211.29 1029.29,-195.88 1007.62,-183.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1009.11,-180.26 998.69,-178.32 1005.62,-186.34 1009.11,-180.26\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>11</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"825.98\" cy=\"-306\" rx=\"201.46\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"825.98\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[brand, user_id, product_id...]</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;12 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>11&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M766.14,-288.76C724.52,-277.47 669.27,-262.48 627.68,-251.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"628.52,-247.8 617.96,-248.56 626.69,-254.56 628.52,-247.8\"/>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;18 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>12&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M567.98,-215.7C567.98,-207.98 567.98,-198.71 567.98,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"571.48,-190.1 567.98,-180.1 564.48,-190.1 571.48,-190.1\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>14</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"194.98\" cy=\"-306\" rx=\"194.97\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"194.98\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">input cols=[price, ts_weekday, ts_day...]</text>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>15</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"267.98\" cy=\"-234\" rx=\"62.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"267.98\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">FillMissing</text>\n",
       "</g>\n",
       "<!-- 14&#45;&gt;15 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>14&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M212.65,-288.05C221.8,-279.28 233.12,-268.43 243.13,-258.83\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"245.68,-261.24 250.47,-251.79 240.83,-256.18 245.68,-261.24\"/>\n",
       "</g>\n",
       "<!-- 15&#45;&gt;16 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>15&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M294.17,-217.46C311.09,-207.43 333.29,-194.26 351.63,-183.38\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"353.46,-186.36 360.27,-178.25 349.89,-180.34 353.46,-186.36\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f8b99541580>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Executing the workflow\n",
    "\n",
    "After having defined the workflow, calling the `fit()` method will start the actual computation to record the required statistics from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 9.39 s, total: 20.4 s\n",
      "Wall time: 22.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "time_preproc_start = time()\n",
    "proc.fit(train_dataset)\n",
    "time_preproc = time()-time_preproc_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dtypes = {}\n",
    "for col in cat_feats.columns:\n",
    "    dict_dtypes[col] = np.int64\n",
    "for col in cont_feats.columns:\n",
    "    dict_dtypes[col] = np.float32\n",
    "\n",
    "dict_dtypes['target'] = np.float32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we call the `transform()` method to transform the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_train_dir = os.path.join(output_path, 'train/')\n",
    "output_valid_dir = os.path.join(output_path, 'valid/')\n",
    "output_test_dir = os.path.join(output_path, 'test/')\n",
    "! rm -rf $output_train_dir && mkdir -p $output_train_dir\n",
    "! rm -rf $output_valid_dir && mkdir -p $output_valid_dir\n",
    "! rm -rf $output_test_dir && mkdir -p $output_test_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.14 s, sys: 2.62 s, total: 4.76 s\n",
      "Wall time: 8.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "time_preproc_start = time()\n",
    "proc.transform(train_dataset).to_parquet(output_path=output_train_dir, dtypes=dict_dtypes,\n",
    "                                         shuffle=nvt.io.Shuffle.PER_PARTITION,\n",
    "                                         cats=cat_feats.columns,\n",
    "                                         conts=cont_feats.columns,\n",
    "                                         labels=['target'])\n",
    "time_preproc += time()-time_preproc_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 767915\n",
      "-rw-r--r-- 1 root dip 706360433 Jul 12 06:00 0.187d286a7350426e877b1361cbcbf51f.parquet\n",
      "-rw-r--r-- 1 root dip        75 Jul 12 06:00 _file_list.txt\n",
      "-rw-r--r-- 1 root dip     21931 Jul 12 06:00 _metadata\n",
      "-rw-r--r-- 1 root dip      1073 Jul 12 06:00 _metadata.json\n"
     ]
    }
   ],
   "source": [
    "!ls -l $output_train_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 940 ms, sys: 1.35 s, total: 2.29 s\n",
      "Wall time: 2.47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "time_preproc_start = time()\n",
    "proc.transform(valid_dataset).to_parquet(output_path=output_valid_dir, dtypes=dict_dtypes,\n",
    "                                         shuffle=nvt.io.Shuffle.PER_PARTITION,\n",
    "                                         cats=cat_feats.columns,\n",
    "                                         conts=cont_feats.columns,\n",
    "                                         labels=['target'])\n",
    "time_preproc += time()-time_preproc_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 100539\n",
      "-rw-r--r-- 1 root dip 92438411 Jul 12 06:00 0.b0fc84833238495c9a7241a03aa8c4a0.parquet\n",
      "-rw-r--r-- 1 root dip       75 Jul 12 06:00 _file_list.txt\n",
      "-rw-r--r-- 1 root dip    10351 Jul 12 06:00 _metadata\n",
      "-rw-r--r-- 1 root dip     1073 Jul 12 06:00 _metadata.json\n"
     ]
    }
   ],
   "source": [
    "!ls -l $output_valid_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 932 ms, sys: 1.14 s, total: 2.07 s\n",
      "Wall time: 2.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "time_preproc_start = time()\n",
    "proc.transform(test_dataset).to_parquet(output_path=output_test_dir, dtypes=dict_dtypes,\n",
    "                                         shuffle=nvt.io.Shuffle.PER_PARTITION,\n",
    "                                         cats=cat_feats.columns,\n",
    "                                         conts=cont_feats.columns,\n",
    "                                         labels=['target'])\n",
    "time_preproc += time()-time_preproc_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.99239206314087"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_preproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify the preprocessed data\n",
    "\n",
    "Let's quickly read the data back and verify that all fields have the expected format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_hour_user_id_brand_cross</th>\n",
       "      <th>ts_weekday_user_id_brand_cross</th>\n",
       "      <th>cat_0_user_id_brand_cross</th>\n",
       "      <th>cat_1_user_id_brand_cross</th>\n",
       "      <th>cat_2_user_id_brand_cross</th>\n",
       "      <th>product_id_user_id_cross</th>\n",
       "      <th>brand_user_id_cross</th>\n",
       "      <th>ts_hour_user_id_cross</th>\n",
       "      <th>ts_minute_user_id_cross</th>\n",
       "      <th>price</th>\n",
       "      <th>ts_weekday</th>\n",
       "      <th>ts_day</th>\n",
       "      <th>ts_month</th>\n",
       "      <th>TE_brand_target_TE</th>\n",
       "      <th>TE_user_id_target_TE</th>\n",
       "      <th>TE_product_id_target_TE</th>\n",
       "      <th>TE_cat_2_target_TE</th>\n",
       "      <th>TE_ts_weekday_ts_day_target_TE</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1702468</td>\n",
       "      <td>1914940</td>\n",
       "      <td>1420609</td>\n",
       "      <td>2061648</td>\n",
       "      <td>795164</td>\n",
       "      <td>1631369</td>\n",
       "      <td>2825650</td>\n",
       "      <td>1539344</td>\n",
       "      <td>1723039</td>\n",
       "      <td>-0.307055</td>\n",
       "      <td>-0.007929</td>\n",
       "      <td>1.157649</td>\n",
       "      <td>1.314784</td>\n",
       "      <td>0.364934</td>\n",
       "      <td>0.377139</td>\n",
       "      <td>0.410295</td>\n",
       "      <td>0.459572</td>\n",
       "      <td>0.408560</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3122932</td>\n",
       "      <td>0</td>\n",
       "      <td>445028</td>\n",
       "      <td>259068</td>\n",
       "      <td>-0.493823</td>\n",
       "      <td>-0.502085</td>\n",
       "      <td>-0.456215</td>\n",
       "      <td>-0.666240</td>\n",
       "      <td>-1.289363</td>\n",
       "      <td>0.426331</td>\n",
       "      <td>0.545904</td>\n",
       "      <td>0.422698</td>\n",
       "      <td>0.555064</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1949005</td>\n",
       "      <td>0</td>\n",
       "      <td>731583</td>\n",
       "      <td>1467440</td>\n",
       "      <td>-0.850879</td>\n",
       "      <td>1.474540</td>\n",
       "      <td>-0.456215</td>\n",
       "      <td>-0.864342</td>\n",
       "      <td>-1.289097</td>\n",
       "      <td>0.354801</td>\n",
       "      <td>0.040850</td>\n",
       "      <td>-1.284724</td>\n",
       "      <td>0.405450</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4323785</td>\n",
       "      <td>0</td>\n",
       "      <td>230057</td>\n",
       "      <td>472287</td>\n",
       "      <td>0.928795</td>\n",
       "      <td>0.980384</td>\n",
       "      <td>0.581269</td>\n",
       "      <td>1.314784</td>\n",
       "      <td>-1.281996</td>\n",
       "      <td>0.217903</td>\n",
       "      <td>0.185848</td>\n",
       "      <td>-1.286561</td>\n",
       "      <td>0.413379</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3886418</td>\n",
       "      <td>1822928</td>\n",
       "      <td>496027</td>\n",
       "      <td>667474</td>\n",
       "      <td>2004982</td>\n",
       "      <td>3542749</td>\n",
       "      <td>1966466</td>\n",
       "      <td>3511160</td>\n",
       "      <td>4769922</td>\n",
       "      <td>-0.650051</td>\n",
       "      <td>-0.007929</td>\n",
       "      <td>-0.456215</td>\n",
       "      <td>1.314784</td>\n",
       "      <td>0.466245</td>\n",
       "      <td>0.366901</td>\n",
       "      <td>0.449289</td>\n",
       "      <td>0.382346</td>\n",
       "      <td>0.369620</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ts_hour_user_id_brand_cross  ts_weekday_user_id_brand_cross  \\\n",
       "0                      1702468                         1914940   \n",
       "1                            0                               0   \n",
       "2                            0                               0   \n",
       "3                            0                               0   \n",
       "4                      3886418                         1822928   \n",
       "\n",
       "   cat_0_user_id_brand_cross  cat_1_user_id_brand_cross  \\\n",
       "0                    1420609                    2061648   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                     496027                     667474   \n",
       "\n",
       "   cat_2_user_id_brand_cross  product_id_user_id_cross  brand_user_id_cross  \\\n",
       "0                     795164                   1631369              2825650   \n",
       "1                          0                   3122932                    0   \n",
       "2                          0                   1949005                    0   \n",
       "3                          0                   4323785                    0   \n",
       "4                    2004982                   3542749              1966466   \n",
       "\n",
       "   ts_hour_user_id_cross  ts_minute_user_id_cross     price  ts_weekday  \\\n",
       "0                1539344                  1723039 -0.307055   -0.007929   \n",
       "1                 445028                   259068 -0.493823   -0.502085   \n",
       "2                 731583                  1467440 -0.850879    1.474540   \n",
       "3                 230057                   472287  0.928795    0.980384   \n",
       "4                3511160                  4769922 -0.650051   -0.007929   \n",
       "\n",
       "     ts_day  ts_month  TE_brand_target_TE  TE_user_id_target_TE  \\\n",
       "0  1.157649  1.314784            0.364934              0.377139   \n",
       "1 -0.456215 -0.666240           -1.289363              0.426331   \n",
       "2 -0.456215 -0.864342           -1.289097              0.354801   \n",
       "3  0.581269  1.314784           -1.281996              0.217903   \n",
       "4 -0.456215  1.314784            0.466245              0.366901   \n",
       "\n",
       "   TE_product_id_target_TE  TE_cat_2_target_TE  \\\n",
       "0                 0.410295            0.459572   \n",
       "1                 0.545904            0.422698   \n",
       "2                 0.040850           -1.284724   \n",
       "3                 0.185848           -1.286561   \n",
       "4                 0.449289            0.382346   \n",
       "\n",
       "   TE_ts_weekday_ts_day_target_TE  target  \n",
       "0                        0.408560     0.0  \n",
       "1                        0.555064     1.0  \n",
       "2                        0.405450     0.0  \n",
       "3                        0.413379     0.0  \n",
       "4                        0.369620     1.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvtdata = pd.read_parquet(output_train_dir)\n",
    "nvtdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_hour_user_id_brand_cross</th>\n",
       "      <th>ts_weekday_user_id_brand_cross</th>\n",
       "      <th>cat_0_user_id_brand_cross</th>\n",
       "      <th>cat_1_user_id_brand_cross</th>\n",
       "      <th>cat_2_user_id_brand_cross</th>\n",
       "      <th>product_id_user_id_cross</th>\n",
       "      <th>brand_user_id_cross</th>\n",
       "      <th>ts_hour_user_id_cross</th>\n",
       "      <th>ts_minute_user_id_cross</th>\n",
       "      <th>price</th>\n",
       "      <th>ts_weekday</th>\n",
       "      <th>ts_day</th>\n",
       "      <th>ts_month</th>\n",
       "      <th>TE_brand_target_TE</th>\n",
       "      <th>TE_user_id_target_TE</th>\n",
       "      <th>TE_product_id_target_TE</th>\n",
       "      <th>TE_cat_2_target_TE</th>\n",
       "      <th>TE_ts_weekday_ts_day_target_TE</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.311681</td>\n",
       "      <td>-0.502085</td>\n",
       "      <td>-0.571491</td>\n",
       "      <td>-0.468138</td>\n",
       "      <td>0.094309</td>\n",
       "      <td>0.419315</td>\n",
       "      <td>0.368925</td>\n",
       "      <td>-1.285230</td>\n",
       "      <td>0.376006</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.784008</td>\n",
       "      <td>1.474540</td>\n",
       "      <td>-1.724251</td>\n",
       "      <td>-0.468138</td>\n",
       "      <td>0.211300</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.393520</td>\n",
       "      <td>-1.286561</td>\n",
       "      <td>0.389836</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1392408</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.476485</td>\n",
       "      <td>-0.502085</td>\n",
       "      <td>-1.378423</td>\n",
       "      <td>-0.468138</td>\n",
       "      <td>0.453972</td>\n",
       "      <td>0.350201</td>\n",
       "      <td>0.527262</td>\n",
       "      <td>0.459460</td>\n",
       "      <td>0.421816</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.656416</td>\n",
       "      <td>-0.996241</td>\n",
       "      <td>-1.493699</td>\n",
       "      <td>-0.468138</td>\n",
       "      <td>0.426964</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.331059</td>\n",
       "      <td>0.422271</td>\n",
       "      <td>0.400376</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2947934</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.626371</td>\n",
       "      <td>-0.502085</td>\n",
       "      <td>-0.571491</td>\n",
       "      <td>-0.468138</td>\n",
       "      <td>0.355599</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.306809</td>\n",
       "      <td>-1.287655</td>\n",
       "      <td>0.374874</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ts_hour_user_id_brand_cross  ts_weekday_user_id_brand_cross  \\\n",
       "0                            0                               0   \n",
       "1                            0                               0   \n",
       "2                            0                               0   \n",
       "3                            0                               0   \n",
       "4                            0                               0   \n",
       "\n",
       "   cat_0_user_id_brand_cross  cat_1_user_id_brand_cross  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   cat_2_user_id_brand_cross  product_id_user_id_cross  brand_user_id_cross  \\\n",
       "0                          0                         0                    0   \n",
       "1                          0                         0                    0   \n",
       "2                          0                         0                    0   \n",
       "3                          0                         0                    0   \n",
       "4                          0                         0                    0   \n",
       "\n",
       "   ts_hour_user_id_cross  ts_minute_user_id_cross     price  ts_weekday  \\\n",
       "0                      0                        0 -0.311681   -0.502085   \n",
       "1                      0                        0 -0.784008    1.474540   \n",
       "2                1392408                        0 -0.476485   -0.502085   \n",
       "3                      0                        0  1.656416   -0.996241   \n",
       "4                2947934                        0 -0.626371   -0.502085   \n",
       "\n",
       "     ts_day  ts_month  TE_brand_target_TE  TE_user_id_target_TE  \\\n",
       "0 -0.571491 -0.468138            0.094309              0.419315   \n",
       "1 -1.724251 -0.468138            0.211300              0.390281   \n",
       "2 -1.378423 -0.468138            0.453972              0.350201   \n",
       "3 -1.493699 -0.468138            0.426964              0.390281   \n",
       "4 -0.571491 -0.468138            0.355599              0.390281   \n",
       "\n",
       "   TE_product_id_target_TE  TE_cat_2_target_TE  \\\n",
       "0                 0.368925           -1.285230   \n",
       "1                 0.393520           -1.286561   \n",
       "2                 0.527262            0.459460   \n",
       "3                 0.331059            0.422271   \n",
       "4                 0.306809           -1.287655   \n",
       "\n",
       "   TE_ts_weekday_ts_day_target_TE  target  \n",
       "0                        0.376006     0.0  \n",
       "1                        0.389836     0.0  \n",
       "2                        0.421816     0.0  \n",
       "3                        0.400376     0.0  \n",
       "4                        0.374874     0.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nvtdata_valid = pd.read_parquet(output_valid_dir)\n",
    "nvtdata_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2359020"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(nvtdata_valid['ts_hour_user_id_brand_cross']==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2461719"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nvtdata_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the embedding size\n",
    "\n",
    "Next, we need to get the embedding size for the categorical variables. This is an important input for defining the embedding table size to be used by HugeCTR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brand_user_id_cross': (3009092, 512),\n",
       " 'cat_0_user_id_brand_cross': (2877223, 512),\n",
       " 'cat_1_user_id_brand_cross': (2890639, 512),\n",
       " 'cat_2_user_id_brand_cross': (2159304, 512),\n",
       " 'product_id_user_id_cross': (4398425, 512),\n",
       " 'ts_hour_user_id_brand_cross': (4427037, 512),\n",
       " 'ts_hour_user_id_cross': (3999369, 512),\n",
       " 'ts_minute_user_id_cross': (5931061, 512),\n",
       " 'ts_weekday_user_id_brand_cross': (3961156, 512)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = ops.get_embedding_sizes(proc)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4427037, 3961156, 2877223, 2890639, 2159304, 4398425, 3009092, 3999369, 5931061]\n"
     ]
    }
   ],
   "source": [
    "print([embeddings[x][0] for x in cat_feats.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ts_hour_user_id_brand_cross',\n",
       " 'ts_weekday_user_id_brand_cross',\n",
       " 'cat_0_user_id_brand_cross',\n",
       " 'cat_1_user_id_brand_cross',\n",
       " 'cat_2_user_id_brand_cross',\n",
       " 'product_id_user_id_cross',\n",
       " 'brand_user_id_cross',\n",
       " 'ts_hour_user_id_cross',\n",
       " 'ts_minute_user_id_cross']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[4427037, 3961156, 2877223, 2890639, 2159304, 4398425, 3009092, 3999369, 5931061]'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_size_str = \"{}\".format([embeddings[x][0] for x in cat_feats.columns])\n",
    "embedding_size_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_con_feates = len(cont_feats.columns)\n",
    "num_con_feates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price',\n",
       " 'ts_weekday',\n",
       " 'ts_day',\n",
       " 'ts_month',\n",
       " 'TE_brand_target_TE',\n",
       " 'TE_user_id_target_TE',\n",
       " 'TE_product_id_target_TE',\n",
       " 'TE_cat_2_target_TE',\n",
       " 'TE_ts_weekday_ts_day_target_TE']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cont_feats.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4427037, 3961156, 2877223, 2890639, 2159304, 4398425, 3009092, 3999369, 5931061]\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print([embeddings[x][0] for x in cat_feats.columns])\n",
    "print(len(cont_feats.columns))\n",
    "print(len(cat_feats.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll shutdown our Dask client from earlier to free up some memory so that we can share it with HugeCTR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.shutdown()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the training Python script for HugeCTR\n",
    "\n",
    "HugeCTR model can be defined by Python API. The below Python script defines a DLRM model and specifies the training resources. \n",
    "\n",
    "Several parameters that need to be edited to match this dataset are:\n",
    "\n",
    "- `slot_size_array`: cadinalities for the categorical variables\n",
    "- `dense_dim`: number of dense features\n",
    "- `slot_num`: number of categorical variables\n",
    "\n",
    "The model graph can be saved into a JSON file by calling `model.graph_to_json`, which will be used for inference afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting hugectr_dlrm_ecommerce.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile hugectr_dlrm_ecommerce.py\n",
    "import hugectr\n",
    "from mpi4py import MPI\n",
    "solver = hugectr.CreateSolver(max_eval_batches = 2720,\n",
    "                              batchsize_eval = 16384,\n",
    "                              batchsize = 16384,\n",
    "                              lr = 0.1,\n",
    "                              warmup_steps = 8000,\n",
    "                              decay_start = 48000,\n",
    "                              decay_steps = 24000,\n",
    "                              vvgpu = [[0,1,2,3]],\n",
    "                              repeat_dataset = True,\n",
    "                              i64_input_key = True)\n",
    "reader = hugectr.DataReaderParams(data_reader_type = hugectr.DataReaderType_t.Parquet,\n",
    "                                  source = [\"./nvtabular_temp/output/train/_file_list.txt\"],\n",
    "                                  eval_source = \"./nvtabular_temp/output/valid/_file_list.txt\",\n",
    "                                  check_type = hugectr.Check_t.Non,\n",
    "                                  slot_size_array = [4427037, 3961156, 2877223, 2890639, 2159304, 4398425, 3009092, 3999369, 5931061])\n",
    "optimizer = hugectr.CreateOptimizer(optimizer_type = hugectr.Optimizer_t.SGD,\n",
    "                                    update_type = hugectr.Update_t.Local,\n",
    "                                    atomic_update = True)\n",
    "model = hugectr.Model(solver, reader, optimizer)\n",
    "model.add(hugectr.Input(label_dim = 1, label_name = \"label\",\n",
    "                        dense_dim = 9, dense_name = \"dense\",\n",
    "                        data_reader_sparse_param_array = \n",
    "                        [hugectr.DataReaderSparseParam(\"data1\", 1, True, 9)]))\n",
    "model.add(hugectr.SparseEmbedding(embedding_type = hugectr.Embedding_t.DistributedSlotSparseEmbeddingHash,\n",
    "                            workspace_size_per_gpu_in_mb = 4883,\n",
    "                            embedding_vec_size = 128,\n",
    "                            combiner = 'sum',\n",
    "                            sparse_embedding_name = \"sparse_embedding1\",\n",
    "                            bottom_name = \"data1\",\n",
    "                            optimizer = optimizer))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"dense\"],\n",
    "                            top_names = [\"fc1\"],\n",
    "                            num_output=512))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc1\"],\n",
    "                            top_names = [\"relu1\"]))                           \n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"relu1\"],\n",
    "                            top_names = [\"fc2\"],\n",
    "                            num_output=256))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc2\"],\n",
    "                            top_names = [\"relu2\"]))                            \n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"relu2\"],\n",
    "                            top_names = [\"fc3\"],\n",
    "                            num_output=128))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc3\"],\n",
    "                            top_names = [\"relu3\"]))                              \n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.Interaction,\n",
    "                            bottom_names = [\"relu3\",\"sparse_embedding1\"],\n",
    "                            top_names = [\"interaction1\"]))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"interaction1\"],\n",
    "                            top_names = [\"fc4\"],\n",
    "                            num_output=1024))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc4\"],\n",
    "                            top_names = [\"relu4\"]))                              \n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"relu4\"],\n",
    "                            top_names = [\"fc5\"],\n",
    "                            num_output=1024))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc5\"],\n",
    "                            top_names = [\"relu5\"]))                              \n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"relu5\"],\n",
    "                            top_names = [\"fc6\"],\n",
    "                            num_output=512))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc6\"],\n",
    "                            top_names = [\"relu6\"]))                               \n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"relu6\"],\n",
    "                            top_names = [\"fc7\"],\n",
    "                            num_output=256))\n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.ReLU,\n",
    "                            bottom_names = [\"fc7\"],\n",
    "                            top_names = [\"relu7\"]))                                                                              \n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.InnerProduct,\n",
    "                            bottom_names = [\"relu7\"],\n",
    "                            top_names = [\"fc8\"],\n",
    "                            num_output=1))                                                                                           \n",
    "model.add(hugectr.DenseLayer(layer_type = hugectr.Layer_t.BinaryCrossEntropyLoss,\n",
    "                            bottom_names = [\"fc8\", \"label\"],\n",
    "                            top_names = [\"loss\"]))\n",
    "model.compile()\n",
    "model.summary()\n",
    "model.graph_to_json(graph_config_file = \"dlrm_ecommerce.json\")\n",
    "model.fit(max_iter = 12000, display = 1000, eval_interval = 3000, snapshot = 10000, snapshot_prefix = \"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3. HugeCTR training\n",
    "\n",
    "Now we are ready to train a DLRM model with HugeCTR.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================Model Init=====================================================\n",
      "[12d06h09m18s][HUGECTR][INFO]: Global seed is 3594265474\n",
      "Device 0: Tesla V100-SXM2-16GB\n",
      "Device 1: Tesla V100-SXM2-16GB\n",
      "Device 2: Tesla V100-SXM2-16GB\n",
      "Device 3: Tesla V100-SXM2-16GB\n",
      "[12d06h09m24s][HUGECTR][INFO]: num of DataReader workers: 4\n",
      "[12d06h09m24s][HUGECTR][INFO]: max_vocabulary_size_per_gpu_=10000384\n",
      "===================================================Model Compile===================================================\n",
      "[12d06h10m36s][HUGECTR][INFO]: gpu0 start to init embedding[\n",
      "[1212d0d0606hh10m10m3636s][HUGECTR][INFO]: gpu3 start to init embeddings\n",
      "][HUGECTR][INFO]: gpu1 start to init embedding\n",
      "[12d06h10m36s][HUGECTR][INFO]: gpu2 start to init embedding\n",
      "[12d06h10m36s][HUGECTR][INFO]: gpu3 init embedding done\n",
      "[12d06h10m36s][HUGECTR][INFO]: gpu2 init embedding done\n",
      "[12d06h10m36s][HUGECTR][INFO]: gpu0 init embedding done\n",
      "[12d06h10m36s][HUGECTR][INFO]: gpu1 init embedding done\n",
      "===================================================Model Summary===================================================\n",
      "Label                                   Dense                         Sparse                        \n",
      "label                                   dense                          data1                         \n",
      "(None, 1)                               (None, 9)                               \n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "Layer Type                              Input Name                    Output Name                   Output Shape                  \n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "DistributedSlotSparseEmbeddingHash      data1                         sparse_embedding1             (None, 9, 128)                \n",
      "InnerProduct                            dense                         fc1                           (None, 512)                   \n",
      "ReLU                                    fc1                           relu1                         (None, 512)                   \n",
      "InnerProduct                            relu1                         fc2                           (None, 256)                   \n",
      "ReLU                                    fc2                           relu2                         (None, 256)                   \n",
      "InnerProduct                            relu2                         fc3                           (None, 128)                   \n",
      "ReLU                                    fc3                           relu3                         (None, 128)                   \n",
      "Interaction                             relu3,sparse_embedding1       interaction1                  (None, 174)                   \n",
      "InnerProduct                            interaction1                  fc4                           (None, 1024)                  \n",
      "ReLU                                    fc4                           relu4                         (None, 1024)                  \n",
      "InnerProduct                            relu4                         fc5                           (None, 1024)                  \n",
      "ReLU                                    fc5                           relu5                         (None, 1024)                  \n",
      "InnerProduct                            relu5                         fc6                           (None, 512)                   \n",
      "ReLU                                    fc6                           relu6                         (None, 512)                   \n",
      "InnerProduct                            relu6                         fc7                           (None, 256)                   \n",
      "ReLU                                    fc7                           relu7                         (None, 256)                   \n",
      "InnerProduct                            relu7                         fc8                           (None, 1)                     \n",
      "BinaryCrossEntropyLoss                  fc8,label                     loss                                                        \n",
      "------------------------------------------------------------------------------------------------------------------\n",
      "[12d60h10m36s][HUGECTR][INFO]: Save the model graph to dlrm_ecommerce.json, successful\n",
      "=====================================================Model Fit=====================================================\n",
      "[12d60h10m36s][HUGECTR][INFO]: Use non-epoch mode with number of iterations: 12000\n",
      "[12d60h10m36s][HUGECTR][INFO]: Training batchsize: 16384, evaluation batchsize: 16384\n",
      "[12d60h10m36s][HUGECTR][INFO]: Evaluation interval: 3000, snapshot interval: 10000\n",
      "[12d60h10m36s][HUGECTR][INFO]: Sparse embedding trainable: 1, dense network trainable: 1\n",
      "[12d60h10m36s][HUGECTR][INFO]: Use mixed precision: 0, scaler: 1.000000, use cuda graph: 1\n",
      "[12d60h10m36s][HUGECTR][INFO]: lr: 0.100000, warmup_steps: 8000, decay_start: 48000, decay_steps: 24000, decay_power: 2.000000, end_lr: 0.000000\n",
      "[12d60h10m36s][HUGECTR][INFO]: Training source file: ./nvtabular_temp/output/train/_file_list.txt\n",
      "[12d60h10m36s][HUGECTR][INFO]: Evaluation source file: ./nvtabular_temp/output/valid/_file_list.txt\n",
      "[12d60h10m44s][HUGECTR][INFO]: Iter: 1000 Time(1000 iters): 7.665220s Loss: 0.653065 lr:0.012512\n",
      "[12d60h10m52s][HUGECTR][INFO]: Iter: 2000 Time(1000 iters): 7.689930s Loss: 0.528752 lr:0.025013\n",
      "[12d60h10m59s][HUGECTR][INFO]: Iter: 3000 Time(1000 iters): 7.629534s Loss: 0.526933 lr:0.037512\n",
      "[12d60h11m22s][HUGECTR][INFO]: Evaluation, AUC: 0.648711\n",
      "[12d60h11m22s][HUGECTR][INFO]: Eval Time for 2720 iters: 22.321903s\n",
      "[12d60h11m29s][HUGECTR][INFO]: Iter: 4000 Time(1000 iters): 30.022837s Loss: 0.506167 lr:0.050012\n",
      "[12d60h11m37s][HUGECTR][INFO]: Iter: 5000 Time(1000 iters): 7.661832s Loss: 0.523222 lr:0.062513\n",
      "[12d60h11m45s][HUGECTR][INFO]: Iter: 6000 Time(1000 iters): 7.689628s Loss: 0.500767 lr:0.075013\n",
      "[12d60h12m70s][HUGECTR][INFO]: Evaluation, AUC: 0.650302\n",
      "[12d60h12m70s][HUGECTR][INFO]: Eval Time for 2720 iters: 22.313590s\n",
      "[12d60h12m15s][HUGECTR][INFO]: Iter: 7000 Time(1000 iters): 29.978754s Loss: 0.519886 lr:0.087513\n",
      "[12d60h12m22s][HUGECTR][INFO]: Iter: 8000 Time(1000 iters): 7.689465s Loss: 0.511019 lr:0.100000\n",
      "[12d60h12m30s][HUGECTR][INFO]: Iter: 9000 Time(1000 iters): 7.657638s Loss: 0.517614 lr:0.100000\n",
      "[12d60h12m52s][HUGECTR][INFO]: Evaluation, AUC: 0.646990\n",
      "[12d60h12m52s][HUGECTR][INFO]: Eval Time for 2720 iters: 22.289129s\n",
      "[12d60h13m00s][HUGECTR][INFO]: Iter: 10000 Time(1000 iters): 29.954833s Loss: 0.494307 lr:0.100000\n",
      "[12d60h13m90s][HUGECTR][INFO]: Rank0: Write hash table to file\n",
      "[12d60h14m50s][HUGECTR][INFO]: Dumping sparse weights to files, successful\n",
      "[12d60h14m50s][HUGECTR][INFO]: Dumping sparse optimzer states to files, successful\n",
      "[12d60h14m50s][HUGECTR][INFO]: Dumping dense weights to file, successful\n",
      "[12d60h14m50s][HUGECTR][INFO]: Dumping dense optimizer states to file, successful\n",
      "[12d60h14m50s][HUGECTR][INFO]: Dumping untrainable weights to file, successful\n",
      "[12d60h14m13s][HUGECTR][INFO]: Iter: 11000 Time(1000 iters): 73.121730s Loss: 0.521651 lr:0.100000\n"
     ]
    }
   ],
   "source": [
    "!python3 hugectr_dlrm_ecommerce.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "## 4. HugeCTR inference\n",
    "\n",
    "In this section, we will read the test dataset, and compute the AUC value. \n",
    "\n",
    "We will utilize the saved model graph in JSON format for inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the inference session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from hugectr.inference import InferenceParams, CreateInferenceSession\n",
    "from mpi4py import MPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12d06h15m03s][HUGECTR][INFO]: default_emb_vec_value is not specified using default: 0.000000\n",
      "[12d06h16m49s][HUGECTR][INFO]: Global seed is 1517370373\n",
      "[12d06h16m50s][HUGECTR][INFO]: Peer-to-peer access cannot be fully enabled.\n",
      "[12d06h16m50s][HUGECTR][INFO]: Use mixed precision: 0\n",
      "[12d06h16m50s][HUGECTR][INFO]: start create embedding for inference\n",
      "[12d06h16m50s][HUGECTR][INFO]: sparse_input name data1\n",
      "[12d06h16m50s][HUGECTR][INFO]: create embedding for inference success\n",
      "[12d06h16m50s][HUGECTR][INFO]: Inference stage skip BinaryCrossEntropyLoss layer, replaced by Sigmoid layer\n"
     ]
    }
   ],
   "source": [
    "# create inference session\n",
    "inference_params = InferenceParams(model_name = \"dlrm\",\n",
    "                              max_batchsize = 4096,\n",
    "                              hit_rate_threshold = 0.6,\n",
    "                              dense_model_file = \"./_dense_10000.model\",\n",
    "                              sparse_model_files = [\"./0_sparse_10000.model\"],\n",
    "                              device_id = 0,\n",
    "                              use_gpu_embedding_cache = True,\n",
    "                              cache_size_percentage = 0.2,\n",
    "                              i64_input_key = True)\n",
    "inference_session = CreateInferenceSession(\"dlrm_ecommerce.json\", inference_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and prepare the data\n",
    "\n",
    "We first read the NVTabular processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ts_hour_user_id_brand_cross</th>\n",
       "      <th>ts_weekday_user_id_brand_cross</th>\n",
       "      <th>cat_0_user_id_brand_cross</th>\n",
       "      <th>cat_1_user_id_brand_cross</th>\n",
       "      <th>cat_2_user_id_brand_cross</th>\n",
       "      <th>product_id_user_id_cross</th>\n",
       "      <th>brand_user_id_cross</th>\n",
       "      <th>ts_hour_user_id_cross</th>\n",
       "      <th>ts_minute_user_id_cross</th>\n",
       "      <th>price</th>\n",
       "      <th>ts_weekday</th>\n",
       "      <th>ts_day</th>\n",
       "      <th>ts_month</th>\n",
       "      <th>TE_brand_target_TE</th>\n",
       "      <th>TE_user_id_target_TE</th>\n",
       "      <th>TE_product_id_target_TE</th>\n",
       "      <th>TE_cat_2_target_TE</th>\n",
       "      <th>TE_ts_weekday_ts_day_target_TE</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.422081</td>\n",
       "      <td>-0.502085</td>\n",
       "      <td>0.696545</td>\n",
       "      <td>-0.270035</td>\n",
       "      <td>0.466245</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.534358</td>\n",
       "      <td>0.459729</td>\n",
       "      <td>0.404632</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3044537</td>\n",
       "      <td>0</td>\n",
       "      <td>0.177097</td>\n",
       "      <td>0.980384</td>\n",
       "      <td>-0.571491</td>\n",
       "      <td>-0.270035</td>\n",
       "      <td>-1.289483</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.280030</td>\n",
       "      <td>-1.290198</td>\n",
       "      <td>0.417089</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.503718</td>\n",
       "      <td>0.486228</td>\n",
       "      <td>0.927097</td>\n",
       "      <td>-0.270035</td>\n",
       "      <td>0.312325</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.290619</td>\n",
       "      <td>-1.284724</td>\n",
       "      <td>0.433664</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.771479</td>\n",
       "      <td>-1.490397</td>\n",
       "      <td>0.465993</td>\n",
       "      <td>-0.270035</td>\n",
       "      <td>-1.289097</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.330096</td>\n",
       "      <td>-1.284724</td>\n",
       "      <td>0.399351</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.691742</td>\n",
       "      <td>-0.996241</td>\n",
       "      <td>0.581269</td>\n",
       "      <td>-0.270035</td>\n",
       "      <td>0.334554</td>\n",
       "      <td>0.390281</td>\n",
       "      <td>0.454499</td>\n",
       "      <td>0.353616</td>\n",
       "      <td>0.397146</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ts_hour_user_id_brand_cross  ts_weekday_user_id_brand_cross  \\\n",
       "0                            0                               0   \n",
       "1                            0                               0   \n",
       "2                            0                               0   \n",
       "3                            0                               0   \n",
       "4                            0                               0   \n",
       "\n",
       "   cat_0_user_id_brand_cross  cat_1_user_id_brand_cross  \\\n",
       "0                          0                          0   \n",
       "1                          0                          0   \n",
       "2                          0                          0   \n",
       "3                          0                          0   \n",
       "4                          0                          0   \n",
       "\n",
       "   cat_2_user_id_brand_cross  product_id_user_id_cross  brand_user_id_cross  \\\n",
       "0                          0                         0                    0   \n",
       "1                          0                         0                    0   \n",
       "2                          0                         0                    0   \n",
       "3                          0                         0                    0   \n",
       "4                          0                         0                    0   \n",
       "\n",
       "   ts_hour_user_id_cross  ts_minute_user_id_cross     price  ts_weekday  \\\n",
       "0                      0                        0 -0.422081   -0.502085   \n",
       "1                3044537                        0  0.177097    0.980384   \n",
       "2                      0                        0 -0.503718    0.486228   \n",
       "3                      0                        0 -0.771479   -1.490397   \n",
       "4                      0                        0 -0.691742   -0.996241   \n",
       "\n",
       "     ts_day  ts_month  TE_brand_target_TE  TE_user_id_target_TE  \\\n",
       "0  0.696545 -0.270035            0.466245              0.390281   \n",
       "1 -0.571491 -0.270035           -1.289483              0.390281   \n",
       "2  0.927097 -0.270035            0.312325              0.390281   \n",
       "3  0.465993 -0.270035           -1.289097              0.390281   \n",
       "4  0.581269 -0.270035            0.334554              0.390281   \n",
       "\n",
       "   TE_product_id_target_TE  TE_cat_2_target_TE  \\\n",
       "0                 0.534358            0.459729   \n",
       "1                 0.280030           -1.290198   \n",
       "2                 0.290619           -1.284724   \n",
       "3                 0.330096           -1.284724   \n",
       "4                 0.454499            0.353616   \n",
       "\n",
       "   TE_ts_weekday_ts_day_target_TE  target  \n",
       "0                        0.404632     0.0  \n",
       "1                        0.417089     0.0  \n",
       "2                        0.433664     0.0  \n",
       "3                        0.399351     0.0  \n",
       "4                        0.397146     0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "nvtdata_test = pd.read_parquet('./nvtabular_temp/output/test')\n",
    "nvtdata_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "con_feats = ['price',\n",
    " 'ts_weekday',\n",
    " 'ts_day',\n",
    " 'ts_month',\n",
    " 'TE_brand_target_TE',\n",
    " 'TE_user_id_target_TE',\n",
    " 'TE_product_id_target_TE',\n",
    " 'TE_cat_2_target_TE',\n",
    " 'TE_ts_weekday_ts_day_target_TE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = ['ts_hour_user_id_brand_cross',\n",
    " 'ts_weekday_user_id_brand_cross',\n",
    " 'cat_0_user_id_brand_cross',\n",
    " 'cat_1_user_id_brand_cross',\n",
    " 'cat_2_user_id_brand_cross',\n",
    " 'product_id_user_id_cross',\n",
    " 'brand_user_id_cross',\n",
    " 'ts_hour_user_id_cross',\n",
    " 'ts_minute_user_id_cross']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = [4427037, 3961156, 2877223, 2890639, 2159304, 4398425, 3009092, 3999369, 5931061]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting data to CSR format\n",
    "\n",
    "HugeCTR expects data in CSR format for inference. One important thing to note is that NVTabular requires categorical variables to occupy different integer ranges. For example, if there are 10 users and 10 items, then the users should be encoded in the 0-9 range, while items should be in the 10-19 range. NVTabular encodes both users and items in the 0-9 ranges.\n",
    "\n",
    "For this reason, we need to shift the keys of the categorical variable produced by NVTabular to comply with HugeCTR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "shift = np.insert(np.cumsum(emb_size), 0, 0)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_data = nvtdata_test[cat_feats].values + shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_data = nvtdata_test[con_feats].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_batch(inference_session, dense_data_batch, cat_data_batch):\n",
    "    dense_features = list(dense_data_batch.flatten())\n",
    "    embedding_columns = list(cat_data_batch.flatten())\n",
    "    row_ptrs= list(range(0,len(embedding_columns)+1))\n",
    "    output = inference_session.predict(dense_features, embedding_columns, row_ptrs)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to carry out inference on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4096\n",
    "num_batches = (len(dense_data) // batch_size) + 1\n",
    "batch_idx = np.array_split(np.arange(len(dense_data)), num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (4.59.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 677/677 [00:07<00:00, 89.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "labels = []\n",
    "for batch_id in tqdm(batch_idx):\n",
    "    dense_data_batch = dense_data[batch_id]\n",
    "    cat_data_batch = cat_data[batch_id]\n",
    "    results = infer_batch(inference_session, dense_data_batch, cat_data_batch)\n",
    "    labels.extend(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2772486"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the test AUC value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = nvtdata_test['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5542272060903836"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(ground_truth, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this notebook, we have walked you through the process of preprocessing the data, train a DLRM model with HugeCTR, then carrying out inference with the HugeCTR Python interface. Try this workflow on your data and let us know your feedback.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
