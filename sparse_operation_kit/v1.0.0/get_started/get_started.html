

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Get Started With SparseOperationKit &mdash; SparseOperationKit  documentation</title>
  

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Examples" href="../examples/index.html" />
    <link rel="prev" title="Features in SparseOperationKit" href="../features/features.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> SparseOperationKit
          

          
          </a>

          
            
            
              <div class="version">
                1.0.0
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../intro_link.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../features/features.html">Features</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Get Started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#install-sparseoperationkit">Install SparseOperationKit</a></li>
<li class="toctree-l2"><a class="reference internal" href="#import-sparseoperationkit">Import SparseOperationKit</a></li>
<li class="toctree-l2"><a class="reference internal" href="#define-a-model-with-tensorflow">Define a model with TensorFlow</a></li>
<li class="toctree-l2"><a class="reference internal" href="#use-sparseoperationkit-with-tf-distribute-strategy">Use SparseOperationKit with tf.distribute.Strategy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#with-tf-distribute-mirroredstrategy">with tf.distribute.MirroredStrategy</a></li>
<li class="toctree-l3"><a class="reference internal" href="#with-tf-distribute-multiworkermirroredstrategy">With tf.distribute.MultiWorkerMirroredStrategy</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../examples/index.html">Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance/index.html">Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../api/index.html">API Docs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../known_issues/issues.html">Known Issues</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">SparseOperationKit</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Get Started With SparseOperationKit</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="../_sources/get_started/get_started.md.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section class="tex2jax_ignore mathjax_ignore" id="get-started-with-sparseoperationkit">
<h1>Get Started With SparseOperationKit<a class="headerlink" href="#get-started-with-sparseoperationkit" title="Permalink to this headline">¶</a></h1>
<p>This document will walk you through simple demos to get you familiar with SparseOperationKit.</p>
<div class="admonition note">
<p class="admonition-title">See also</p>
<p>For experts or more examples, please refer to Examples section</p>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>In this document and other examples in SOK, you are assumed to be familiar with TensorFlow and other related tools.</p>
</div>
<section id="install-sparseoperationkit">
<h2>Install SparseOperationKit<a class="headerlink" href="#install-sparseoperationkit" title="Permalink to this headline">¶</a></h2>
<p>Please refer to the <a class="reference external" href="https://nvidia.github.io/HugeCTR/sparse_operation_kit/v1.0.0/intro_link.html#installation"><em>Installation</em> section</a> to install SparseOperationKit to your system.</p>
</section>
<section id="import-sparseoperationkit">
<h2>Import SparseOperationKit<a class="headerlink" href="#import-sparseoperationkit" title="Permalink to this headline">¶</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sparse_operation_kit</span> <span class="k">as</span> <span class="nn">sok</span>
</pre></div>
</div>
</section>
<section id="define-a-model-with-tensorflow">
<h2>Define a model with TensorFlow<a class="headerlink" href="#define-a-model-with-tensorflow" title="Permalink to this headline">¶</a></h2>
<p>The structure of this demo model is depicted in Fig 1.</p>
<p><br><img alt="../_images/demo_model_structure1.png" src="../_images/demo_model_structure1.png" /></br></p>
<center><b>Fig 1. The structure of demo model</b></center>
<br>
<br>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>

<span class="k">class</span> <span class="nc">DemoModel</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">max_vocabulary_size_per_gpu</span><span class="p">,</span>
                 <span class="n">slot_num</span><span class="p">,</span>
                 <span class="n">nnz_per_slot</span><span class="p">,</span>
                 <span class="n">embedding_vector_size</span><span class="p">,</span>
                 <span class="n">num_of_dense_layers</span><span class="p">,</span>
                 <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DemoModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">max_vocabulary_size_per_gpu</span> <span class="o">=</span> <span class="n">max_vocabulary_size_per_gpu</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">slot_num</span> <span class="o">=</span> <span class="n">slot_num</span>            <span class="c1"># the number of feature-fileds per sample</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">nnz_per_slot</span> <span class="o">=</span> <span class="n">nnz_per_slot</span>    <span class="c1"># the number of valid keys per feature-filed</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_vector_size</span> <span class="o">=</span> <span class="n">embedding_vector_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_of_dense_layers</span> <span class="o">=</span> <span class="n">num_of_dense_layers</span>

        <span class="c1"># this embedding layer will concatenate each key&#39;s embedding vector</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">embedding_layer</span> <span class="o">=</span> <span class="n">sok</span><span class="o">.</span><span class="n">All2AllDenseEmbedding</span><span class="p">(</span>
                    <span class="n">max_vocabulary_size_per_gpu</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">max_vocabulary_size_per_gpu</span><span class="p">,</span>
                    <span class="n">embedding_vec_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding_vector_size</span><span class="p">,</span>
                    <span class="n">slot_num</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">slot_num</span><span class="p">,</span>
                    <span class="n">nnz_per_slot</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">nnz_per_slot</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">dense_layers</span> <span class="o">=</span> <span class="nb">list</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_of_dense_layers</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s2">&quot;relu&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dense_layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layer</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">out_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="n">units</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="c1"># its shape is [batchsize, slot_num, nnz_per_slot, embedding_vector_size]</span>
        <span class="n">emb_vector</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_layer</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="n">training</span><span class="p">)</span>

        <span class="c1"># reshape this tensor, so that it can be processed by Dense layer</span>
        <span class="n">emb_vector</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">emb_vector</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">slot_num</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">nnz_per_slot</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding_vector_size</span><span class="p">])</span>

        <span class="n">hidden</span> <span class="o">=</span> <span class="n">emb_vector</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense_layers</span><span class="p">:</span>
            <span class="n">hidden</span> <span class="o">=</span> <span class="n">layer</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>

        <span class="n">logit</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_layer</span><span class="p">(</span><span class="n">hidden</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">logit</span>
</pre></div>
</div>
</section>
<section id="use-sparseoperationkit-with-tf-distribute-strategy">
<h2>Use SparseOperationKit with tf.distribute.Strategy<a class="headerlink" href="#use-sparseoperationkit-with-tf-distribute-strategy" title="Permalink to this headline">¶</a></h2>
<p>SparseOperationKit is compatible with <code class="docutils literal notranslate"><span class="pre">tf.distribute.Strategy</span></code>. More specificly, <code class="docutils literal notranslate"><span class="pre">tf.distribute.MirroredStrategy</span></code> and <code class="docutils literal notranslate"><span class="pre">tf.distribute.MultiWorkerMirroredStrategy</span></code>.</p>
<section id="with-tf-distribute-mirroredstrategy">
<h3>with tf.distribute.MirroredStrategy<a class="headerlink" href="#with-tf-distribute-mirroredstrategy" title="Permalink to this headline">¶</a></h3>
<p>Documents for <a class="reference external" href="https://tensorflow.google.cn/api_docs/python/tf/distribute/MirroredStrategy?hl=en">tf.distribute.MirroredStrategy</a>. <code class="docutils literal notranslate"><span class="pre">tf.distribute.MirroredStrategy</span></code> is a tool to support data-parallel synchronized training in single machine, where there exists multiple GPUs.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The programming model for MirroredStrategy is single-process &amp; multi-threads. But due to the GIL in CPython interpreter, it is hard to fully leverage all available CPU cores, which might impact the end-to-end training / inference performance. Therefore, MirroredStrategy is not recommended for multiple GPUs synchronized training.</p>
</div>
<p><em><strong>create MirroredStrategy</strong></em></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">MirroredStrategy</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>By default, MirroredStrategy will use all available GPUs in one machine. If you want to specify how many GPUs are used or which GPUs are used for synchronized training, please set CUDA_VISIBLE_DEVICES.</p>
</div>
<p><em><strong>create model instance under MirroredStrategy.scope</strong></em></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">global_batch_size</span> <span class="o">=</span> <span class="mi">65536</span>
<span class="n">use_tf_opt</span> <span class="o">=</span> <span class="kc">True</span>

<span class="k">with</span> <span class="n">strategy</span><span class="o">.</span><span class="n">scope</span><span class="p">():</span>
    <span class="n">sok</span><span class="o">.</span><span class="n">Init</span><span class="p">(</span><span class="n">global_batch_size</span><span class="o">=</span><span class="n">global_batch_size</span><span class="p">)</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">DemoModel</span><span class="p">(</span>
        <span class="n">max_vocabulary_size_per_gpu</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
        <span class="n">slot_num</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
        <span class="n">nnz_per_slot</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
        <span class="n">embedding_vector_size</span><span class="o">=</span><span class="mi">16</span><span class="p">,</span>
        <span class="n">num_of_dense_layers</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">use_tf_opt</span><span class="p">:</span>
        <span class="n">emb_opt</span> <span class="o">=</span> <span class="n">sok</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">emb_opt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

    <span class="n">dense_opt</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</pre></div>
</div>
<p>For a DNN model built with SOK, <code class="docutils literal notranslate"><span class="pre">sok.Init</span></code> must be used to conduct initilizations. Please see <a class="reference external" href="https://nvidia.github.io/HugeCTR/sparse_operation_kit/v1.0.0/api/init.html#module-sparse_operation_kit.core.initialize">its API document</a>.</p>
<p><em><strong>define training step</strong></em></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">loss_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">reduction</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">Reducetion</span><span class="o">.</span><span class="n">NONE</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_replica_loss</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">logits</span><span class="p">):</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">labels</span><span class="p">,</span> <span class="n">logits</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">compute_average_loss</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">global_batch_size</span><span class="o">=</span><span class="n">global_batch_size</span><span class="p">)</span>

<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">_train_step</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">_replica_loss</span><span class="p">(</span><span class="n">lables</span><span class="p">,</span> <span class="n">logits</span><span class="p">)</span>
    <span class="n">emb_var</span><span class="p">,</span> <span class="n">other_var</span> <span class="o">=</span> <span class="n">sok</span><span class="o">.</span><span class="n">split_embedding_variable_from_others</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
    <span class="n">grads</span><span class="p">,</span> <span class="n">emb_grads</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">[</span><span class="n">other_var</span><span class="p">,</span> <span class="n">emb_var</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">use_tf_opt</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">sok</span><span class="o">.</span><span class="n">OptimizerScope</span><span class="p">(</span><span class="n">emb_var</span><span class="p">):</span>
            <span class="n">emb_opt</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">emb_grads</span><span class="p">,</span> <span class="n">emb_var</span><span class="p">),</span>
                                    <span class="n">experimental_aggregate_gradients</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">dense_opt</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">other_var</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">loss</span>
</pre></div>
</div>
<p>If you are using native TensorFlow optimizers, such as <code class="docutils literal notranslate"><span class="pre">tf.keras.optimizers.Adam</span></code>, then <code class="docutils literal notranslate"><span class="pre">sok.OptimizerScope</span></code> must be used. Please see <a class="reference external" href="https://nvidia.github.io/HugeCTR/sparse_operation_kit/v1.0.0/api/utils/opt_scope.html#sparseoperationkit-optimizer-scope">its API document</a>.</p>
<p><em><strong>start training</strong></em></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="o">...</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">dataset</span><span class="p">):</span>
    <span class="n">replica_loss</span> <span class="o">=</span> <span class="n">strategy</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">_train_step</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">))</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">strategy</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">ReduceOp</span><span class="o">.</span><span class="n">SUM</span><span class="p">,</span> <span class="n">replica_loss</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;[SOK INFO]: Iteration: </span><span class="si">{}</span><span class="s2">, loss: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>
</pre></div>
</div>
<p>After these steps, the <code class="docutils literal notranslate"><span class="pre">DemoModel</span></code> will be successfully trained.</p>
</section>
<section id="with-tf-distribute-multiworkermirroredstrategy">
<h3>With tf.distribute.MultiWorkerMirroredStrategy<a class="headerlink" href="#with-tf-distribute-multiworkermirroredstrategy" title="Permalink to this headline">¶</a></h3>
<p>Documents for <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/distribute/MultiWorkerMirroredStrategy">tf.distribute.MultiWorkerMirroredStrategy</a>. <code class="docutils literal notranslate"><span class="pre">tf.distribute.MultiWorkerMirroredStrategy</span></code> is a tool to support data-parallel synchronized training in multiple machines, where there exists multiple GPUs in each machine.</p>
<div class="admonition caution">
<p class="admonition-title">Caution</p>
<p>The programming model for MultiWorkerMirroredStrategy is multi-processes &amp; multi-threads. Each process owns multi-threads and controls all available GPUs in single machine. Due to the GIL in CPython interpreter, it is hard to fully leverage all available CPU cores in each machine, which might impact the end-to-end training / inference performance. Therefore, it is recommended to use multiple processes in each machine, and each process controls one GPU.</p>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>By default, MultiWorkerMirroredStrategy will use all available GPUs in each process. Please set CUDA_VISIBLE_DEVICES for each process to let each process controls different GPU.</p>
</div>
<p><em><strong>create MultiWorkerMirroredStrategy</strong></em></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">json</span>

<span class="n">worker_num</span> <span class="o">=</span> <span class="mi">8</span> <span class="c1"># how many GPUs are used</span>
<span class="n">task_id</span> <span class="o">=</span> <span class="mi">0</span>    <span class="c1"># this process controls which GPU</span>

<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_VISIBLE_DEVICES&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">task_id</span><span class="p">)</span> <span class="c1"># this procecss only controls this GPU</span>

<span class="n">port</span> <span class="o">=</span> <span class="mi">12345</span> <span class="c1"># could be arbitrary unused port on this machine</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;TF_CONFIG&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">({</span>
    <span class="s2">&quot;cluster&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;worker&quot;</span><span class="p">:</span> <span class="p">[</span><span class="s2">&quot;localhost:&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">port</span> <span class="o">+</span> <span class="n">i</span><span class="p">)</span>
                            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">worker_num</span><span class="p">)]},</span>
    <span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="p">{</span><span class="s2">&quot;type&quot;</span><span class="p">:</span> <span class="s2">&quot;worker&quot;</span><span class="p">,</span> <span class="s2">&quot;index&quot;</span><span class="p">:</span> <span class="n">task_id</span><span class="p">}</span>
<span class="p">})</span>
<span class="n">strategy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">distribute</span><span class="o">.</span><span class="n">MultiWorkerMirroredStrategy</span><span class="p">()</span>
</pre></div>
</div>
<p><em><strong>Other Steps</strong></em><br>
The steps <em><strong>create model instance under MultiWorkerMirroredStrategy.scope</strong></em>, <em><strong>define training step</strong></em> and <em><strong>start training</strong></em> are the same as which are described in <a class="reference external" href="#with-tf-distribute-mirroredstrategy">with tf.distribute.MirroredStrategy</a>. Please check that section.</p>
<p><em><strong>launch training program</strong></em><br>
Because multiple CPU processes are used in each machine for synchronized training, therefore <code class="docutils literal notranslate"><span class="pre">MPI</span></code> can be used to launch this program. For example:</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>$ mpiexec -np <span class="m">8</span> <span class="o">[</span>mpi-args<span class="o">]</span> python3 main.py <span class="o">[</span>python-args<span class="o">]</span>
</pre></div>
</div>
</section>
</section>
</section>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="../examples/index.html" class="btn btn-neutral float-right" title="Examples" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="../features/features.html" class="btn btn-neutral float-left" title="Features in SparseOperationKit" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, NVIDIA.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: sok_v1.0.0
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="get_started.html">sok_v1.0.0</a></dd>
    </dl>
  </div>
</div>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>