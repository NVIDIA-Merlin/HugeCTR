<!DOCTYPE html>
<html class="writer-html5" lang="en">
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>HugeCTR Layer Classes and Methods &mdash; Merlin HugeCTR  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css" />
      <link rel="stylesheet" type="text/css" href="../_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css" />
      <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />

  
    <link rel="canonical" href="https://nvidia-merlin.github.io/HugeCTR/main/api/hugectr_layer_book.html" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Additional Resources" href="../additional_resources.html" />
    <link rel="prev" title="HugeCTR Python Interface" href="python_interface.html" /> 
</head>

<body class="wy-body-for-nav">
  <div class="banner">
    <p class="banner">
      Since the HugeCTR <code>v23.09</code>, the offline inference has been deprecated.
      Since the HugeCTR <code>v24.06</code>, the HPS has been deprecated.
  </div>

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Merlin HugeCTR
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">HUGECTR</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../hugectr_user_guide.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hugectr_core_features.html">Core Features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hierarchical_parameter_server/index.html">Hierarchical Parameter Server</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sparse_operation_kit.html">Sparse Operation Kit</a></li>
<li class="toctree-l1"><a class="reference internal" href="../performance.html">Performance</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/index.html">Example Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notebooks/multi-modal-data/index.html">Multi-modal Example Notebooks</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">API Documentation</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="python_interface.html">Python Interface</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Layer Classes and Methods</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../additional_resources.html">Additional Resources</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release_notes.html">Release Notes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../hugectr_contributor_guide.html">Contributing to HugeCTR</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Merlin HugeCTR</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="index.html">HugeCTR API Documentation</a></li>
      <li class="breadcrumb-item active">HugeCTR Layer Classes and Methods</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section class="tex2jax_ignore mathjax_ignore" id="hugectr-layer-classes-and-methods">
<h1>HugeCTR Layer Classes and Methods<a class="headerlink" href="#hugectr-layer-classes-and-methods" title="Permalink to this heading">ÔÉÅ</a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#input-layer" id="id1">Input Layer</a></p></li>
<li><p><a class="reference internal" href="#sparse-embedding" id="id2">Sparse Embedding</a></p></li>
<li><p><a class="reference internal" href="#embedding-types-detail" id="id3">Embedding Types Detail</a></p>
<ul>
<li><p><a class="reference internal" href="#distributedslotsparseembeddinghash-layer" id="id4">DistributedSlotSparseEmbeddingHash Layer</a></p></li>
<li><p><a class="reference internal" href="#localizedslotsparseembeddinghash-layer" id="id5">LocalizedSlotSparseEmbeddingHash Layer</a></p></li>
<li><p><a class="reference internal" href="#localizedslotsparseembeddingonehot-layer" id="id6">LocalizedSlotSparseEmbeddingOneHot Layer</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#dense-layers" id="id7">Dense Layers</a></p></li>
<li><p><a class="reference internal" href="#dense-layers-usage" id="id8">Dense Layers Usage</a></p>
<ul>
<li><p><a class="reference internal" href="#fullyconnected-layer" id="id9">FullyConnected Layer</a></p></li>
<li><p><a class="reference internal" href="#mlp-layer" id="id10">MLP Layer</a></p></li>
<li><p><a class="reference internal" href="#multicross-layer" id="id11">MultiCross Layer</a></p></li>
<li><p><a class="reference internal" href="#fmorder2-layer" id="id12">FmOrder2 Layer</a></p></li>
<li><p><a class="reference internal" href="#weightmultiply-layer" id="id13">WeightMultiply Layer</a></p></li>
<li><p><a class="reference internal" href="#elementwisemultiply-layer" id="id14">ElementwiseMultiply Layer</a></p></li>
<li><p><a class="reference internal" href="#batchnorm-layer" id="id15">BatchNorm Layer</a></p></li>
<li><p><a class="reference internal" href="#layernorm-layer" id="id16">LayerNorm Layer</a></p></li>
<li><p><a class="reference internal" href="#concat-layer" id="id17">Concat Layer</a></p></li>
<li><p><a class="reference internal" href="#reshape-layer" id="id18">Reshape Layer</a></p></li>
<li><p><a class="reference internal" href="#select-layer" id="id19">Select Layer</a></p></li>
<li><p><a class="reference internal" href="#slice-layer" id="id20">Slice Layer</a></p></li>
<li><p><a class="reference internal" href="#dropout-layer" id="id21">Dropout Layer</a></p></li>
<li><p><a class="reference internal" href="#elu-layer" id="id22">ELU Layer</a></p></li>
<li><p><a class="reference internal" href="#relu-layer" id="id23">ReLU Layer</a></p></li>
<li><p><a class="reference internal" href="#sigmoid-layer" id="id24">Sigmoid Layer</a></p></li>
<li><p><a class="reference internal" href="#interaction-layer" id="id25">Interaction Layer</a></p></li>
<li><p><a class="reference internal" href="#add-layer" id="id26">Add Layer</a></p></li>
<li><p><a class="reference internal" href="#reducesum-layer" id="id27">ReduceSum Layer</a></p></li>
<li><p><a class="reference internal" href="#binarycrossentropyloss" id="id28">BinaryCrossEntropyLoss</a></p></li>
<li><p><a class="reference internal" href="#crossentropyloss" id="id29">CrossEntropyLoss</a></p></li>
<li><p><a class="reference internal" href="#multicrossentropyloss" id="id30">MultiCrossEntropyLoss</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#embedding-collection" id="id31">Embedding Collection</a></p>
<ul>
<li><p><a class="reference internal" href="#about-the-hugectr-embedding-collection" id="id32">About the HugeCTR embedding collection</a></p></li>
<li><p><a class="reference internal" href="#overview-of-using-the-hugectr-embedding-collection" id="id33">Overview of using the HugeCTR embedding collection</a></p></li>
<li><p><a class="reference internal" href="#known-limitations" id="id34">Known Limitations</a></p></li>
<li><p><a class="reference internal" href="#embeddingtableconfig" id="id35">EmbeddingTableConfig</a></p></li>
<li><p><a class="reference internal" href="#embeddingcollectionconfig" id="id36">EmbeddingCollectionConfig</a></p></li>
</ul>
</li>
</ul>
</nav>
<p>This document introduces different layer classes and corresponding methods in the Python API of HugeCTR. The description of each method includes its functionality, arguments, and examples of usage.</p>
<section id="input-layer">
<h2>Input Layer<a class="headerlink" href="#input-layer" title="Permalink to this heading">ÔÉÅ</a></h2>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hugectr</span><span class="o">.</span><span class="n">Input</span><span class="p">()</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">Input</span></code> layer specifies the parameters related to the data input. <code class="docutils literal notranslate"><span class="pre">Input</span></code> layer should be added to the Model instance first so that the following <code class="docutils literal notranslate"><span class="pre">SparseEmbedding</span></code> and <code class="docutils literal notranslate"><span class="pre">DenseLayer</span></code> instances can access the inputs with their specified names.</p>
<p><strong>Arguments</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">label_dim</span></code>: Integer, the label dimension. 1 implies it is a binary label. For example, if an item is clicked or not. There is NO default value and it should be specified by users.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">label_name</span></code>: String, the name of the label tensor to be referenced by following layers. There is NO default value and it should be specified by users.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dense_dim</span></code>: Integer, the number of dense (or continuous) features. If there is no dense feature, set it to 0. There is NO default value and it should be specified by users.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dense_name</span></code>: Integer, the name of the dense input tensor to be referenced by following layers. There is NO default value and it should be specified by users.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">data_reader_sparse_param_array</span></code>: List[hugectr.DataReaderSparseParam], the list of the sparse parameters for categorical inputs. Each <code class="docutils literal notranslate"><span class="pre">DataReaderSparseParam</span></code> instance should be constructed with  <code class="docutils literal notranslate"><span class="pre">sparse_name</span></code>, <code class="docutils literal notranslate"><span class="pre">nnz_per_slot</span></code>, <code class="docutils literal notranslate"><span class="pre">is_fixed_length</span></code> and <code class="docutils literal notranslate"><span class="pre">slot_num</span></code>.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">sparse_name</span></code> is the name of the sparse input tensors to be referenced by following layers. There is NO default value and it should be specified by users.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">nnz_per_slot</span></code> is the maximum hotness for input sparse features and is used by data reader. The <code class="docutils literal notranslate"><span class="pre">nnz_per_slot</span></code> can be an <code class="docutils literal notranslate"><span class="pre">int</span></code> which will apply on every slot. It could be convenient if all slots have the same hotness. Or one can use List[int] to initialize <code class="docutils literal notranslate"><span class="pre">nnz_per_slot</span></code> when hotness of slots differs, in which case the length of the array <code class="docutils literal notranslate"><span class="pre">nnz_per_slot</span></code> should be identical to <code class="docutils literal notranslate"><span class="pre">slot_num</span></code>. Note that for <code class="docutils literal notranslate"><span class="pre">RawAsync</span></code> data reader, only static hotness is support. This parameter has no impact on <code class="docutils literal notranslate"><span class="pre">Parquet</span></code> and <code class="docutils literal notranslate"><span class="pre">Raw</span></code> data reader.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">is_fixed_length</span></code> is used to identify whether categorical inputs has the same length for each slot among all samples. If different samples have the same number of features for each slot, then user can set <code class="docutils literal notranslate"><span class="pre">is_fixed_length</span> <span class="pre">=</span> <span class="pre">True</span></code> and HugeCTR can use this information to reduce data transferring time.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">slot_num</span></code> specifies the number of slots used for this sparse input in the dataset.</p></li>
</ul>
</li>
</ul>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">label_dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">label_name</span> <span class="o">=</span> <span class="s2">&quot;label&quot;</span><span class="p">,</span>
                        <span class="n">dense_dim</span> <span class="o">=</span> <span class="mi">13</span><span class="p">,</span> <span class="n">dense_name</span> <span class="o">=</span> <span class="s2">&quot;dense&quot;</span><span class="p">,</span>
                        <span class="n">data_reader_sparse_param_array</span> <span class="o">=</span>
                            <span class="p">[</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DataReaderSparseParam</span><span class="p">(</span><span class="s2">&quot;data1&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="mi">26</span><span class="p">)]))</span>
</pre></div>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Input</span><span class="p">(</span><span class="n">label_dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">label_name</span> <span class="o">=</span> <span class="s2">&quot;label&quot;</span><span class="p">,</span>
                        <span class="n">dense_dim</span> <span class="o">=</span> <span class="mi">13</span><span class="p">,</span> <span class="n">dense_name</span> <span class="o">=</span> <span class="s2">&quot;dense&quot;</span><span class="p">,</span>
                        <span class="n">data_reader_sparse_param_array</span> <span class="o">=</span>
                            <span class="p">[</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DataReaderSparseParam</span><span class="p">(</span><span class="s2">&quot;wide_data&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="mi">2</span><span class="p">),</span>
                            <span class="n">hugectr</span><span class="o">.</span><span class="n">DataReaderSparseParam</span><span class="p">(</span><span class="s2">&quot;deep_data&quot;</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="mi">26</span><span class="p">)]))</span>
</pre></div>
</div>
</section>
<section id="sparse-embedding">
<h2>Sparse Embedding<a class="headerlink" href="#sparse-embedding" title="Permalink to this heading">ÔÉÅ</a></h2>
<p><strong>SparseEmbedding class</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hugectr</span><span class="o">.</span><span class="n">SparseEmbedding</span><span class="p">()</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">SparseEmbedding</span></code> specifies the parameters related to the sparse embedding layer. One or several <code class="docutils literal notranslate"><span class="pre">SparseEmbedding</span></code> layers should be added to the Model instance after <code class="docutils literal notranslate"><span class="pre">Input</span></code> and before <code class="docutils literal notranslate"><span class="pre">DenseLayer</span></code>.</p>
<p><strong>Arguments</strong></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">embedding_type</span></code>: The embedding type.
Specify one of the following values:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">hugectr.Embedding_t.DistributedSlotSparseEmbeddingHash</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">hugectr.Embedding_t.LocalizedSlotSparseEmbeddingHash</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">hugectr.Embedding_t.LocalizedSlotSparseEmbeddingOneHot</span></code></p></li>
</ul>
<p>For information about the different embedding types, see <a class="reference internal" href="#embedding-types-detail"><span class="std std-ref">Embedding Types Detail</span></a>.
This argument does not have a default value.
You must specify a value.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">workspace_size_per_gpu_in_mb</span></code>: Integer, the workspace memory size in megabyte per GPU.
This workspace memory must be big enough to hold all the embedding vocabulary and its corresponding optimizer state that is used during the training and evaluation.
To understand how to set this value, see <a class="reference internal" href="../QAList.html#how-to-set-workspace-size-per-gpu-in-mb-and-slot-size-array"><span class="std std-ref">How to set workspace_size_per_gpu_in_mb and slot_size_array</span></a>.
This argument does not have a default value.
You must specify a value.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">embedding_vec_size</span></code>: Integer, the embedding vector size.
This argument does not have a default value.
You must specify a value.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">combiner</span></code>: String, the intra-slot reduction operation.
Specify <code class="docutils literal notranslate"><span class="pre">sum</span></code> or <code class="docutils literal notranslate"><span class="pre">mean</span></code>.
This argument does not have a default value.
You must specify a value.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sparse_embedding_name</span></code>: String, the name of the sparse embedding tensor.
This name is referenced by the following layers.
This argument does not have a default value.
You must specify a value.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bottom_name</span></code>: String, the number of the bottom tensor to consume with this sparse embedding layer.
Please note that the value should be a predefined sparse input name.
This argument does not have a default value.
You must specify a value.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">slot_size_array</span></code>: List[int], specify the maximum key value from each slot.
It should be consistent with that of the sparse input.
This parameter is used in <code class="docutils literal notranslate"><span class="pre">LocalizedSlotSparseEmbeddingHash</span></code> and <code class="docutils literal notranslate"><span class="pre">LocalizedSlotSparseEmbeddingOneHot</span></code>.
The value you specify can help avoid wasting memory that is caused by an imbalanced vocabulary size.
For more information, see <a class="reference internal" href="../QAList.html#how-to-set-workspace-size-per-gpu-in-mb-and-slot-size-array"><span class="std std-ref">How to set workspace_size_per_gpu_in_mb and slot_size_array</span></a>.
This argument does not have a default value.
You must specify a value.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">optimizer</span></code>: OptParamsPy, the optimizer that is dedicated to this sparse embedding layer.
If you do not specify the optimizer for the sparse embedding, the sparse embedding layer adopts the same optimizer as dense layers.</p></li>
</ul>
</section>
<section id="embedding-types-detail">
<h2>Embedding Types Detail<a class="headerlink" href="#embedding-types-detail" title="Permalink to this heading">ÔÉÅ</a></h2>
<section id="distributedslotsparseembeddinghash-layer">
<h3>DistributedSlotSparseEmbeddingHash Layer<a class="headerlink" href="#distributedslotsparseembeddinghash-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">DistributedSlotSparseEmbeddingHash</span></code> stores embeddings in an embedding table and gets them by using a set of integers or indices. The embedding table can be segmented into multiple slots or feature fields, which spans multiple GPUs and nodes. With <code class="docutils literal notranslate"><span class="pre">DistributedSlotSparseEmbeddingHash</span></code>, each GPU will have a portion of a slot. This type of embedding is useful when there‚Äôs an existing load imbalance among slots and OOM issues.</p>
<p><strong>Important Notes</strong>:</p>
<ul class="simple">
<li><p>In a single embedding layer, it is assumed that input integers represent unique feature IDs, which are mapped to unique embedding vectors.
All the embedding vectors in a single embedding layer must have the same size. If you want some input categorical features to have different embedding vector sizes, use multiple embedding layers.</p></li>
<li><p>The input indices‚Äô data type, <code class="docutils literal notranslate"><span class="pre">input_key_type</span></code>, is specified in the solver. By default,  the 32-bit integer (I32) is used, but the 64-bit integer type (I64) is also allowed even if it is constrained by the dataset type. For additional information, see <a class="reference internal" href="python_interface.html#solver"><span class="std std-ref">Solver</span></a>.</p></li>
<li><p>The DistributedSlotSparseEmbeddingHash Layer performs overflow checking in every iteration by default to verify if
the number of inserted keys is beyond the size set by workspace_size_per_gpu_in_mb. However, this can negatively
impact performance when the table is large. If user are confident that there will be no overflow, you can disable
overflow checking by setting the environment variable HUGECTR_DISABLE_OVERFLOW_CHECK=1.</p></li>
</ul>
<p><strong>Example:</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">SparseEmbedding</span><span class="p">(</span>
            <span class="n">embedding_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Embedding_t</span><span class="o">.</span><span class="n">DistributedSlotSparseEmbeddingHash</span><span class="p">,</span>
            <span class="n">workspace_size_per_gpu_in_mb</span> <span class="o">=</span> <span class="mi">23</span><span class="p">,</span>
            <span class="n">embedding_vec_size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">combiner</span> <span class="o">=</span> <span class="s1">&#39;sum&#39;</span><span class="p">,</span>
            <span class="n">sparse_embedding_name</span> <span class="o">=</span> <span class="s2">&quot;sparse_embedding1&quot;</span><span class="p">,</span>
            <span class="n">bottom_name</span> <span class="o">=</span> <span class="s2">&quot;input_data&quot;</span><span class="p">,</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="localizedslotsparseembeddinghash-layer">
<h3>LocalizedSlotSparseEmbeddingHash Layer<a class="headerlink" href="#localizedslotsparseembeddinghash-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">LocalizedSlotSparseEmbeddingHash</span></code> layer to store embeddings in an embedding table and get them by using a set of integers or indices. The embedding table can be segmented into multiple slots or feature fields, which spans multiple GPUs and nodes. Unlike the DistributedSlotSparseEmbeddingHash layer, with this type of embedding layer, each individual slot is located in each GPU and not shared. This type of embedding layer provides the best scalability.</p>
<p><strong>Important Notes</strong>:</p>
<ul class="simple">
<li><p>In a single embedding layer, it is assumed that input integers represent unique feature IDs, which are mapped to unique embedding vectors.
All the embedding vectors in a single embedding layer must have the same size. If you want some input categorical features to have different embedding vector sizes, use multiple embedding layers.</p></li>
<li><p>The input indices‚Äô data type, <code class="docutils literal notranslate"><span class="pre">input_key_type</span></code>, is specified in the solver. By default, the 32-bit integer (I32) is used, but the 64-bit integer type (I64) is also allowed even if it is constrained by the dataset type. For additional information, see <a class="reference internal" href="python_interface.html#solver"><span class="std std-ref">Solver</span></a>.</p></li>
<li><p>The LocalizedSlotSparseEmbeddingHash Layer performs overflow checking in every iteration by default to verify if the
number of inserted keys is beyond the size set by workspace_size_per_gpu_in_mb or slot_size_array. However, this
can negatively impact performance when the table is large. If user are confident that there will be no overflow, you
can disable overflow checking by setting the environment variable HUGECTR_DISABLE_OVERFLOW_CHECK=1.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">SparseEmbedding</span><span class="p">(</span>
            <span class="n">embedding_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Embedding_t</span><span class="o">.</span><span class="n">LocalizedSlotSparseEmbeddingHash</span><span class="p">,</span>
            <span class="n">workspace_size_per_gpu_in_mb</span> <span class="o">=</span> <span class="mi">23</span><span class="p">,</span>
            <span class="n">embedding_vec_size</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
            <span class="n">combiner</span> <span class="o">=</span> <span class="s1">&#39;sum&#39;</span><span class="p">,</span>
            <span class="n">sparse_embedding_name</span> <span class="o">=</span> <span class="s2">&quot;sparse_embedding1&quot;</span><span class="p">,</span>
            <span class="n">bottom_name</span> <span class="o">=</span> <span class="s2">&quot;input_data&quot;</span><span class="p">,</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="localizedslotsparseembeddingonehot-layer">
<h3>LocalizedSlotSparseEmbeddingOneHot Layer<a class="headerlink" href="#localizedslotsparseembeddingonehot-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The LocalizedSlotSparseEmbeddingOneHot layer stores embeddings in an embedding table and gets them by using a set of integers or indices. The embedding table can be segmented into multiple slots or feature fields, which spans multiple GPUs and nodes. This is a performance-optimized version of LocalizedSlotSparseEmbeddingHash for the case where NVSwitch is available and inputs are one-hot categorical features.</p>
<p><strong>Note</strong>: LocalizedSlotSparseEmbeddingOneHot can only be used together with the Raw dataset format. Unlike other types of embeddings, LocalizedSlotSparseEmbeddingOneHot only supports single-node training and can be used only in a NVSwitch equipped system such as DGX-2 and DGX A100.
The input indices‚Äô data type, <code class="docutils literal notranslate"><span class="pre">input_key_type</span></code>, is specified in the solver. By default, the 32-bit integer (I32) is used, but the 64-bit integer type (I64) is also allowed even if it is constrained by the dataset type. For additional information, see <a class="reference internal" href="python_interface.html#solver"><span class="std std-ref">Solver</span></a>.</p>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">SparseEmbedding</span><span class="p">(</span>
            <span class="n">embedding_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Embedding_t</span><span class="o">.</span><span class="n">LocalizedSlotSparseEmbeddingOneHot</span><span class="p">,</span>
            <span class="n">slot_size_array</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1221</span><span class="p">,</span> <span class="mi">754</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">12</span><span class="p">,</span> <span class="mi">49</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
            <span class="n">embedding_vec_size</span> <span class="o">=</span> <span class="mi">128</span><span class="p">,</span>
            <span class="n">combiner</span> <span class="o">=</span> <span class="s1">&#39;sum&#39;</span><span class="p">,</span>
            <span class="n">sparse_embedding_name</span> <span class="o">=</span> <span class="s2">&quot;sparse_embedding1&quot;</span><span class="p">,</span>
            <span class="n">bottom_name</span> <span class="o">=</span> <span class="s2">&quot;input_data&quot;</span><span class="p">,</span>
            <span class="n">optimizer</span> <span class="o">=</span> <span class="n">optimizer</span><span class="p">))</span>
</pre></div>
</div>
</section>
</section>
<section id="dense-layers">
<h2>Dense Layers<a class="headerlink" href="#dense-layers" title="Permalink to this heading">ÔÉÅ</a></h2>
<p><strong>DenseLayer class</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">()</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">DenseLayer</span></code> specifies the parameters related to the dense layer or the loss function. HugeCTR currently supports multiple dense layers and loss functions. Please <strong>NOTE</strong> that the final sigmoid function is fused with the loss function to better utilize memory bandwidth.</p>
<p><strong>Arguments</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">layer_type</span></code>: The layer type to be used. The supported types include <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.Add</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.BatchNorm</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.Cast</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.Concat</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.Dropout</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.ELU</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.FmOrder2</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.InnerProduct</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.MLP</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.Interaction</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.MultiCross</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.ReLU</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.ReduceSum</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.Reshape</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.Select</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.Sigmoid</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.Slice</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.WeightMultiply</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.ElementwiseMultiply</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.GRU</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.Scale</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.FusedReshapeConcat</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.FusedReshapeConcatGeneral</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.Softmax</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.PReLU_Dice</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.ReduceMean</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.Sub</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.Gather</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.BinaryCrossEntropyLoss</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.CrossEntropyLoss</span></code> and <code class="docutils literal notranslate"><span class="pre">hugectr.Layer_t.MultiCrossEntropyLoss</span></code>. There is NO default value and it should be specified by users.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bottom_names</span></code>: List[str], the list of bottom tensor names to be consumed by this dense layer. Each name in the list should be the predefined tensor name. There is NO default value and it should be specified by users.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">top_names</span></code>: List[str], the list of top tensor names, which specify the output tensors of this dense layer. There is NO default value and it should be specified by users.</p></li>
<li><p>For details about the usage of each layer type and its parameters, please refer to <a class="reference internal" href="#dense-layers-usage">Dense Layers Usage</a>.</p></li>
</ul>
</section>
<section id="dense-layers-usage">
<h2>Dense Layers Usage<a class="headerlink" href="#dense-layers-usage" title="Permalink to this heading">ÔÉÅ</a></h2>
<section id="fullyconnected-layer">
<h3>FullyConnected Layer<a class="headerlink" href="#fullyconnected-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The FullyConnected layer is a densely connected layer (or MLP layer). It is usually made of a <code class="docutils literal notranslate"><span class="pre">InnerProduct</span></code> layer and a <code class="docutils literal notranslate"><span class="pre">ReLU</span></code>.</p>
<p>Parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">num_output</span></code>: Integer, the number of output elements for the <code class="docutils literal notranslate"><span class="pre">InnerProduct</span></code> layer. The default value is 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weight_init_type</span></code>: Specifies how to initialize the weight array. The supported types include <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Uniform</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierNorm</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierUniform</span></code> and <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Zero</span></code>. The default value is <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bias_init_type</span></code>: Specifies how to initialize the bias array for the <code class="docutils literal notranslate"><span class="pre">InnerProduct</span></code> or <code class="docutils literal notranslate"><span class="pre">MultiCross</span></code> layer. The supported types include <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Uniform</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierNorm</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierUniform</span></code> and <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Zero</span></code>. The default value is <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: (batch_size, *) where * represents any number of elements</p></li>
<li><p>output: (batch_size, num_output)</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">InnerProduct</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;relu1&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fc2&quot;</span><span class="p">],</span>
                            <span class="n">num_output</span><span class="o">=</span><span class="mi">1024</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fc2&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;relu2&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</section>
<section id="mlp-layer">
<h3>MLP Layer<a class="headerlink" href="#mlp-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The MLP layer is comprised of multiple fused fully-connected layers. The MLP layer supports FP16, FP32, and TF32.</p>
<p><strong>Arguments</strong></p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">num_outputs</span></code>: List[Integer], specifies the number of output elements for each fused fully-connected layer in the MLP. There is NO default value and it should be specified by users.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">act_type</span></code>: The activation type of the MLP layer. This argument is applied to all layers in the MLP. The supported types include <code class="docutils literal notranslate"><span class="pre">Activation_t.Relu</span></code> and <code class="docutils literal notranslate"><span class="pre">Activation_t.Non</span></code>. The default value is <code class="docutils literal notranslate"><span class="pre">Activation_t.Relu</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">use_bias</span></code>: Boolean, whether to use bias. This argument is applied to all layers in the MLP. The default value is True.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">activations</span></code>: List[Activation_t], specifies the activation type for each layer in the MLP. This argument overrides the <code class="docutils literal notranslate"><span class="pre">act_type</span></code> argument.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">biases</span></code>: List[Boolean], specifies for each layer in the MLP Layer whether to use bias. This argument overrides the <code class="docutils literal notranslate"><span class="pre">use_bias</span></code> argument.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weight_init_type</span></code>: Specifies how to initialize the weight array of all layers in the MLP. The supported types include <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Uniform</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierNorm</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierUniform</span></code> and <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Zero</span></code>. The default value is <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bias_init_type</span></code>: Specifies how to initialize the bias array of all layers in the MLP. The supported types include <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Uniform</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierNorm</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierUniform</span></code> and <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Zero</span></code>. The default value is <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">compute_config</span></code>: hugectr.DenseLayerComputeConfig, specifies the computation configuration of all layers in the MLP. For MLP, the valid flags in compute_config are <code class="docutils literal notranslate"><span class="pre">hugectr.DenseLayerComputeConfig.async_wgrad</span></code> and <code class="docutils literal notranslate"><span class="pre">hugectr.DenseLayerComputeConfig.fuse_wb</span></code>.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">hugectr.DenseLayerComputeConfig.async_wgrad</span></code>: Specifies whether the wgrad compute is asynchronous to dgrad. The default value is False.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">hugectr.DenseLayerComputeConfig.fuse_wb</span></code>: Specifies whether to fuse wgrad with bgrad. The default value is False.</p></li>
</ul>
</li>
<li><p>input: (batch_size, *) where * represents any number of elements</p></li>
<li><p>output: (batch_size, num_output of the last layer)</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="n">compute_config_bottom</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayerComputeConfig</span><span class="p">(</span>
    <span class="n">async_wgrad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">fuse_wb</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">compute_config_top</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayerComputeConfig</span><span class="p">(</span>
    <span class="n">async_wgrad</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">fuse_wb</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">MLP</span><span class="p">,</span>
        <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;dense&quot;</span><span class="p">],</span>
        <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mlp1&quot;</span><span class="p">],</span>
        <span class="n">num_outputs</span><span class="o">=</span><span class="p">[</span><span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">128</span><span class="p">],</span>
        <span class="n">act_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Activation_t</span><span class="o">.</span><span class="n">Relu</span><span class="p">,</span>
        <span class="n">use_bias</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">compute_config</span><span class="o">=</span><span class="n">compute_config_bottom</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">Interaction</span><span class="p">,</span>
        <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mlp1&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse_embedding1&quot;</span><span class="p">],</span>
        <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;interaction1&quot;</span><span class="p">,</span> <span class="s2">&quot;interaction_grad&quot;</span><span class="p">],</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">MLP</span><span class="p">,</span>
        <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;interaction1&quot;</span><span class="p">,</span> <span class="s2">&quot;interaction_grad&quot;</span><span class="p">],</span>
        <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mlp2&quot;</span><span class="p">],</span>
        <span class="n">num_outputs</span><span class="o">=</span><span class="p">[</span><span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
        <span class="n">activations</span><span class="o">=</span><span class="p">[</span>
            <span class="n">hugectr</span><span class="o">.</span><span class="n">Activation_t</span><span class="o">.</span><span class="n">Relu</span><span class="p">,</span>
            <span class="n">hugectr</span><span class="o">.</span><span class="n">Activation_t</span><span class="o">.</span><span class="n">Relu</span><span class="p">,</span>
            <span class="n">hugectr</span><span class="o">.</span><span class="n">Activation_t</span><span class="o">.</span><span class="n">Relu</span><span class="p">,</span>
            <span class="n">hugectr</span><span class="o">.</span><span class="n">Activation_t</span><span class="o">.</span><span class="n">Relu</span><span class="p">,</span>
            <span class="n">hugectr</span><span class="o">.</span><span class="n">Activation_t</span><span class="o">.</span><span class="n">Non</span><span class="p">,</span>
        <span class="p">],</span>
        <span class="n">biases</span> <span class="o">=</span> <span class="p">[</span><span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">],</span>
        <span class="n">compute_config</span><span class="o">=</span><span class="n">compute_config_top</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>

<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">BinaryCrossEntropyLoss</span><span class="p">,</span>
        <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;mlp2&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">],</span>
        <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">],</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="multicross-layer">
<h3>MultiCross Layer<a class="headerlink" href="#multicross-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The MultiCross layer is a cross network where explicit feature crossing is applied across cross layers.
There are two versions of cross network which are invented in <a class="reference external" href="https://arxiv.org/abs/1708.05123">DCN v1</a> and <a class="reference external" href="https://arxiv.org/abs/2008.13535">DCN v2</a> respectively.</p>
<p>Suppose the dimension of features to be interacted is <span class="math notranslate nohighlight">\(n\)</span>, the mathematical formulas of feature crossing for those two versions are:</p>
<dl class="simple myst">
<dt>DCN v1</dt><dd><div class="math notranslate nohighlight">
\[
  x_{l+1}=x_{0}x^{T}_{l}w_{l}+b_l+x_l
  \]</div>
<p>where <span class="math notranslate nohighlight">\( w_l, b_l \in \mathbb{R}^{n\times1}\)</span> are learnable parameter, <span class="math notranslate nohighlight">\(x_{l},x_0\)</span> are input and <span class="math notranslate nohighlight">\(x_{l+1}\)</span> is output.</p>
</dd>
<dt>DCN v2</dt><dd><div class="math notranslate nohighlight">
\[
  x_{l+1}=x_{0}\odot (\mathbf{W}_{l} x_{l}+b_l )+x_l
  \]</div>
<p>where <span class="math notranslate nohighlight">\( \odot \)</span> represents elementwise dot, <span class="math notranslate nohighlight">\(\mathbf{W}_l \in \mathbb{R}^{n\times n}, b_l \in \mathbb{R}^{n\times 1 }\)</span> are learnable parameter, <span class="math notranslate nohighlight">\(x_{l},x_0\)</span> are input and <span class="math notranslate nohighlight">\(x_{l+1}\)</span> is output.</p>
<p>To decrease the computation complexity, <span class="math notranslate nohighlight">\(\mathbf{W}_l\)</span> can be approximately factorized into multiplication of two lower rank matrices <span class="math notranslate nohighlight">\(\mathbf{U} \in \mathbb{R}^{n \times k}, \mathbf{V} \in \mathbb{R}^{k \times n}\)</span>,  where <span class="math notranslate nohighlight">\(k\)</span> is a so-called projection dimension.
Correspondingly the formula evolves and can be expressed as follows:</p>
<div class="math notranslate nohighlight">
\[
  x_{l+1}=x_{0}\odot (\mathbf{U}_{l} \mathbf{V}_{l} x_{l}+b_l )+x_l
  \]</div>
</dd>
</dl>
<p>Parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">num_layers</span></code>: Integer, number of cross layers in the cross network. It should be set as a positive number if you want to use the cross network. The default value is <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">projection_dim</span></code>: Integer, the projection dimension for DCN v2. If you specify <code class="docutils literal notranslate"><span class="pre">0</span></code>, the layer degrades to DCN v1. The default value is <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weight_init_type</span></code>: Specifies how to initialize the weight array. The supported types include <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Uniform</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierNorm</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierUniform</span></code> and <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Zero</span></code>. The default value is <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bias_init_type</span></code>: Specifies how to initialize the bias array. The supported types include <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Uniform</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierNorm</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierUniform</span></code> and <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Zero</span></code>. The default value is <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">compute_config</span></code>: hugectr.DenseLayerComputeConfig, specifies the computation configuration of all layers in the cross network. The valid flags in compute_config is <code class="docutils literal notranslate"><span class="pre">hugectr.DenseLayerComputeConfig.async_wgrad</span></code> and applies only to DCN v2.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">hugectr.DenseLayerComputeConfig.async_wgrad</span></code>: Specifies whether the wgrad compute is asynchronous to dgrad. The default value is False.</p></li>
</ul>
</li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: (batch_size, *) where * represents any number of elements</p></li>
<li><p>output: same as input</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">MultiCross</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;slice11&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;multicross1&quot;</span><span class="p">],</span>
                            <span class="n">num_layers</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span>
                            <span class="n">projection_dim</span><span class="o">=</span><span class="mi">512</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="fmorder2-layer">
<h3>FmOrder2 Layer<a class="headerlink" href="#fmorder2-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>TheFmOrder2 layer is the second-order factorization machine (FM), which models linear and pairwise interactions as dot products of latent vectors.</p>
<p>Parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">out_dim</span></code>: Integer, the output vector size. It should be set as a positive number if you want to use factorization machine. The default value is 0.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: (batch_size, *) where * represents any number of elements</p></li>
<li><p>output: (batch_size, out_dim)</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">FmOrder2</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;slice32&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fmorder2&quot;</span><span class="p">],</span>
                            <span class="n">out_dim</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="weightmultiply-layer">
<h3>WeightMultiply Layer<a class="headerlink" href="#weightmultiply-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The Multiply Layer maps input elements into a latent vector space by multiplying each feature with a corresponding weight vector.</p>
<p>Parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">weight_dims</span></code>: List[Integer], the shape of the weight matrix (slot_dim, vec_dim) where vec_dim corresponds to the latent vector length for the <code class="docutils literal notranslate"><span class="pre">WeightMultiply</span></code> layer. It should be set correctly if you want to employ the weight multiplication. The default value is [].</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weight_init_type</span></code>: Specifies how to initialize the weight array. The supported types include <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Uniform</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierNorm</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierUniform</span></code> and <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Zero</span></code>. The default value is <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: (batch_size, slot_dim) where slot_dim represents the number of input features</p></li>
<li><p>output: (batch_size, slot_dim * vec_dim)</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">WeightMultiply</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;slice32&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fmorder2&quot;</span><span class="p">],</span>
                            <span class="n">weight_dims</span> <span class="o">=</span> <span class="p">[</span><span class="mi">13</span><span class="p">,</span> <span class="mi">10</span><span class="p">]),</span>
                            <span class="n">weight_init_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Initializer_t</span><span class="o">.</span><span class="n">XavierUniform</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="elementwisemultiply-layer">
<h3>ElementwiseMultiply Layer<a class="headerlink" href="#elementwisemultiply-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The ElementwiseMultiply Layer maps two inputs into a single resulting vector by performing an element-wise multiplication of the two inputs.</p>
<p>Parameters: None</p>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: 2x(batch_size, num_elem)</p></li>
<li><p>output: (batch_size, num_elem)</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">ElementwiseMultiply</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;slice1&quot;</span><span class="p">,</span><span class="s2">&quot;slice2&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;eltmultiply1&quot;</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="batchnorm-layer">
<h3>BatchNorm Layer<a class="headerlink" href="#batchnorm-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The BatchNorm layer implements a cuDNN based batch normalization.</p>
<p>Parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">factor</span></code>: Float, exponential average factor such as runningMean = runningMean*(1-factor) + newMean*factor for the <code class="docutils literal notranslate"><span class="pre">BatchNorm</span></code> layer. The default value is 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">eps</span></code>: Float, epsilon value used in the batch normalization formula for the <code class="docutils literal notranslate"><span class="pre">BatchNorm</span></code> layer. The default value is 1e-5.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">gamma_init_type</span></code>: Specifies how to initialize the gamma (or scale) array for the <code class="docutils literal notranslate"><span class="pre">BatchNorm</span></code> layer. The supported types include <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Uniform</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierNorm</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierUniform</span></code> and <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Zero</span></code>. The default value is <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">beta_init_type</span></code>: Specifies how to initialize the beta (or offset) array for the <code class="docutils literal notranslate"><span class="pre">BatchNorm</span></code> layer. The supported types include <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Uniform</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierNorm</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierUniform</span></code> and <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Zero</span></code>. The default value is <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: (batch_size, num_elem)</p></li>
<li><p>output: same as input</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">BatchNorm</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;slice32&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fmorder2&quot;</span><span class="p">],</span>
                            <span class="n">factor</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span>
                            <span class="n">eps</span> <span class="o">=</span> <span class="mf">0.00001</span><span class="p">,</span>
                            <span class="n">gamma_init_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Initializer_t</span><span class="o">.</span><span class="n">XavierUniform</span><span class="p">,</span>
                            <span class="n">beta_init_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Initializer_t</span><span class="o">.</span><span class="n">XavierUniform</span><span class="p">)</span>
</pre></div>
</div>
<p>When training a model, each BatchNorm layer stores mean and variance in a JSON file using the following format:
‚Äúsnapshot_prefix‚Äù + ‚Äú<em>dense</em>‚Äù + str(iter) + ‚Äù.model‚Äù</p>
<p>Example: my_snapshot_dense_5000.model<br></p>
<p>In the JSON file, you can find the batch norm parameters as shown below:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;layers&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">          </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;BatchNorm&quot;</span><span class="p">,</span>
<span class="w">          </span><span class="nt">&quot;mean&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">-0.192325</span><span class="p">,</span><span class="w"> </span><span class="mf">0.003050</span><span class="p">,</span><span class="w"> </span><span class="mf">-0.323447</span><span class="p">,</span><span class="w"> </span><span class="mf">-0.034817</span><span class="p">,</span><span class="w"> </span><span class="mf">-0.091861</span><span class="p">],</span>
<span class="w">          </span><span class="nt">&quot;var&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.738942</span><span class="p">,</span><span class="w"> </span><span class="mf">0.410794</span><span class="p">,</span><span class="w"> </span><span class="mf">1.370279</span><span class="p">,</span><span class="w"> </span><span class="mf">1.156337</span><span class="p">,</span><span class="w"> </span><span class="mf">0.638146</span><span class="p">]</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">          </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;BatchNorm&quot;</span><span class="p">,</span>
<span class="w">          </span><span class="nt">&quot;mean&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">-0.759954</span><span class="p">,</span><span class="w"> </span><span class="mf">0.251507</span><span class="p">,</span><span class="w"> </span><span class="mf">-0.648882</span><span class="p">,</span><span class="w"> </span><span class="mf">-0.176316</span><span class="p">,</span><span class="w"> </span><span class="mf">0.515163</span><span class="p">],</span>
<span class="w">          </span><span class="nt">&quot;var&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">1.434012</span><span class="p">,</span><span class="w"> </span><span class="mf">1.422724</span><span class="p">,</span><span class="w"> </span><span class="mf">1.001451</span><span class="p">,</span><span class="w"> </span><span class="mf">1.756962</span><span class="p">,</span><span class="w"> </span><span class="mf">1.126412</span><span class="p">]</span>
<span class="w">        </span><span class="p">},</span>
<span class="w">        </span><span class="p">{</span>
<span class="w">          </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;BatchNorm&quot;</span><span class="p">,</span>
<span class="w">          </span><span class="nt">&quot;mean&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">0.851878</span><span class="p">,</span><span class="w"> </span><span class="mf">-0.837513</span><span class="p">,</span><span class="w"> </span><span class="mf">-0.694674</span><span class="p">,</span><span class="w"> </span><span class="mf">0.791046</span><span class="p">,</span><span class="w"> </span><span class="mf">-0.849544</span><span class="p">],</span>
<span class="w">          </span><span class="nt">&quot;var&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mf">1.694500</span><span class="p">,</span><span class="w"> </span><span class="mf">5.405566</span><span class="p">,</span><span class="w"> </span><span class="mf">4.211646</span><span class="p">,</span><span class="w"> </span><span class="mf">1.936811</span><span class="p">,</span><span class="w"> </span><span class="mf">5.659098</span><span class="p">]</span>
<span class="w">        </span><span class="p">}</span>
<span class="w">      </span><span class="p">]</span>
<span class="w">    </span><span class="p">}</span>
</pre></div>
</div>
</section>
<section id="layernorm-layer">
<h3>LayerNorm Layer<a class="headerlink" href="#layernorm-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The LayerNorm layer implements a layer normalization.</p>
<p>Parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">eps</span></code>: Float, epsilon value used in the batch normalization formula for the <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> layer. The default value is 1e-5.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">gamma_init_type</span></code>: Specifies how to initialize the gamma (or scale) array for the <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> layer. The supported types include <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Uniform</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierNorm</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierUniform</span></code> and <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Zero</span></code>. The default value is <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">beta_init_type</span></code>: Specifies how to initialize the beta (or offset) array for the <code class="docutils literal notranslate"><span class="pre">LayerNorm</span></code> layer. The supported types include <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Uniform</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierNorm</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierUniform</span></code> and <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Zero</span></code>. The default value is <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: 2D: (batch_size, num_elem), 3D: (batch_size, seq_len, num_elem), 4D: (batch_size, num_attention_heads, seq_len, num_elem)</p></li>
<li><p>output: same as input</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;slice32&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fmorder2&quot;</span><span class="p">],</span>
                            <span class="n">eps</span> <span class="o">=</span> <span class="mf">0.00001</span><span class="p">,</span>
                            <span class="n">gamma_init_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Initializer_t</span><span class="o">.</span><span class="n">XavierUniform</span><span class="p">,</span>
                            <span class="n">beta_init_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Initializer_t</span><span class="o">.</span><span class="n">XavierUniform</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="concat-layer">
<h3>Concat Layer<a class="headerlink" href="#concat-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The Concat layer concatenates a list of inputs.</p>
<p>Parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">axis</span></code>:  Integer, the dimension to concat for the <code class="docutils literal notranslate"><span class="pre">Concat</span></code> layer. If the input is N-dimensional, 0 &lt;= axis &lt; N. The default value is 1.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: 3D: {(batch_size, num_feas_0, num_elems_0), (batch_size, num_feas + 1, num_elems_1), ‚Ä¶} or 2D: {(batch_size, num_elems_0), (batch_size, num_elems_1), ‚Ä¶}</p></li>
<li><p>output: 3D and axis=1: (batch_size, num_feas_0+num_feas_1+‚Ä¶, num_elems). 3D and axis=2: (batch_size, num_feas, num_elems_0+num_elems_1+‚Ä¶). 2D: (batch_size, num_elems_0+num_elems_1+‚Ä¶)</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">Concat</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;reshape3&quot;</span><span class="p">,</span><span class="s2">&quot;weight_multiply2&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;concat2&quot;</span><span class="p">],</span>
                            <span class="n">axis</span> <span class="o">=</span> <span class="mi">2</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="reshape-layer">
<h3>Reshape Layer<a class="headerlink" href="#reshape-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The Reshape layer reshapes a 3D input tensor into 2D shape.</p>
<p>Parameter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">leading_dim</span></code>: Integer, the innermost dimension of the output tensor. It must be the multiple of the total number of input elements. If it is unspecified, n_slots * num_elems (see below) is used as the default leading_dim.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">time_step</span></code>: Integer, the second dimension of the 3D output tensor. It must be the multiple of the total number of input elements and must be defined with leading_dim.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">selected</span></code>: Boolean, whether to use the selected mode for the <code class="docutils literal notranslate"><span class="pre">Reshape</span></code> layer. The default value is False.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">selected_slots</span></code>: List[int], the selected slots for the <code class="docutils literal notranslate"><span class="pre">Reshape</span></code> layer. It will be ignored if <code class="docutils literal notranslate"><span class="pre">selected</span></code> is False. The default value is [].</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">shape</span></code>: List of Integer, the destination shape of output. You can use -1 as a placeholder for dimensions that are variable, such as batch size. This parameter cannot be used together with other parameters and other parameters will be deprecated in the future. This parameter does not restrict dimensions.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: (batch_size, n_slots, num_elems)</p></li>
<li><p>output: (tailing_dim, leading_dim) where tailing_dim is batch_size * n_slots * num_elems / leading_dim</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">Reshape</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;sparse_embedding1&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;reshape1&quot;</span><span class="p">],</span>
                            <span class="n">leading_dim</span><span class="o">=</span><span class="mi">416</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">Reshape</span><span class="p">,</span>
                             <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;sparse_embedding1&quot;</span><span class="p">],</span>
                             <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;reshape1&quot;</span><span class="p">],</span>
                             <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">128</span><span class="p">]))</span>
</pre></div>
</div>
</section>
<section id="select-layer">
<h3>Select Layer<a class="headerlink" href="#select-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The Select layer can be used to select some index from a dimension.</p>
<p>Parameter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dim</span></code>: Integer, the dimension user want to do select.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">index</span></code>: List of Integer, the index user want to select from the specified dimension.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: any shape</p></li>
<li><p>output: depending on the parameter <code class="docutils literal notranslate"><span class="pre">dim</span></code> and <code class="docutils literal notranslate"><span class="pre">index</span></code></p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># if the shape of &quot;sparse_embedding1&quot; is (batch_size, 10, 128) the shape of &quot;select1&quot; will be (batch_size, 2, 128).</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">Selcte</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;sparse_embedding1&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;select1&quot;</span><span class="p">],</span>
                            <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                            <span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">]))</span>
</pre></div>
</div>
</section>
<section id="slice-layer">
<h3>Slice Layer<a class="headerlink" href="#slice-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The Slice layer extracts multiple output tensors from input tensors.</p>
<p>Parameter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ranges</span></code>: List[Tuple[int, int]], used for the Slice layer. A list of tuples in which each one represents a range in the input tensor to generate the corresponding output tensor. For example, (2, 8) indicates that 6 elements starting from the second element in the input tensor are used to create an output tensor. Note that the start index is inclusive and the end index is exclusive. The number of tuples corresponds to the number of output tensors. Ranges are allowed to overlap unless it is a reverse or negative range. The default value is []. The input tensors are sliced along the last dimension.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: (batch_size, num_elems)</p></li>
<li><p>output: {(batch_size, b-a), (batch_size, d-c), ‚Ä¶) where ranges ={[a, b), [c, d), ‚Ä¶} and len(ranges) &lt;= 5</p></li>
</ul>
<p>Example:</p>
<p>You can apply the Slice layer to actually slicing a tensor. In this case, it must be explicitly added with Python API.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">Slice</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;dense&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;slice21&quot;</span><span class="p">,</span> <span class="s2">&quot;slice22&quot;</span><span class="p">],</span>
                            <span class="n">ranges</span><span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">10</span><span class="p">),(</span><span class="mi">10</span><span class="p">,</span><span class="mi">13</span><span class="p">)]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">WeightMultiply</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;slice21&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;weight_multiply1&quot;</span><span class="p">],</span>
                            <span class="n">weight_dims</span><span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span><span class="mi">10</span><span class="p">]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">WeightMultiply</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;slice22&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;weight_multiply2&quot;</span><span class="p">],</span>
                            <span class="n">weight_dims</span><span class="o">=</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
<p>The Slice layer can also be employed to create copies of a tensor, which helps to express a branch topology in your model graph.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">Slice</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;dense&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;slice21&quot;</span><span class="p">,</span> <span class="s2">&quot;slice22&quot;</span><span class="p">],</span>
                            <span class="n">ranges</span><span class="o">=</span><span class="p">[(</span><span class="mi">0</span><span class="p">,</span><span class="mi">13</span><span class="p">),(</span><span class="mi">0</span><span class="p">,</span><span class="mi">13</span><span class="p">)]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">WeightMultiply</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;slice21&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;weight_multiply1&quot;</span><span class="p">],</span>
                            <span class="n">weight_dims</span><span class="o">=</span> <span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">10</span><span class="p">]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">WeightMultiply</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;slice22&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;weight_multiply2&quot;</span><span class="p">],</span>
                            <span class="n">weight_dims</span><span class="o">=</span> <span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
<p>From HugeCTR v.3.3, the aforementioned, Slice layer based branching can be abstracted away. When the same tensor is referenced multiple times in constructing a model in Python, the HugeCTR parser can internally add a Slice layer to handle such a situation. Thus, the example below behaves as the same as the one above whilst simplifying the code.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">WeightMultiply</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;dense&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;weight_multiply1&quot;</span><span class="p">],</span>
                            <span class="n">weight_dims</span><span class="o">=</span> <span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">10</span><span class="p">]))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">WeightMultiply</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;dense&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;weight_multiply2&quot;</span><span class="p">],</span>
                            <span class="n">weight_dims</span><span class="o">=</span> <span class="p">[</span><span class="mi">13</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>
</pre></div>
</div>
</section>
<section id="dropout-layer">
<h3>Dropout Layer<a class="headerlink" href="#dropout-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The Dropout layer randomly zeroizes or drops some of the input elements.</p>
<p>Parameter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dropout_rate</span></code>: Float, The dropout rate to be used for the <code class="docutils literal notranslate"><span class="pre">Dropout</span></code> layer. It should be between 0 and 1. Setting it to 0 indicates that there is no dropped element at all. The default value is 0.5.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: (batch_size, num_elems)</p></li>
<li><p>output: same as input</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">Dropout</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;relu1&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;dropout1&quot;</span><span class="p">],</span>
                            <span class="n">dropout_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="elu-layer">
<h3>ELU Layer<a class="headerlink" href="#elu-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The ELU layer represents the Exponential Linear Unit.</p>
<p>Parameter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">elu_alpha</span></code>: Float, the scalar that decides the value where this ELU function saturates for negative values. The default value is 1.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: (batch_size, *) where * represents any number of elements</p></li>
<li><p>output: same as input</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">ELU</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fc1&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;elu1&quot;</span><span class="p">],</span>
                            <span class="n">elu_alpha</span><span class="o">=</span><span class="mf">1.0</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="relu-layer">
<h3>ReLU Layer<a class="headerlink" href="#relu-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The ReLU layer represents the Rectified Linear Unit.</p>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: (batch_size, *) where * represents any number of elements</p></li>
<li><p>output: same as input</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">ReLU</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fc1&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;relu1&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</section>
<section id="sigmoid-layer">
<h3>Sigmoid Layer<a class="headerlink" href="#sigmoid-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The Sigmoid layer represents the Sigmoid Unit.</p>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: (batch_size, *) where * represents any number of elements</p></li>
<li><p>output: same as input</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fc1&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;sigmoid1&quot;</span><span class="p">]))</span>
</pre></div>
</div>
<p><strong>Note</strong>: The final sigmoid function is fused with the loss function to better utilize memory bandwidth, so do NOT add a Sigmoid layer before the loss layer.</p>
</section>
<section id="interaction-layer">
<h3>Interaction Layer<a class="headerlink" href="#interaction-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The interaction layer is used to explicitly capture second-order interactions between features.</p>
<p>Parameters: None</p>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: {(batch_size, num_elems), (batch_size, num_feas, num_elems)} where the first tensor typically represents a fully connected layer and the second is an embedding.</p></li>
<li><p>output: (batch_size, output_dim) where output_dim = num_elems + (num_feas + 1) * (num_feas + 2 ) / 2 - (num_feas + 1) + 1</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">Interaction</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;layer1&quot;</span><span class="p">,</span> <span class="s2">&quot;layer3&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;interaction1&quot;</span><span class="p">]))</span>
</pre></div>
</div>
<p><strong>Important Notes</strong>:
There are optimizations that can be employed on the <code class="docutils literal notranslate"><span class="pre">Interaction</span></code> layer and the following <code class="docutils literal notranslate"><span class="pre">MLP</span></code> layer during fp16 training. In this case, you should specify two output tensor names for the <code class="docutils literal notranslate"><span class="pre">Interaction</span></code> layer, and use them as the input tensors for the following <code class="docutils literal notranslate"><span class="pre">MLP</span></code> layer. Please refer to the example of <a class="reference internal" href="#mlp-layer">MLP layer</a> for the detailed usage.</p>
</section>
<section id="add-layer">
<h3>Add Layer<a class="headerlink" href="#add-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The Add layer adds up an arbitrary number of tensors that have the same size in an element-wise manner.</p>
<p>Parameters: None</p>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: Nx(batch_size, num_elems) where N is the number of input tensors</p></li>
<li><p>output: (batch_size, num_elems)</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">Add</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fc4&quot;</span><span class="p">,</span> <span class="s2">&quot;reducesum1&quot;</span><span class="p">,</span> <span class="s2">&quot;reducesum2&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;add&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</section>
<section id="reducesum-layer">
<h3>ReduceSum Layer<a class="headerlink" href="#reducesum-layer" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The ReduceSum Layer sums up all the elements across a specified dimension.</p>
<p>Parameter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">axis</span></code>:  Integer, the dimension to reduce for the <code class="docutils literal notranslate"><span class="pre">ReduceSum</span></code> layer. If the input is N-dimensional, 0 &lt;= axis &lt; N. The default value is 1.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: (batch_size, ‚Ä¶) where ‚Ä¶ represents any number of elements with an arbitrary number of dimensions</p></li>
<li><p>output: Dimension corresponding to axis is set to 1. The others remain the same as the input.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">ReduceSum</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fmorder2&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;reducesum1&quot;</span><span class="p">],</span>
                            <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
<section id="gru-layer">
<h4>GRU Layer<a class="headerlink" href="#gru-layer" title="Permalink to this heading">ÔÉÅ</a></h4>
<p>The GRU layer is Gated Recurrent Unit.</p>
<p>Parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">num_output</span></code>: Number of output elements.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">batchsize</span></code>: Number of batchsize.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SeqLength</span></code>: Length of the sequence.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">vector_size</span></code>: size of the input vector.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">weight_init_type</span></code>: Specifies how to initialize the weight array. The supported types include <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Uniform</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierNorm</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierUniform</span></code> and <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Zero</span></code>. The default value is <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bias_init_type</span></code>: Specifies how to initialize the bias array. The supported types include <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Uniform</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierNorm</span></code>, <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.XavierUniform</span></code> and <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Zero</span></code>. The default value is <code class="docutils literal notranslate"><span class="pre">hugectr.Initializer_t.Default</span></code>.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: (1, batch_size<em>SeqLength</em>embedding_vec_size)</p></li>
<li><p>output: (1, batch_size<em>SeqLength</em>embedding_vec_size)</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">GRU</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;GRU1&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;conncat1&quot;</span><span class="p">],</span>
                            <span class="n">num_output</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span>
                            <span class="n">batchsize</span><span class="o">=</span><span class="mi">13</span><span class="p">,</span>
                            <span class="n">SeqLength</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span>
                            <span class="n">vector_size</span><span class="o">=</span><span class="mi">20</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="preludice-layer">
<h4>PReLUDice Layer<a class="headerlink" href="#preludice-layer" title="Permalink to this heading">ÔÉÅ</a></h4>
<p>The PReLUDice layer represents the Parametric Rectified Linear Unit, which adaptively adjusts the rectified point according to distribution of input data.</p>
<p>Parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">elu_alpha</span></code>: A scalar that decides the value where this activation function saturates for negative values.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">eps</span></code>: Epsilon value used in the PReLU/Dice formula.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: (batch_size, *) where * represents any number of elements</p></li>
<li><p>output: same as input</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">PReLU_Dice</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fc_din_i1&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;dice_1&quot;</span><span class="p">],</span>
                            <span class="n">elu_alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">1e-8</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="scale-layer">
<h4>Scale Layer<a class="headerlink" href="#scale-layer" title="Permalink to this heading">ÔÉÅ</a></h4>
<p>The Scale layer scales the input 2D tensor to specific size on the designate axis.</p>
<p>Parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">axis</span></code>: Along the designate axis to scale the tensor. The designate axis could be axis 0, 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">factor</span> </code>: scale factor.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: (batch_size, num_elems)</p></li>
<li><p>output: if axis = 0; (batch_size, num_elems * factor), if axis = 1; (batch_size * factor, num_elems)</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">Scale</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;item1&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Scale_item&quot;</span><span class="p">],</span>
                            <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">factor</span> <span class="o">=</span> <span class="mi">10</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="fusedreshapeconcat-layer">
<h4>FusedReshapeConcat Layer<a class="headerlink" href="#fusedreshapeconcat-layer" title="Permalink to this heading">ÔÉÅ</a></h4>
<p>The FusedReshapeConcat layer cross combines the input tensors and outputs item tensor, AD tensor.</p>
<p>Parameters: None</p>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: {(batch_size, num_feas + 1, num_elems_0), (batch_size, num_feas + 1, num_elems_1), ‚Ä¶}, the input tensors are embeddings.</p></li>
<li><p>output: {(batch_size x num_feas, (num_elems_0 + num_elems_1 + ‚Ä¶)), (batch_size, (num_elems_0 + num_elems_1 + ‚Ä¶))}.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">FusedReshapeConcat</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;sparse_embedding_good&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse_embedding_cate&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;FusedReshapeConcat_item_his_em&quot;</span><span class="p">,</span> <span class="s2">&quot;FusedReshapeConcat_item&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</section>
<section id="fusedreshapeconcatgeneral-layer">
<h4>FusedReshapeConcatGeneral Layer<a class="headerlink" href="#fusedreshapeconcatgeneral-layer" title="Permalink to this heading">ÔÉÅ</a></h4>
<p>The FusedReshapeConcatGeneral layer cross combines the input tensors and outputs item tensor, AD tensor.</p>
<p>Parameters: None</p>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: {(batch_size, num_feas, num_elems_0), (batch_size, num_feas, num_elems_1), ‚Ä¶}, the input tensors are embeddings.</p></li>
<li><p>output: (batch_size x num_feas, (num_elems_0 + num_elems_1 + ‚Ä¶)).</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">FusedReshapeConcatGeneral</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;sparse_embedding_good&quot;</span><span class="p">,</span> <span class="s2">&quot;sparse_embedding_cate&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;FusedReshapeConcat_item_his_em&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</section>
<section id="softmax-layer">
<h4>Softmax Layer<a class="headerlink" href="#softmax-layer" title="Permalink to this heading">ÔÉÅ</a></h4>
<p>The Softmax layer computes softmax activations.
When the softmax layer accept two inputs tensors, the first one is the tensor need to do softmax and the other one is mask which mask some positions of the first tensor (setting them to -10000) before the softmax step.</p>
<p>Parameter: None</p>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: (batch_size, num_elems)</p></li>
<li><p>output: same as input</p></li>
<li><p>input: (batch_size, num_attention_heads, seq_len, seq_len) (batch_size, 1, 1, seq_len)</p></li>
<li><p>output: same as input</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">Softmax</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;reshape1&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;softmax_i&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</section>
<section id="sub-layer">
<h4>Sub Layer<a class="headerlink" href="#sub-layer" title="Permalink to this heading">ÔÉÅ</a></h4>
<p>Inputs: x tensor, y tensor in same size.
Produce x - y in element wise manner.</p>
<p>Parameters: None</p>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: Nx(batch_size, num_elems) where N is the number of input tensors</p></li>
<li><p>output: (batch_size, num_elems)</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">Sub</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Scale_item1&quot;</span><span class="p">,</span> <span class="s2">&quot;item_his1&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;sub_ih&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</section>
<section id="reducemean-layer">
<h4>ReduceMean Layer<a class="headerlink" href="#reducemean-layer" title="Permalink to this heading">ÔÉÅ</a></h4>
<p>The ReduceMean Layer computes the mean of elements across a specified dimension.</p>
<p>Parameter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">axis</span></code>: The dimension to reduce. If the input is N-dimensional, 0 &lt;= axis &lt; N.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: (batch_size, ‚Ä¶) where ‚Ä¶ represents any number of elements with an arbitrary number of dimensions</p></li>
<li><p>output: Dimension corresponding to axis is set to 1. The others remain the same as the input.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">ReduceMean</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;fmorder2&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;reducemean1&quot;</span><span class="p">],</span>
                            <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="matrixmutiply-layer">
<h4>MatrixMutiply Layer<a class="headerlink" href="#matrixmutiply-layer" title="Permalink to this heading">ÔÉÅ</a></h4>
<p>The MatrixMutiply Layer is a binary operation that produces a matrix output from two matrix inputs by performing matrix mutiplication.</p>
<p>Parameters: None</p>
<p>Input and Output Shapes:</p>
<p>There are following shape configuration supported</p>
<ul class="simple">
<li><p>input: 2D x 2D (m, n)x(n, k) and the output will be 2D (m,k)</p></li>
<li><p>input: 3D x 3D (batch_size, m, n)x(batch_size, n, k) and the output will be 3D (batch_size, m, k)</p></li>
<li><p>input: 2D x 3D (batch_size, m)x(m, g, h) and the output will be 3D (batch_size, g, h)</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">MatrixMutiply</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;slice1&quot;</span><span class="p">,</span><span class="s2">&quot;slice2&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;MatrixMutiply1&quot;</span><span class="p">])</span>
</pre></div>
</div>
</section>
<section id="multiheadattention-layer">
<h4>MultiHeadAttention Layer<a class="headerlink" href="#multiheadattention-layer" title="Permalink to this heading">ÔÉÅ</a></h4>
<p>The MultiHeadAttention Layer is a binary operation that produces a matrix output from 3 matrix inputs by performing matrix mutiplication. The formulas is as follows:
$<span class="math notranslate nohighlight">\(
\mathbf{O} = \text {softmax} (s \cdot (\mathbf{Q} \cdot \mathbf{K}) \odot \mathbf{M}) \cdot \mathbf{V}
\)</span><span class="math notranslate nohighlight">\(
Where \)</span>Q, K, V<span class="math notranslate nohighlight">\( are 3D inputs and \)</span>O<span class="math notranslate nohighlight">\( is 3D output. The \)</span>\odot<span class="math notranslate nohighlight">\( represents element-wise dot while \)</span>\cdot<span class="math notranslate nohighlight">\( represents matrix inner product. \)</span>\mathbf{M}$ is used to mask out padded input due to the inequality of sequence length.
Please refer to <a class="reference external" href="https://arxiv.org/pdf/1706.03762.pdf">Attention is all you need</a> for more details.
Parameter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">num_attention_heads</span></code>: The number of attention heads. Default value is 1.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(Q\)</span>: (batch_size, seq_from, hidden_dim),</p></li>
<li><p><span class="math notranslate nohighlight">\(K\)</span>: (batch_size, seq_to, hidden_dim),</p></li>
<li><p><span class="math notranslate nohighlight">\(V\)</span>: (batch_size, seq_to, hidden_dim)</p></li>
<li><p><span class="math notranslate nohighlight">\(M\)</span> (optional): (batch_size, 1, seq_from, seq_to)</p></li>
</ul>
</li>
<li><p>output:</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(O\)</span>: (batch_size, seq_from, hidden_dim)</p></li>
</ul>
</li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span>
    <span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span>
        <span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">MultiHeadAttention</span><span class="p">,</span>
        <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;query&quot;</span><span class="p">,</span> <span class="s2">&quot;key&quot;</span><span class="p">,</span> <span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="s2">&quot;mask&quot;</span><span class="p">],</span>
        <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;attention_out&quot;</span><span class="p">],</span>
        <span class="n">num_attention_heads</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</section>
<section id="sequencemask-layer">
<h4>SequenceMask Layer<a class="headerlink" href="#sequencemask-layer" title="Permalink to this heading">ÔÉÅ</a></h4>
<p>The SequenceMask Layer can generate a binary padding mask which marks the zero padding values in the input by 0.  The importance of having a padding mask is to make sure that these zero values are not processed along with the actual input values</p>
<p>Parameter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">max_sequence_len_from</span></code>: The maximum length of query sequences. Default value is 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_sequence_len_to</span></code>: The maximum length of key sequences. Default value is 1.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: 2D: (batch_size, 1), (batch_size, 1)</p></li>
<li><p>output: 4D: (batch_size, 1, max_sequence_len_from, max_sequence_len_to)</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span><span class="o">=</span><span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">SequenceMask</span><span class="p">,</span>
                             <span class="n">bottom_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;dense&quot;</span><span class="p">,</span><span class="s2">&quot;dense&quot;</span><span class="p">],</span>
                             <span class="n">top_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;sequence_mask&quot;</span><span class="p">],</span>
                             <span class="n">max_sequence_len_from</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
                             <span class="n">max_sequence_len_to</span><span class="o">=</span><span class="mi">10</span><span class="p">,))</span>
</pre></div>
</div>
</section>
<section id="gather-layer">
<h4>Gather Layer<a class="headerlink" href="#gather-layer" title="Permalink to this heading">ÔÉÅ</a></h4>
<p>The Gather layer gather multiple output tensor slices from an input tensors on the last dimension.</p>
<p>Parameter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">indices</span></code>: A list of indices in which each one represents an index in the input tensor to generate the corresponding output tensor. For example, [2, 8] indicates the second and eights tensor slice in the input tensor which are used to create an output tensor.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: (batch_size, num_elems)</p></li>
<li><p>output: (num_indices, num_elems)</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">Gather</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;reshape1&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;gather1&quot;</span><span class="p">],</span>
                            <span class="n">indices</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">]))</span>
</pre></div>
</div>
</section>
</section>
<section id="binarycrossentropyloss">
<h3>BinaryCrossEntropyLoss<a class="headerlink" href="#binarycrossentropyloss" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>BinaryCrossEntropyLoss calculates loss from labels and predictions where each label is binary. The final sigmoid function is fused with the loss function to better utilize memory bandwidth.</p>
<p>Parameter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">use_regularizer</span></code>: Boolean, whether to use regulariers. THe default value is False.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">regularizer_type</span></code>: The regularizer type for the <code class="docutils literal notranslate"><span class="pre">BinaryCrossEntropyLoss</span></code>, <code class="docutils literal notranslate"><span class="pre">CrossEntropyLoss</span></code> or <code class="docutils literal notranslate"><span class="pre">MultiCrossEntropyLoss</span></code> layer. The supported types include <code class="docutils literal notranslate"><span class="pre">hugectr.Regularizer_t.L1</span></code> and <code class="docutils literal notranslate"><span class="pre">hugectr.Regularizer_t.L2</span></code>. It will be ignored if <code class="docutils literal notranslate"><span class="pre">use_regularizer</span></code> is False. The default value is <code class="docutils literal notranslate"><span class="pre">hugectr.Regularizer_t.L1</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lambda</span></code>: Float, the lambda value of the regularization term. It will be ignored if <code class="docutils literal notranslate"><span class="pre">use_regularier</span></code> is False. The default value is 0.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: [(batch_size, 1), (batch_size, 1)] where the first tensor represents the predictions while the second tensor represents the labels</p></li>
<li><p>output: (batch_size, 1)</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">BinaryCrossEntropyLoss</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;add&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">]))</span>
</pre></div>
</div>
</section>
<section id="crossentropyloss">
<h3>CrossEntropyLoss<a class="headerlink" href="#crossentropyloss" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>CrossEntropyLoss calculates loss from labels and predictions between the forward propagation phases and backward propagation phases. It assumes that each label is two-dimensional.</p>
<p>Parameter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">use_regularizer</span></code>: Boolean, whether to use regulariers. THe default value is False.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">regularizer_type</span></code>: The regularizer type for the <code class="docutils literal notranslate"><span class="pre">BinaryCrossEntropyLoss</span></code>, <code class="docutils literal notranslate"><span class="pre">CrossEntropyLoss</span></code> or <code class="docutils literal notranslate"><span class="pre">MultiCrossEntropyLoss</span></code> layer. The supported types include <code class="docutils literal notranslate"><span class="pre">hugectr.Regularizer_t.L1</span></code> and <code class="docutils literal notranslate"><span class="pre">hugectr.Regularizer_t.L2</span></code>. It will be ignored if <code class="docutils literal notranslate"><span class="pre">use_regularizer</span></code> is False. The default value is <code class="docutils literal notranslate"><span class="pre">hugectr.Regularizer_t.L1</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lambda</span></code>: Float, the lambda value of the regularization term. It will be ignored if <code class="docutils literal notranslate"><span class="pre">use_regularier</span></code> is False. The default value is 0.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: [(batch_size, 2), (batch_size, 2)] where the first tensor represents the predictions while the second tensor represents the labels</p></li>
<li><p>output: (batch_size, 2)</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;add&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">],</span>
                            <span class="n">use_regularizer</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                            <span class="n">regularizer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Regularizer_t</span><span class="o">.</span><span class="n">L2</span><span class="p">,</span>
                            <span class="k">lambda</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">))</span>
</pre></div>
</div>
</section>
<section id="multicrossentropyloss">
<h3>MultiCrossEntropyLoss<a class="headerlink" href="#multicrossentropyloss" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>MultiCrossEntropyLoss calculates loss from labels and predictions between the forward propagation phases and backward propagation phases. It allows labels in an arbitrary dimension, but all the labels must be in the same shape.</p>
<p>Parameter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">use_regularizer</span></code>: Boolean, whether to use regulariers. THe default value is False.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">regularizer_type</span></code>: The regularizer type for the <code class="docutils literal notranslate"><span class="pre">BinaryCrossEntropyLoss</span></code>, <code class="docutils literal notranslate"><span class="pre">CrossEntropyLoss</span></code> or <code class="docutils literal notranslate"><span class="pre">MultiCrossEntropyLoss</span></code> layer. The supported types include <code class="docutils literal notranslate"><span class="pre">hugectr.Regularizer_t.L1</span></code> and <code class="docutils literal notranslate"><span class="pre">hugectr.Regularizer_t.L2</span></code>. It will be ignored if <code class="docutils literal notranslate"><span class="pre">use_regularizer</span></code> is False. The default value is <code class="docutils literal notranslate"><span class="pre">hugectr.Regularizer_t.L1</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">lambda</span></code>: Float, the lambda value of the regularization term. It will be ignored if <code class="docutils literal notranslate"><span class="pre">use_regularier</span></code> is False. The default value is 0.</p></li>
</ul>
<p>Input and Output Shapes:</p>
<ul class="simple">
<li><p>input: [(batch_size, *), (batch_size, *)] where the first tensor represents the predictions while the second tensor represents the labels. * represents any even number of elements.</p></li>
<li><p>output: (batch_size, *)</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">hugectr</span><span class="o">.</span><span class="n">DenseLayer</span><span class="p">(</span><span class="n">layer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Layer_t</span><span class="o">.</span><span class="n">MultiCrossEntropyLoss</span><span class="p">,</span>
                            <span class="n">bottom_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;add&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">],</span>
                            <span class="n">top_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;loss&quot;</span><span class="p">],</span>
                            <span class="n">use_regularizer</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                            <span class="n">regularizer_type</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">Regularizer_t</span><span class="o">.</span><span class="n">L1</span><span class="p">,</span>
                            <span class="k">lambda</span> <span class="o">=</span> <span class="mf">0.1</span>
                            <span class="p">))</span>
</pre></div>
</div>
</section>
</section>
<section id="embedding-collection">
<h2>Embedding Collection<a class="headerlink" href="#embedding-collection" title="Permalink to this heading">ÔÉÅ</a></h2>
<section id="about-the-hugectr-embedding-collection">
<h3>About the HugeCTR embedding collection<a class="headerlink" href="#about-the-hugectr-embedding-collection" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>Embedding collection is introduced in the v3.7 release.
The embedding collection enables you to use embeddings with different vector sizes, optimizers, and arbitrary table placement strategy.
Compared with the <code class="docutils literal notranslate"><span class="pre">hugectr.SparseEmbedding</span></code> class, the embedding collection has three key advantages:</p>
<ol class="arabic simple">
<li><p>The embedding collection can fuse embedding tables with different embedding vector sizes.
The previous embedding can only fuse embedding tables with the same embedding vector size.
The enhancement boosts both flexibility and performance.</p></li>
<li><p>The embedding collection extends the functionality of embedding by supporting the <code class="docutils literal notranslate"><span class="pre">concat</span></code> combiner and supporting different lookups on the same embedding table.</p></li>
<li><p>The embedding collection supports arbitrary embedding table placement, such as data parallel and model parallel.</p></li>
</ol>
</section>
<section id="overview-of-using-the-hugectr-embedding-collection">
<h3>Overview of using the HugeCTR embedding collection<a class="headerlink" href="#overview-of-using-the-hugectr-embedding-collection" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>To use an embedding collection, you need the following items:</p>
<ul class="simple">
<li><p>A list of <code class="docutils literal notranslate"><span class="pre">hugectr.EmbeddingTableConfig</span></code> objects that represent the embedding tables, user needs to configure table name/max_vocabulary_size/ev_size/optimizer(optional).</p></li>
<li><p>A <code class="docutils literal notranslate"><span class="pre">hugectr.EmbeddingCollectionConfig</span></code> object that uses the embedding table config objects to organize the lookup operations between the input data and the embedding tables. It also provides method to configure the table placement strategy.</p></li>
</ul>
<p>You can use the <code class="docutils literal notranslate"><span class="pre">add()</span></code> method from <code class="docutils literal notranslate"><span class="pre">hugectr.Model</span></code> to use the embedding collection for training and evaluation.</p>
</section>
<section id="known-limitations">
<h3>Known Limitations<a class="headerlink" href="#known-limitations" title="Permalink to this heading">ÔÉÅ</a></h3>
<ol class="arabic simple">
<li><p>Only <code class="docutils literal notranslate"><span class="pre">embedding_vec_size</span></code> values of up to 256 are currently supported in the embedding collection.</p></li>
<li><p>If you use a dynamic hash table (by setting <code class="docutils literal notranslate"><span class="pre">max_vocabulary_size</span></code> to -1 in <code class="docutils literal notranslate"><span class="pre">hugectr.EmbeddingTableConfig</span></code>), it is
recommended that you set the <code class="docutils literal notranslate"><span class="pre">NCCL_LAUNCH_MODE=GROUP</span></code> environment variable to avoid potential hangs.</p></li>
<li><p>Mixed-precision training is not supported when using a dynamic hash table.</p></li>
</ol>
</section>
<section id="embeddingtableconfig">
<h3>EmbeddingTableConfig<a class="headerlink" href="#embeddingtableconfig" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">hugectr.EmbeddingTableConfig</span></code> class enables you to specify the attributes of an embedding table.</p>
<p>Parameter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code>: String, a name which is used when dumping and loading embedding table.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">max_vocabulary_size</span></code>: Integer, specifies the vocabulary size of this table.
If positive, then the value indicates the number of embedding vectors that this table contains.
If you specify the value incorrectly and exceed the value during training or evaluation, you will cause an overflow and receive an error.
If you do not know the exact size of the embedding table, you can specify <code class="docutils literal notranslate"><span class="pre">-1</span></code> to use a dynamic hash embedding table with a size that can be extended dynamically during training or evaluation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ev_size</span></code>: Integer, specifies the embedding vector size that this embedding consists of.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">opt_params</span></code>: Optional, <code class="docutils literal notranslate"><span class="pre">hugectr.Optimizer</span></code>, the optimizer you want to use for this embedding table.
If not specified, the embedding table uses the optimizer specified in <code class="docutils literal notranslate"><span class="pre">hugectr.Model</span></code>.
Currently, if the user sets max_vocabulary_size to a value greater than 0, the supported optimizer types are <code class="docutils literal notranslate"><span class="pre">SGD</span></code> and <code class="docutils literal notranslate"><span class="pre">AdaGrad</span></code>. If the user sets <code class="docutils literal notranslate"><span class="pre">max_vocabulary_size</span></code> to -1, a dynamic hash embedding table is used, and the supported optimizer types are <code class="docutils literal notranslate"><span class="pre">SGD</span></code>, <code class="docutils literal notranslate"><span class="pre">MomentumSGD</span></code>, <code class="docutils literal notranslate"><span class="pre">Nesterov</span></code>, <code class="docutils literal notranslate"><span class="pre">AdaGrad</span></code>, <code class="docutils literal notranslate"><span class="pre">RMSProp</span></code>, <code class="docutils literal notranslate"><span class="pre">Adam</span></code>, and <code class="docutils literal notranslate"><span class="pre">Ftrl</span></code>.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create the embedding table.</span>
<span class="n">slot_size_array</span> <span class="o">=</span> <span class="p">[</span><span class="mi">203931</span><span class="p">,</span> <span class="mi">18598</span><span class="p">,</span> <span class="mi">14092</span><span class="p">,</span> <span class="mi">7012</span><span class="p">,</span> <span class="mi">18977</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6385</span><span class="p">,</span> <span class="mi">1245</span><span class="p">,</span> <span class="mi">49</span><span class="p">,</span>
                   <span class="mi">186213</span><span class="p">,</span> <span class="mi">71328</span><span class="p">,</span> <span class="mi">67288</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="mi">2168</span><span class="p">,</span> <span class="mi">7338</span><span class="p">,</span> <span class="mi">61</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">932</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span>
                   <span class="mi">204515</span><span class="p">,</span> <span class="mi">141526</span><span class="p">,</span> <span class="mi">199433</span><span class="p">,</span> <span class="mi">60919</span><span class="p">,</span> <span class="mi">9137</span><span class="p">,</span> <span class="mi">71</span><span class="p">,</span> <span class="mi">34</span><span class="p">]</span>
<span class="n">embedding_table_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">slot_size_array</span><span class="p">))):</span>
    <span class="n">embedding_table_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">hugectr</span><span class="o">.</span><span class="n">EmbeddingTableConfig</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="s2">&quot;table_&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span>
            <span class="n">max_vocabulary_size</span><span class="o">=</span><span class="n">slot_size_array</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">ev_size</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>
</pre></div>
</div>
</section>
<section id="embeddingcollectionconfig">
<h3>EmbeddingCollectionConfig<a class="headerlink" href="#embeddingcollectionconfig" title="Permalink to this heading">ÔÉÅ</a></h3>
<p>Create a <code class="docutils literal notranslate"><span class="pre">hugectr.EmbeddingCollectionConfig</span></code> instance to construct the lookup operation and configure the table placement strategy.</p>
<p>Parameter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">use_exclusive_keys</span></code>: bool, if true, any key is exclusively owned by only one table.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">comm_strategy</span></code>: hugectr.CommunicationStrategy, can be <code class="docutils literal notranslate"><span class="pre">hugectr.CommunicationStrategy.Uniform</span></code> or <code class="docutils literal notranslate"><span class="pre">hugectr.CommunicationStrategy.Hierarchical</span></code>.</p></li>
</ul>
<section id="embedding-lookup-method">
<h4>embedding_lookup method<a class="headerlink" href="#embedding-lookup-method" title="Permalink to this heading">ÔÉÅ</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">embedding_lookup</span></code> method enables you to specify the lookup operations between the input data and an embedding table.</p>
<p>Parameter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">table_config</span></code> : <code class="docutils literal notranslate"><span class="pre">hugectr.EmbeddingTableConfig</span></code>, the embedding table for the lookup operation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bottom_name</span></code>: str, the bottom tensor name.
Specify a tensor that is compatible with the <code class="docutils literal notranslate"><span class="pre">data_reader_sparse_param_array</span></code> parameter of <a class="reference internal" href="#input-layer"><code class="docutils literal notranslate"><span class="pre">hugectr.Input</span></code></a> in <code class="docutils literal notranslate"><span class="pre">hugectr.Model</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">top_name</span></code>: str, the output tensor name.
The shape of output tensor is (<code class="docutils literal notranslate"><span class="pre">&lt;batch</span> <span class="pre">size&gt;</span></code>, <code class="docutils literal notranslate"><span class="pre">1</span></code>, <code class="docutils literal notranslate"><span class="pre">&lt;embedding</span> <span class="pre">vector</span> <span class="pre">size&gt;</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">combiner</span></code>: str, specifies the combiner operation.
Specify <code class="docutils literal notranslate"><span class="pre">mean</span></code>, <code class="docutils literal notranslate"><span class="pre">sum</span></code>, or <code class="docutils literal notranslate"><span class="pre">concat</span></code>.</p></li>
</ul>
<p>Embedding Collection supports configuring the batch-major output with list of args in <code class="docutils literal notranslate"><span class="pre">embedding_lookup</span></code>.</p>
<p>Parameter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">table_config</span></code> : list of <code class="docutils literal notranslate"><span class="pre">hugectr.EmbeddingTableConfig</span></code>, the embedding table for the lookup operation.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">bottom_name</span></code>: list of str, the bottom tensor name.
Specify a tensor that is compatible with the <code class="docutils literal notranslate"><span class="pre">data_reader_sparse_param_array</span></code> parameter of <a class="reference internal" href="#input-layer"><code class="docutils literal notranslate"><span class="pre">hugectr.Input</span></code></a> in <code class="docutils literal notranslate"><span class="pre">hugectr.Model</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">top_name</span></code>: str, the output tensor name.
The shape of output tensor is (<code class="docutils literal notranslate"><span class="pre">&lt;batch</span> <span class="pre">size&gt;</span></code>, <code class="docutils literal notranslate"><span class="pre">sum</span> <span class="pre">of</span> <span class="pre">all</span> <span class="pre">&lt;embedding</span> <span class="pre">vector</span> <span class="pre">size&gt;</span></code>).</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">combiner</span></code>: list of str, specifies the combiner operation.
Specify <code class="docutils literal notranslate"><span class="pre">mean</span></code>, <code class="docutils literal notranslate"><span class="pre">sum</span></code>, or <code class="docutils literal notranslate"><span class="pre">concat</span></code>.</p></li>
</ul>
</section>
<section id="shard-method">
<h4>shard method<a class="headerlink" href="#shard-method" title="Permalink to this heading">ÔÉÅ</a></h4>
<p>In the recommendation system, the embedding table is usually so large that a single GPU is not able to hold all embedding tables.
One strategy for addressing the challenge is to use sharding to distribute the embedding tables across multiple GPUs.
We call this sharding strategy the embedding table placement strategy (ETPS).</p>
<p>ETPS can significantly boost the performance of embedding because different sharding strategies influence the communication between GPUs.
The optimal strategy is highly dependent on your dataset and your lookup operation.</p>
<p>EmbeddingCollectionConfig provides <code class="docutils literal notranslate"><span class="pre">shard</span></code> method for users to configure the ETPS so that users can adjust the ETPS according their own use case to achieve optimal performance.</p>
<p>Parameter:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">shard_matrix</span></code>: list of list of str, a matrix with num_gpus row and each row stores the name of embedding table that user want to place on row-th GPU.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">shard_strategy</span></code>: list of tuple(str, list of str), for each tuple(str, list of str), the first str means the table placement strategy, which can be ‚Äúmp‚Äù(model parallel) or ‚Äúdp‚Äù(data parallel), and the second list of str means table name which user want to apply the table placement strategy to. User can configure multiple table placement strategy. For example, [(‚Äúmp‚Äù, [‚Äút0‚Äù, ‚Äút1‚Äù]), (‚Äúdp‚Äù, [‚Äút2‚Äù, ‚Äút3‚Äù])]. Note, the <code class="docutils literal notranslate"><span class="pre">shard_strategy</span></code> should be consistent with <code class="docutils literal notranslate"><span class="pre">shard_matrix</span></code>, which means for the table which is ‚Äúdp‚Äù sharded should be placed on every GPU. And also one table can only be applied with one shard strategy.</p></li>
</ul>
<p>Example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># create embedding table configs</span>
<span class="n">embedding_table_names</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;goods&quot;</span><span class="p">,</span> <span class="s2">&quot;ads&quot;</span><span class="p">,</span> <span class="s2">&quot;userID&quot;</span><span class="p">,</span> <span class="s2">&quot;time&quot;</span><span class="p">]</span>
<span class="n">embedding_table_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">embedding_table_names</span><span class="p">:</span>
    <span class="n">embedding_table_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
        <span class="n">hugectr</span><span class="o">.</span><span class="n">EmbeddingTableConfig</span><span class="p">(</span>
            <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span>
            <span class="n">max_vocabulary_size</span><span class="o">=...</span><span class="p">,</span>
            <span class="n">ev_size</span><span class="o">=...</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="p">)</span>

<span class="c1"># create embedding collection config and configure lookup</span>
<span class="n">ebc_config</span> <span class="o">=</span> <span class="n">hugectr</span><span class="o">.</span><span class="n">EmbeddingCollectionConfig</span><span class="p">()</span>
<span class="n">ebc_config</span><span class="o">.</span><span class="n">embedding_lookup</span><span class="p">(</span>
    <span class="n">table_config</span><span class="o">=</span><span class="p">[</span><span class="n">embedding_table_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_TABLE</span><span class="p">)],</span>
    <span class="n">bottom_name</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;data</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_TABLE</span><span class="p">)],</span>
    <span class="n">top_name</span><span class="o">=</span><span class="s2">&quot;sparse_embedding&quot;</span><span class="p">,</span>
    <span class="n">combiner</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;sum&quot;</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">NUM_TABLE</span><span class="p">)],</span>
<span class="p">)</span>

<span class="c1"># configure the table placement strategy, suppose we have 4 GPUs</span>
<span class="n">shard_matrix</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="s2">&quot;goods&quot;</span><span class="p">,</span> <span class="s2">&quot;userID&quot;</span><span class="p">,</span> <span class="s2">&quot;time&quot;</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;ads&quot;</span><span class="p">,</span> <span class="s2">&quot;time&quot;</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;userID&quot;</span><span class="p">,</span> <span class="s2">&quot;time&quot;</span><span class="p">],</span>
    <span class="p">[</span><span class="s2">&quot;goods&quot;</span><span class="p">,</span> <span class="s2">&quot;time&quot;</span><span class="p">]</span>
<span class="p">]</span>
<span class="n">shard_strategy</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s2">&quot;mp&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;goods&quot;</span><span class="p">,</span> <span class="s2">&quot;userID&quot;</span><span class="p">,</span> <span class="s2">&quot;ads&quot;</span><span class="p">]),</span>
    <span class="p">(</span><span class="s2">&quot;dp&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;time&quot;</span><span class="p">]),</span>
<span class="p">]</span>
<span class="n">ebc_config</span><span class="o">.</span><span class="n">shard</span><span class="p">(</span><span class="n">shard_matrix</span><span class="o">=</span><span class="n">shard_matrix</span><span class="p">,</span> <span class="n">shard_strategy</span><span class="o">=</span><span class="n">shard_strategy</span><span class="p">)</span>
</pre></div>
</div>
</section>
</section>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="python_interface.html" class="btn btn-neutral float-left" title="HugeCTR Python Interface" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../additional_resources.html" class="btn btn-neutral float-right" title="Additional Resources" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, NVIDIA.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  
<div class="rst-versions" data-toggle="rst-versions" role="note" aria-label="versions">
  <span class="rst-current-version" data-toggle="rst-current-version">
    <span class="fa fa-book"> Other Versions</span>
    v: v24.06.00
    <span class="fa fa-caret-down"></span>
  </span>
  <div class="rst-other-versions">
    <dl>
      <dt>Tags</dt>
      <dd><a href="../../v23.08.00/api/hugectr_layer_book.html">v23.08.00</a></dd>
      <dd><a href="../../v23.09.00/api/hugectr_layer_book.html">v23.09.00</a></dd>
      <dd><a href="../../v23.12.00/api/hugectr_layer_book.html">v23.12.00</a></dd>
      <dd><a href="../../v24.04.00/api/hugectr_layer_book.html">v24.04.00</a></dd>
      <dd><a href="hugectr_layer_book.html">v24.06.00</a></dd>
      <dd><a href="../../v25.03.00/api/hugectr_layer_book.html">v25.03.00</a></dd>
    </dl>
    <dl>
      <dt>Branches</dt>
      <dd><a href="../../main/api/hugectr_layer_book.html">main</a></dd>
    </dl>
  </div>
</div><script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
    <!-- Theme Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-NVJ1Y1YJHK"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'G-NVJ1Y1YJHK', {
          'anonymize_ip': false,
      });
    </script> 

</body>
</html>